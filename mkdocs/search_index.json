{
    "docs": [
        {
            "location": "/", 
            "text": "Waffles\n\n\n\n\n\n\nWaffles\n\n\nAbout Waffles\n\n\nWhy Bash?\n\n\nWhy \"Waffles\"?\n\n\nContributing\n\n\n\n\n\n\n\n\n\n\nAbout Waffles\n\n\nWaffles is a configuration management system that helps you install, configure, and maintain services.\n\n\nIt is written in Bash 4.3 and uses core Linux utilities such as \ngrep\n, \nsed\n, and \nawk\n. \nrsync\n is required to push deployments to remote systems.\n\n\nWaffles also has a library of \nAugeas\n-based components. You can use Waffles without these components, but Augeas makes handling certain situations easier.\n\n\nWhy Bash?\n\n\nI chose Bash over another language such as Python, Ruby, Golang, etc because:\n\n\n\n\nBash is available on every Linux distribution out of the box. It's easy to install on FreeBSD and similar nix systems.\n\n\nConfiguring a nix-based system is all about running commands in a sequence as well as editing text files. This is exactly what Bash and the core utilities do.\n\n\nSome configuration management systems just create Bash subprocesses to perform the underlying system changes anyway.\n\n\n\n\nWhy \"Waffles\"?\n\n\nI had all sorts of names for this project. \"Composite\" was the longest running name, but I always felt it was kind of boring. \nHecubus\n was another front-runner. I eventually settled on \"Waffles\" because I wanted a name that was simple and wasn't too serious. And it's one of the first words I hear every morning when my son asks \"wa-foos?\".\n\n\nContributing\n\n\nAll kinds of contributions are welcome:\n\n\n\n\nMore docs\n\n\nMore resources\n\n\nBetter ways of accomplishing something", 
            "title": "Home"
        }, 
        {
            "location": "/#waffles", 
            "text": "Waffles  About Waffles  Why Bash?  Why \"Waffles\"?  Contributing", 
            "title": "Waffles"
        }, 
        {
            "location": "/#about-waffles", 
            "text": "Waffles is a configuration management system that helps you install, configure, and maintain services.  It is written in Bash 4.3 and uses core Linux utilities such as  grep ,  sed , and  awk .  rsync  is required to push deployments to remote systems.  Waffles also has a library of  Augeas -based components. You can use Waffles without these components, but Augeas makes handling certain situations easier.", 
            "title": "About Waffles"
        }, 
        {
            "location": "/#why-bash", 
            "text": "I chose Bash over another language such as Python, Ruby, Golang, etc because:   Bash is available on every Linux distribution out of the box. It's easy to install on FreeBSD and similar nix systems.  Configuring a nix-based system is all about running commands in a sequence as well as editing text files. This is exactly what Bash and the core utilities do.  Some configuration management systems just create Bash subprocesses to perform the underlying system changes anyway.", 
            "title": "Why Bash?"
        }, 
        {
            "location": "/#why-waffles", 
            "text": "I had all sorts of names for this project. \"Composite\" was the longest running name, but I always felt it was kind of boring.  Hecubus  was another front-runner. I eventually settled on \"Waffles\" because I wanted a name that was simple and wasn't too serious. And it's one of the first words I hear every morning when my son asks \"wa-foos?\".", 
            "title": "Why \"Waffles\"?"
        }, 
        {
            "location": "/#contributing", 
            "text": "All kinds of contributions are welcome:   More docs  More resources  Better ways of accomplishing something", 
            "title": "Contributing"
        }, 
        {
            "location": "/guides/install/", 
            "text": "Install Waffles\n\n\n\n\n\n\nInstall Waffles\n\n\nDescription\n\n\nSteps\n\n\nMore Information\n\n\n\n\n\n\n\n\n\n\nDescription\n\n\nThis guide will show how to install and use Waffles.\n\n\nSteps\n\n\n\n\nClone the repository to a directory of your choice:\n\n\n\n\n$ git clone https://github.com/jtopjian/waffles .waffles\n$ cd .waffles\n\n\n\n\n\n\nCreate a data file:\n\n\n\n\n$ cat \n site/data/memcached.sh \nEOF\ndata_memcached_interface=\n0.0.0.0\n\nEOF\n\n\n\n\n\n\nCreate a profile:\n\n\n\n\n$ cat \n site/profiles/memcached/scripts/server.sh \nEOF\nstdlib.title site/profiles/memcached/server\nstdlib.apt --package memcached --version latest\nstdlib.file_line --name memcached.conf/listen --file /etc/memcached.conf --line \n-l $data_memcached_server_listen\n --match \n^-l\n\nstdlib.sysvinit --name memcached\n\nif [[ $stdlib_state_change == true ]]; then\n  stdlib.mute /etc/init.d/memcached restart\nfi\n\n\n\n\n\n\nCreate a role:\n\n\n\n\n$ cat \n site/roles/memcached.sh \nEOF\nstdlib.data memcached\nstdlib.profile memcached/server\n\n\n\n\nMore Information\n\n\nFor more information about Data, Profiles, and Roles, see the \nusage\n doc.", 
            "title": "Installation"
        }, 
        {
            "location": "/guides/install/#install-waffles", 
            "text": "Install Waffles  Description  Steps  More Information", 
            "title": "Install Waffles"
        }, 
        {
            "location": "/guides/install/#description", 
            "text": "This guide will show how to install and use Waffles.", 
            "title": "Description"
        }, 
        {
            "location": "/guides/install/#steps", 
            "text": "Clone the repository to a directory of your choice:   $ git clone https://github.com/jtopjian/waffles .waffles\n$ cd .waffles   Create a data file:   $ cat   site/data/memcached.sh  EOF\ndata_memcached_interface= 0.0.0.0 \nEOF   Create a profile:   $ cat   site/profiles/memcached/scripts/server.sh  EOF\nstdlib.title site/profiles/memcached/server\nstdlib.apt --package memcached --version latest\nstdlib.file_line --name memcached.conf/listen --file /etc/memcached.conf --line  -l $data_memcached_server_listen  --match  ^-l \nstdlib.sysvinit --name memcached\n\nif [[ $stdlib_state_change == true ]]; then\n  stdlib.mute /etc/init.d/memcached restart\nfi   Create a role:   $ cat   site/roles/memcached.sh  EOF\nstdlib.data memcached\nstdlib.profile memcached/server", 
            "title": "Steps"
        }, 
        {
            "location": "/guides/install/#more-information", 
            "text": "For more information about Data, Profiles, and Roles, see the  usage  doc.", 
            "title": "More Information"
        }, 
        {
            "location": "/concepts/", 
            "text": "Waffles from Scratch\n\n\n\n\n\n\nWaffles from Scratch\n\n\nLet's Create a Simple memcached Server in Bash\n\n\nThe First Draft\n\n\nThe Second Draft\n\n\nThe Third Draft\n\n\nThe Fourth Draft\n\n\nThe Fifth Draft\n\n\nThe Sixth Draft\n\n\n\n\n\n\nConclusion\n\n\n\n\n\n\n\n\n\n\nTo illustrate Waffles's design, I'll walk through the creation of a Bash script that can successfully run multiple times on a single server and only make changes to the server when required.\n\n\nLet's Create a Simple memcached Server in Bash\n\n\nmemcached\n is a very simple service. It's a single daemon with a single configuration file installed from a single package.\n\n\n\n\nNote\n\n\nThe \"package, file, service\" pattern is very convenient for structuring service configurations.\n\n\n\n\nLet's say we want to create a \nmemcached\n server on a Linux container or virtual machine. Rather than running the commands manually, we'll create a Bash script to do the work. This will serve two purposes:\n\n\n\n\nBuild Documentation\n\n\nRepeatable process\n\n\n\n\nThe First Draft\n\n\nThe initial Bash script would look something like:\n\n\n#!/bin/bash\n\napt-get install -y memcached\n\n\n\n\nThe Second Draft\n\n\nThis works, and doing \nps aux\n shows that \nmemcached\n is running. But notice that \nmemcached\n is only listening on \nlocalhost\n:\n\n\n$ netstat -nap | grep 11211\n\n\n\n\nSince this \nmemcached\n service will be used by other services on the network, we need to change \nmemcached\n's interface binding to \n0.0.0.0\n. The following should work:\n\n\n$ sed -i -e '/^-l 127.0.0.1$/c -l 0.0.0.0' /etc/memcached.conf\n$ /etc/init.d/memcached restart\n\n\n\n\nAnd once that's tested on the command line, we add it to our script:\n\n\n#!/bin/bash\n\napt-get install -y memcached\nsed -i -e '/^-l 127.0.0.1$/c -l 0.0.0.0' /etc/memcached.conf\n/etc/init.d/memcached restart\n\n\n\n\nAstute readers will see an issue. In order for us to test this script, we need to run it again. However, the script is going to report that \nmemcached\n is already installed and an unnecessary restart of \nmemcached\n will take place.\n\n\nThere are two ways to resolve this issue:\n\n\nThe first is by starting over from scratch and running the script on a new server. There's a lot of merit to this method. For example, you can be sure that the exact steps work in sequence on new servers. However, the entire process could take a long time for some situations. Also, what if this \nmemcached\n service was in production? Either you'd have to take the \nmemcached\n service down temporarily while the new service builds or you'd have to find some way of seamlessly adding in the new service while removing the old. While there's benefit to this (which is similar to the current popularity of \"microservices\"), it may not always be a possible solution.\n\n\nThe second way is to alter the script so that changes are only made if required. If a change does not need to be made, nothing happens.\n\n\nLet's say it's not possible for us to rebuild from scratch. Therefore, we'll opt for the second option.\n\n\nThe Third Draft\n\n\nIn order to run our Bash script against a running service without causing (too much of) a disruption, we must ensure that each step is executed only if it needs to be. This means that before any command has run, we must check to see what the current state of the system is, compare it to the change we want to make, and only make the change if the system state does not match.\n\n\nBy doing this, our Bash script becomes a \"state declaration\" that describes how the \nmemcached\n service should be configured when the script is done running. This is known as \nIdempotence\n in Configuration Management.\n\n\nSo let's make our basic Bash script more idempotent:\n\n\ndpkg -s memcached \n/dev/null\nif [ $? == 1 ]; then\n  echo \nInstalling memcached\n\n  apt-get install -y memcached\nfi\n\ngrep -q '^-l 127.0.0.1' /etc/memcached.conf\nif [ $? == 0 ]; then\n  echo \nUpdating memcached.conf and restarting it.\n\n  sed -i -e '/^-l 127.0.0.1$/c -l 0.0.0.0' /etc/memcached.conf\n  /etc/init.d/memcached restart\nfi\n\n\n\n\nWith this in place, we can now execute this script multiple times on the same server, virtual machine, or container, and if a step has already been done it will not happen again.\n\n\nThe Fourth Draft\n\n\nHaving to do a bunch of \ngrep\ns and other checks can become very tedious. Waffles tries to resolve this by including a Standard Library of common tasks. Using the Waffles Standard Library, the above script can be re-written as:\n\n\n#!/bin/bash\n\nsource ./waffles.conf\nsource ./lib/init.sh\n\nstdlib.apt --package memcached\nstdlib.file_line --name memcached.conf/listen --file /etc/memcached.conf --line \n-l 0.0.0.0\n --match \n^-l\n\nstdlib.sysvinit --name memcached\n\nif [ \n$stdlib_state_change\n == true ]; then\n  /etc/init.d/memcached restart\nfi\n\n\n\n\nThere's nothing magical about these commands. They're a collection of standard Bash functions that sweep all of the messy \ngrep\ns under the carpet. You can see the full collection of Standard Library functions in the \nlib/\n directory.\n\n\nThe Fifth Draft\n\n\nThe core \nmemcached\n service is up and running, but there's still a few more tasks that need to be done. For example, maybe we want to create some users:\n\n\nstdlib.groupadd --group jdoe --gid 999\nstdlib.useradd --user jdoe --uid 999 --gid 999 --comment \nJohn\n --shell /bin/bash --homedir /home/jdoe --createhome true\n\n\n\n\nstdlib.useradd\n is another Waffles Standard Library function that enables an easy way to create and manage a user on a server.\n\n\nLooking at the above command, there are a lot of settings that are hard-coded. If we end up creating a \nredis\n server that also needs the \njdoe\n user, we could just copy that line verbatim, but what about a scenario where the \nuid\n must be changed to \n500\n? Then we'd need to change every occurrence of \n999\n to \n500\n. In large environments, there's a chance some changes would be missed.\n\n\nTo resolve this issue, Waffles allows settings such as this (known as \ndata\n) to be stored in data files.\n\n\nA simple way of using data is to just throw all settings into a file called \nsite/data/common.sh\n.\n\n\nLet's add a user:\n\n\ndata_users=(\n  jdoe\n)\n\ndeclare -Ag data_user_info\ndata_user_info=(\n  [jdoe|uid]=999\n  [jdoe|gid]=999\n  [jdoe|comment]=\nJohn doe\n\n  [jdoe|homedir]=\n/home/jdoe\n\n  [jdoe|shell]=\n/bin/bash\n\n  [jdoe|create_home]=true\n)\n\n\n\n\nWaffles data variables can be named anything, but if you want to follow the project standards, have the variables start with \ndata_\n.\n\n\nWith all of this in place, the fifth draft now looks like:\n\n\n#!/bin/bash\n\nsource ./waffles.conf\nsource ./lib/init.sh\n\nstdlib.data common\n\nfor user in \n${data_users[@]}\n; do\n\n  homedir=\n${data_user_info[${user}|homedir]}\n\n  uid=\n${data_user_info[${user}|uid]}\n\n  gid=\n${data_user_info[${user}|gid]}\n\n  comment=\n${data_user_info[${user}|comment]}\n\n  shell=\n${data_user_info[${user}|shell]}\n\n  create_home=\n${data_user_info[${user}|create_home]}\n\n\n  stdlib.groupadd --group \n$user\n --gid \n$gid\n\n  stdlib.useradd --state present --user \n$user\n --uid \n$uid\n --gid \n$gid\n --comment \n$comment\n --homedir \n$homedir\n --shell \n$shell\n --createhome \n$createhome\n\n\ndone\n\nstdlib.apt --package memcached\nstdlib.file_line --name memcached.conf/listen --file /etc/memcached.conf --line \n-l 0.0.0.0\n --match \n^-l\n\nstdlib.sysvinit --name memcached\n\nif [ \n$stdlib_state_change\n == true ]; then\n  /etc/init.d/memcached restart\nfi\n\n\n\n\nThe Sixth Draft\n\n\nThe block of user data can be re-used in other scripts. It'd be best if we just moved it out into its own separate script. By repeating this process, we can create a library of re-usable components. Final scripts then become \"compositions\" of the collection of scripts.\n\n\nCreate the directory structure \nsite/profiles/common/scripts\n and add the following to \nsite/profiles/common/scripts/users.sh\n\n\nfor user in \n${data_users[@]}\n; do\n\n  homedir=\n${data_user_info[${user}|homedir]}\n\n  uid=\n${data_user_info[${user}|uid]}\n\n  gid=\n${data_user_info[${user}|gid]}\n\n  comment=\n${data_user_info[${user}|comment]}\n\n  shell=\n${data_user_info[${user}|shell]}\n\n  create_home=\n${data_user_info[${user}|create_home]}\n\n\n  stdlib.groupadd --group \n$user\n --gid \n$gid\n\n  stdlib.useradd --state present --user \n$user\n --uid \n$uid\n --gid \n$gid\n --comment \n$comment\n --homedir \n$homedir\n --shell \n$shell\n --createhome \n$createhome\n\n\ndone\n\n\n\n\nAnd so the sixth draft now looks like:\n\n\n#!/bin/bash\n\nsource ./waffles.conf\nsource ./lib/init.sh\n\nstdlib.data common\nstdlib.profile common/users\n\nstdlib.apt --package memcached\nstdlib.file_line --name memcached.conf/listen --file /etc/memcached.conf --line \n-l 0.0.0.0\n --match \n^-l\n\nstdlib.sysvinit --name memcached\n\nif [ \n$stdlib_state_change\n == true ]; then\n  /etc/init.d/memcached restart\nfi\n\n\n\n\nYou can create this script inside the Waffles directory (where \nwaffles.conf\n is located), and run it like so:\n\n\nbash test.sh\n\n\n\n\nWhen you run it for the first time on a new server, it'll add the group, user, and set up \nmemcached\n. Run it multiple times and note how those same actions were not performed since the script detected that no changes needed to be made.\n\n\nConclusion\n\n\nAt this point, we've effectively recreated the core of Waffles. The rest of controls how Waffles runs and where to find various files that Waffles needs to read.", 
            "title": "Concepts"
        }, 
        {
            "location": "/concepts/#waffles-from-scratch", 
            "text": "Waffles from Scratch  Let's Create a Simple memcached Server in Bash  The First Draft  The Second Draft  The Third Draft  The Fourth Draft  The Fifth Draft  The Sixth Draft    Conclusion      To illustrate Waffles's design, I'll walk through the creation of a Bash script that can successfully run multiple times on a single server and only make changes to the server when required.", 
            "title": "Waffles from Scratch"
        }, 
        {
            "location": "/concepts/#lets-create-a-simple-memcached-server-in-bash", 
            "text": "memcached  is a very simple service. It's a single daemon with a single configuration file installed from a single package.   Note  The \"package, file, service\" pattern is very convenient for structuring service configurations.   Let's say we want to create a  memcached  server on a Linux container or virtual machine. Rather than running the commands manually, we'll create a Bash script to do the work. This will serve two purposes:   Build Documentation  Repeatable process   The First Draft  The initial Bash script would look something like:  #!/bin/bash\n\napt-get install -y memcached  The Second Draft  This works, and doing  ps aux  shows that  memcached  is running. But notice that  memcached  is only listening on  localhost :  $ netstat -nap | grep 11211  Since this  memcached  service will be used by other services on the network, we need to change  memcached 's interface binding to  0.0.0.0 . The following should work:  $ sed -i -e '/^-l 127.0.0.1$/c -l 0.0.0.0' /etc/memcached.conf\n$ /etc/init.d/memcached restart  And once that's tested on the command line, we add it to our script:  #!/bin/bash\n\napt-get install -y memcached\nsed -i -e '/^-l 127.0.0.1$/c -l 0.0.0.0' /etc/memcached.conf\n/etc/init.d/memcached restart  Astute readers will see an issue. In order for us to test this script, we need to run it again. However, the script is going to report that  memcached  is already installed and an unnecessary restart of  memcached  will take place.  There are two ways to resolve this issue:  The first is by starting over from scratch and running the script on a new server. There's a lot of merit to this method. For example, you can be sure that the exact steps work in sequence on new servers. However, the entire process could take a long time for some situations. Also, what if this  memcached  service was in production? Either you'd have to take the  memcached  service down temporarily while the new service builds or you'd have to find some way of seamlessly adding in the new service while removing the old. While there's benefit to this (which is similar to the current popularity of \"microservices\"), it may not always be a possible solution.  The second way is to alter the script so that changes are only made if required. If a change does not need to be made, nothing happens.  Let's say it's not possible for us to rebuild from scratch. Therefore, we'll opt for the second option.  The Third Draft  In order to run our Bash script against a running service without causing (too much of) a disruption, we must ensure that each step is executed only if it needs to be. This means that before any command has run, we must check to see what the current state of the system is, compare it to the change we want to make, and only make the change if the system state does not match.  By doing this, our Bash script becomes a \"state declaration\" that describes how the  memcached  service should be configured when the script is done running. This is known as  Idempotence  in Configuration Management.  So let's make our basic Bash script more idempotent:  dpkg -s memcached  /dev/null\nif [ $? == 1 ]; then\n  echo  Installing memcached \n  apt-get install -y memcached\nfi\n\ngrep -q '^-l 127.0.0.1' /etc/memcached.conf\nif [ $? == 0 ]; then\n  echo  Updating memcached.conf and restarting it. \n  sed -i -e '/^-l 127.0.0.1$/c -l 0.0.0.0' /etc/memcached.conf\n  /etc/init.d/memcached restart\nfi  With this in place, we can now execute this script multiple times on the same server, virtual machine, or container, and if a step has already been done it will not happen again.  The Fourth Draft  Having to do a bunch of  grep s and other checks can become very tedious. Waffles tries to resolve this by including a Standard Library of common tasks. Using the Waffles Standard Library, the above script can be re-written as:  #!/bin/bash\n\nsource ./waffles.conf\nsource ./lib/init.sh\n\nstdlib.apt --package memcached\nstdlib.file_line --name memcached.conf/listen --file /etc/memcached.conf --line  -l 0.0.0.0  --match  ^-l \nstdlib.sysvinit --name memcached\n\nif [  $stdlib_state_change  == true ]; then\n  /etc/init.d/memcached restart\nfi  There's nothing magical about these commands. They're a collection of standard Bash functions that sweep all of the messy  grep s under the carpet. You can see the full collection of Standard Library functions in the  lib/  directory.  The Fifth Draft  The core  memcached  service is up and running, but there's still a few more tasks that need to be done. For example, maybe we want to create some users:  stdlib.groupadd --group jdoe --gid 999\nstdlib.useradd --user jdoe --uid 999 --gid 999 --comment  John  --shell /bin/bash --homedir /home/jdoe --createhome true  stdlib.useradd  is another Waffles Standard Library function that enables an easy way to create and manage a user on a server.  Looking at the above command, there are a lot of settings that are hard-coded. If we end up creating a  redis  server that also needs the  jdoe  user, we could just copy that line verbatim, but what about a scenario where the  uid  must be changed to  500 ? Then we'd need to change every occurrence of  999  to  500 . In large environments, there's a chance some changes would be missed.  To resolve this issue, Waffles allows settings such as this (known as  data ) to be stored in data files.  A simple way of using data is to just throw all settings into a file called  site/data/common.sh .  Let's add a user:  data_users=(\n  jdoe\n)\n\ndeclare -Ag data_user_info\ndata_user_info=(\n  [jdoe|uid]=999\n  [jdoe|gid]=999\n  [jdoe|comment]= John doe \n  [jdoe|homedir]= /home/jdoe \n  [jdoe|shell]= /bin/bash \n  [jdoe|create_home]=true\n)  Waffles data variables can be named anything, but if you want to follow the project standards, have the variables start with  data_ .  With all of this in place, the fifth draft now looks like:  #!/bin/bash\n\nsource ./waffles.conf\nsource ./lib/init.sh\n\nstdlib.data common\n\nfor user in  ${data_users[@]} ; do\n\n  homedir= ${data_user_info[${user}|homedir]} \n  uid= ${data_user_info[${user}|uid]} \n  gid= ${data_user_info[${user}|gid]} \n  comment= ${data_user_info[${user}|comment]} \n  shell= ${data_user_info[${user}|shell]} \n  create_home= ${data_user_info[${user}|create_home]} \n\n  stdlib.groupadd --group  $user  --gid  $gid \n  stdlib.useradd --state present --user  $user  --uid  $uid  --gid  $gid  --comment  $comment  --homedir  $homedir  --shell  $shell  --createhome  $createhome \n\ndone\n\nstdlib.apt --package memcached\nstdlib.file_line --name memcached.conf/listen --file /etc/memcached.conf --line  -l 0.0.0.0  --match  ^-l \nstdlib.sysvinit --name memcached\n\nif [  $stdlib_state_change  == true ]; then\n  /etc/init.d/memcached restart\nfi  The Sixth Draft  The block of user data can be re-used in other scripts. It'd be best if we just moved it out into its own separate script. By repeating this process, we can create a library of re-usable components. Final scripts then become \"compositions\" of the collection of scripts.  Create the directory structure  site/profiles/common/scripts  and add the following to  site/profiles/common/scripts/users.sh  for user in  ${data_users[@]} ; do\n\n  homedir= ${data_user_info[${user}|homedir]} \n  uid= ${data_user_info[${user}|uid]} \n  gid= ${data_user_info[${user}|gid]} \n  comment= ${data_user_info[${user}|comment]} \n  shell= ${data_user_info[${user}|shell]} \n  create_home= ${data_user_info[${user}|create_home]} \n\n  stdlib.groupadd --group  $user  --gid  $gid \n  stdlib.useradd --state present --user  $user  --uid  $uid  --gid  $gid  --comment  $comment  --homedir  $homedir  --shell  $shell  --createhome  $createhome \n\ndone  And so the sixth draft now looks like:  #!/bin/bash\n\nsource ./waffles.conf\nsource ./lib/init.sh\n\nstdlib.data common\nstdlib.profile common/users\n\nstdlib.apt --package memcached\nstdlib.file_line --name memcached.conf/listen --file /etc/memcached.conf --line  -l 0.0.0.0  --match  ^-l \nstdlib.sysvinit --name memcached\n\nif [  $stdlib_state_change  == true ]; then\n  /etc/init.d/memcached restart\nfi  You can create this script inside the Waffles directory (where  waffles.conf  is located), and run it like so:  bash test.sh  When you run it for the first time on a new server, it'll add the group, user, and set up  memcached . Run it multiple times and note how those same actions were not performed since the script detected that no changes needed to be made.", 
            "title": "Let's Create a Simple memcached Server in Bash"
        }, 
        {
            "location": "/concepts/#conclusion", 
            "text": "At this point, we've effectively recreated the core of Waffles. The rest of controls how Waffles runs and where to find various files that Waffles needs to read.", 
            "title": "Conclusion"
        }, 
        {
            "location": "/usage/", 
            "text": "How to Use Waffles\n\n\n\n\n\n\nHow to Use Waffles\n\n\nThe \"site\" directory\n\n\nData\n\n\nReferencing Data\n\n\nData Structure\n\n\nHierarchial Data\n\n\n\n\n\n\nProfiles\n\n\nProfile Structure\n\n\nProfile Data\n\n\nGit Profiles\n\n\nThe Hosts Profile\n\n\n\n\n\n\nRoles\n\n\nApplying Roles\n\n\nLocal Execution\n\n\nRemote Execution (push)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe \"site\" directory\n\n\nEverything you work on will go under the \"site\" directory. By default, this directory is \nwaffles/site\n, but you can change it by setting \nWAFFLES_SITE_DIR\n in either:\n\n\n\n\nThe environment (environment variable)\n\n\nThe \nwaffles/waffles.conf\n file\n\n\n\n\n\n\nNote\n\n\nSee the \nEnvironment Variables\n Guide for more information.\n\n\n\n\nData\n\n\nData files are stored in \nsite/data\n. They're regular Bash scripts and it's only by convention that you store \"data\", and not programming logic, in these files.\n\n\nSo what is \"data\"? It's all of the settings that make your site or environment unique:\n\n\n\n\nIP Addresses\n\n\nUsernames, UIDs, GIDs\n\n\nPackage versions\n\n\nFirewall rules\n\n\n\n\nA Data file called \nmemcached.sh\n could look like this:\n\n\ndata_memcached_listen=\n0.0.0.0\n\n\ndeclare -Ag data_user_info\ndata_user_info=(\n  [jdoe|uid]=999\n  [jdoe|gid]=999\n  [jdoe|comment]=\nJohn doe\n\n  [jdoe|homedir]=\n/home/jdoe\n\n  [jdoe|shell]=\n/bin/bash\n\n  [jdoe|create_home]=true\n)\n\n\n\n\n\n\nNote\n\n\nYou can name the variables anything you'd like, though the Waffles naming convention is to start each variable with \ndata_\n.\n\n\n\n\n\n\nWarning\n\n\nBash associative arrays \nmust\n be declared as global variables. This is because all files are sourced inside a Bash function and, for whatever reason, associative arrays are not visible outside of a function (unlike all other Bash variable types).\n\n\n\n\nReferencing Data\n\n\nOnce you've created some \"data\" in a data file, you can refer to it by doing the following:\n\n\nstdlib.data memcached\n\necho $data_memcached_listen\n\n\n\n\nstdlib.data\n is a function that takes a single argument: the name of a data file.\n\n\nData Structure\n\n\nThe placement of data files is flexible. You can do any of the following:\n\n\nstdlib.data common       =\n site/data/common.sh\nstdlib.data common       =\n site/data/common/init.sh\nstdlib.data common/users =\n site/data/common/users.sh\nstdlib.data memcached    =\n site/data/memcached.sh\nstdlib.data memcached    =\n site/data/memcached/init.sh\n\n\n\n\nHierarchial Data\n\n\nBy declaring multiple data files in your role, you can create a hierarchy of data. For example:\n\n\nstdlib.data common\nstdlib.data memcached\n\n\n\n\nIn the above, common settings that are applicable to \nany\n role are stored in \nsite/data/common.sh\n. Only data relevant to the \nmemcached\n service is stored in \nsite/data/memcached.sh\n.\n\n\nYou can even declare the same variable in both data files. The data file declaring it last will overwrite all previous declarations and win.\n\n\nFinally, you can reference data from a previously declared data file. You can't, however, reference variables in data files \nbefore\n they are declared. To clarify: \nsite/data/memcached.sh\n can reference data from \nsite/data/common.sh\n, but not vice versa.\n\n\n\n\nNote\n\n\nSee the \nReferencing Data from Data\n and \nOverriding Data\n Guides for more information.\n\n\n\n\nProfiles\n\n\nProfiles are small snippets of bash scripts stored under \nsite/profiles\n. They are meant to be distinct units of work that accomplish a single task.\n\n\nFor example, you may have a Profile that installs the \nmemcached\n package, a Profile that configures \n/etc/memcached.conf\n, and a Profile that sets up the \nmemcached\n daemon. Or you may choose to have a single Profile that does all three tasks. Waffles does not enforce any rules to how you design your Profiles.\n\n\n\n\nWarning\n\n\nIt's possible to call Profiles from other Profiles, but that's not an encouraged practice.\n\n\n\n\nProfile Structure\n\n\nProfiles have a standard structure to them:\n\n\nsite/profiles/consul/\n\u251c\u2500\u2500 data.sh\n\u251c\u2500\u2500 files\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 consul.conf\n\u2514\u2500\u2500 scripts\n    \u251c\u2500\u2500 install_linux.sh\n    \u2514\u2500\u2500 server.sh\n\n\n\n\nStatic files go under \nfiles\n while scripts go under \nscripts\n. Profile-specific data can be stored in \ndata.sh\n\n\n\n\nNote\n\n\nWhen using the \nstdlib.file\n resource, you can use the \n--source\n option to copy files to their destination. The \n--source\n option is able to reference any file on the system. It's recommended to use \n$WAFFLES_SITE_DIR/profiles/profile_name/files/file.conf\n when \"sourcing\" a file.\n\n\n\n\nThe \nstdlib.profile\n function is similar to \nstdlib.data\n: it takes a single argument, which is the name of a profile. The following translations are possible:\n\n\nstdlib.profile common/users    =\n site/profiles/common/scripts/users.sh\nstdlib.profile common/packages =\n site/profiles/common/scripts/packages.sh\nstdlib.profile memcached       =\n site/profiles/memcached/scripts/init.sh\nstdlib.profile memcached/utils =\n site/profiles/memcached/scripts/utils.sh\n\n\n\n\nProfile Data\n\n\nProfile-specific data can be stored in \nprofile_name/data.sh\n. This enables data unique to the profile to be bundled within the profile and stored in a repository outside of \n$WAFFLES_SITE_DIR\n.\n\n\n\n\nWarning\n\n\nProfile data is sourced when the profile is applied. This means that profile data can override or overwrite previously declared data that uses the same name. It is not possible to source profile data at the beginning of the role like with \nstdlib.data\n.\n\n\n\n\nGit Profiles\n\n\nWaffles supports the ability to store profiles in a git repository. To use this feature, include the following in the role:\n\n\nstdlib.git_profile https://github.com/jtopjian/waffles-profile-openstack branch dev\n\n\n\n\nThis will clone https://github.com/jtopjian/waffles-profile-openstack as \n$WAFFLES_SITE_DIR/profiles/openstack\n with the \ndev\n branch checked out.\n\n\nOnce the above is declared, profile scripts can be referenced like normal:\n\n\nstdlib.profile openstack/keystone\n\n\n\n\nProfile names are based on the repository name. Waffles will split the repository name by dashes (\n-\n) and use the last portion of the name.\n\n\nstdlib.git_profile\n has the following syntax:\n\n\nstdlib.git_profile https://github.com/jtopjian/waffles-profile-openstack\nstdlib.git_profile https://github.com/jtopjian/waffles-profile-openstack branch dev\nstdlib.git_profile https://github.com/jtopjian/waffles-profile-openstack tag 0.5.1\nstdlib.git_profile https://github.com/jtopjian/waffles-profile-openstack commit 023a83\n\n\n\n\nIn addition to \nstdlib.git_profile\n, there is \nstdlib.git_profile_push\n which works the same way as \nstdlib.git_profile\n, but the repository is downloaded on the Waffles \"server\" and then pushed to the remote node. This is useful in cases when the nodes do not have direct access to the git repository.\n\n\nThe Hosts Profile\n\n\nWaffles supports an optional special profile called \nhost_files\n, located at \nsite/profiles/host_files\n. The purpose of this profile is to provide an area where files and scripts specific to individual hosts can be stored. This is beneficial because, normally, the entire profile is copied to each node that uses the profile. If you are storing files such as SSL certs in a profile, all SSL certs would be then copied to all hosts that share the profile.\n\n\nThe \nhost_files\n profile has the following structure:\n\n\nsite/profiles/host_files/\n\u251c\u2500\u2500 mysql-01\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 files\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 mysql-01.crt\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 mysql-01.key\n\u251c\u2500\u2500 mysql-02\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 files\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 mysql-02.crt\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 mysql-02.key\n\u2514\u2500\u2500 rabbit-01\n    \u251c\u2500\u2500 files\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 rabbit-01.crt\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 rabbit-01.key\n    \u2514\u2500\u2500 scripts\n        \u2514\u2500\u2500 custom.sh\n\n\n\n\nEach subdirectory of the \nhost_files\n profile is an individual host or node, named after the hostname (not FQDN). The directory of these subdirectories is like a normal profile with the usual \nfiles\n and \nscripts\n subdirectories.\n\n\nInside your role, you can enable this special profile by doing:\n\n\nstdlib.profile host_files\n\n\n\n\n\n\nWarning\n\n\nThis means that \nhost_files\n is a reserved name.\n\n\n\n\nRoles\n\n\nA \"role\" is a name that identifies a unique configuration set. Examples of roles could be:\n\n\n\n\nmemcached\n\n\nmemcached_apt\n\n\nmemcached_yum\n\n\nmemcached_yum_lxc\n\n\nmemcached_and_redis\n\n\n\n\nRole names are up to you -- just make sure \nyou\n understand that applying the \nmemcached_yum_lxc\n role to an Ubuntu-based KVM virtual machine probably won't work.\n\n\nRoles are defined in \nsite/roles\n.\n\n\n\n\nNote\n\n\nA role is really just another Bash script. It's possible to use Waffles to organize a collection of deployment scripts simply by placing them under the \nsite/roles\n directory.\n\n\n\n\nTo use roles most effectively, think of them as glue between \ndata\n and \nprofiles\n:\n\n\nA very simple role could look like this:\n\n\n# Reads data from site/data/common.sh\nstdlib.data common\n\n# Reads data from site/data/memcached.sh\nstdlib.data memcached\n\n# Reads site/profiles/common/scripts/users.sh\nstdlib.profile common/users\n\n# Reads site/profiles/common/scripts/packages.sh\nstdlib.profile common/packages\n\n# Reads site/profiles/memcached/scripts/init.sh\nstdlib.profile memcached\n\n\n\n\nApplying Roles\n\n\nWaffles supports two ways of applying roles:\n\n\nLocal Execution\n\n\nYou can run \nwaffles.sh\n directly on a node and Waffles will apply the role to that node. For example:\n\n\n$ waffles.sh -r memcached\n\n\n\n\nThis is most useful when you copy the entire contents of the \nwaffles\n directory to a node, log into the node, and manually run \nwaffles.sh\n.\n\n\nRemote Execution (push)\n\n\nIt's possible to run Waffles on a remote node by pushing the configuration via rsync and SSH. To do this, use the \n-s \nserver\n flag. For example:\n\n\n$ waffles.sh -s www.example.com -r web\n\n\n\n\nThe benefit of this method is that only the data and profiles referenced in the role will be copied to the remote node. So if you have several other profiles, such as for MySQL or RabbitMQ, those profiles will not be copied to a node acting as a \nmemcached\n node.\n\n\n\n\nNote\n\n\nAt this time, both the Waffles server and destination node must have rsync and installed.", 
            "title": "Usage"
        }, 
        {
            "location": "/usage/#how-to-use-waffles", 
            "text": "How to Use Waffles  The \"site\" directory  Data  Referencing Data  Data Structure  Hierarchial Data    Profiles  Profile Structure  Profile Data  Git Profiles  The Hosts Profile    Roles  Applying Roles  Local Execution  Remote Execution (push)", 
            "title": "How to Use Waffles"
        }, 
        {
            "location": "/usage/#the-site-directory", 
            "text": "Everything you work on will go under the \"site\" directory. By default, this directory is  waffles/site , but you can change it by setting  WAFFLES_SITE_DIR  in either:   The environment (environment variable)  The  waffles/waffles.conf  file    Note  See the  Environment Variables  Guide for more information.", 
            "title": "The \"site\" directory"
        }, 
        {
            "location": "/usage/#data", 
            "text": "Data files are stored in  site/data . They're regular Bash scripts and it's only by convention that you store \"data\", and not programming logic, in these files.  So what is \"data\"? It's all of the settings that make your site or environment unique:   IP Addresses  Usernames, UIDs, GIDs  Package versions  Firewall rules   A Data file called  memcached.sh  could look like this:  data_memcached_listen= 0.0.0.0 \n\ndeclare -Ag data_user_info\ndata_user_info=(\n  [jdoe|uid]=999\n  [jdoe|gid]=999\n  [jdoe|comment]= John doe \n  [jdoe|homedir]= /home/jdoe \n  [jdoe|shell]= /bin/bash \n  [jdoe|create_home]=true\n)   Note  You can name the variables anything you'd like, though the Waffles naming convention is to start each variable with  data_ .    Warning  Bash associative arrays  must  be declared as global variables. This is because all files are sourced inside a Bash function and, for whatever reason, associative arrays are not visible outside of a function (unlike all other Bash variable types).   Referencing Data  Once you've created some \"data\" in a data file, you can refer to it by doing the following:  stdlib.data memcached\n\necho $data_memcached_listen  stdlib.data  is a function that takes a single argument: the name of a data file.  Data Structure  The placement of data files is flexible. You can do any of the following:  stdlib.data common       =  site/data/common.sh\nstdlib.data common       =  site/data/common/init.sh\nstdlib.data common/users =  site/data/common/users.sh\nstdlib.data memcached    =  site/data/memcached.sh\nstdlib.data memcached    =  site/data/memcached/init.sh  Hierarchial Data  By declaring multiple data files in your role, you can create a hierarchy of data. For example:  stdlib.data common\nstdlib.data memcached  In the above, common settings that are applicable to  any  role are stored in  site/data/common.sh . Only data relevant to the  memcached  service is stored in  site/data/memcached.sh .  You can even declare the same variable in both data files. The data file declaring it last will overwrite all previous declarations and win.  Finally, you can reference data from a previously declared data file. You can't, however, reference variables in data files  before  they are declared. To clarify:  site/data/memcached.sh  can reference data from  site/data/common.sh , but not vice versa.   Note  See the  Referencing Data from Data  and  Overriding Data  Guides for more information.", 
            "title": "Data"
        }, 
        {
            "location": "/usage/#profiles", 
            "text": "Profiles are small snippets of bash scripts stored under  site/profiles . They are meant to be distinct units of work that accomplish a single task.  For example, you may have a Profile that installs the  memcached  package, a Profile that configures  /etc/memcached.conf , and a Profile that sets up the  memcached  daemon. Or you may choose to have a single Profile that does all three tasks. Waffles does not enforce any rules to how you design your Profiles.   Warning  It's possible to call Profiles from other Profiles, but that's not an encouraged practice.   Profile Structure  Profiles have a standard structure to them:  site/profiles/consul/\n\u251c\u2500\u2500 data.sh\n\u251c\u2500\u2500 files\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 consul.conf\n\u2514\u2500\u2500 scripts\n    \u251c\u2500\u2500 install_linux.sh\n    \u2514\u2500\u2500 server.sh  Static files go under  files  while scripts go under  scripts . Profile-specific data can be stored in  data.sh   Note  When using the  stdlib.file  resource, you can use the  --source  option to copy files to their destination. The  --source  option is able to reference any file on the system. It's recommended to use  $WAFFLES_SITE_DIR/profiles/profile_name/files/file.conf  when \"sourcing\" a file.   The  stdlib.profile  function is similar to  stdlib.data : it takes a single argument, which is the name of a profile. The following translations are possible:  stdlib.profile common/users    =  site/profiles/common/scripts/users.sh\nstdlib.profile common/packages =  site/profiles/common/scripts/packages.sh\nstdlib.profile memcached       =  site/profiles/memcached/scripts/init.sh\nstdlib.profile memcached/utils =  site/profiles/memcached/scripts/utils.sh  Profile Data  Profile-specific data can be stored in  profile_name/data.sh . This enables data unique to the profile to be bundled within the profile and stored in a repository outside of  $WAFFLES_SITE_DIR .   Warning  Profile data is sourced when the profile is applied. This means that profile data can override or overwrite previously declared data that uses the same name. It is not possible to source profile data at the beginning of the role like with  stdlib.data .   Git Profiles  Waffles supports the ability to store profiles in a git repository. To use this feature, include the following in the role:  stdlib.git_profile https://github.com/jtopjian/waffles-profile-openstack branch dev  This will clone https://github.com/jtopjian/waffles-profile-openstack as  $WAFFLES_SITE_DIR/profiles/openstack  with the  dev  branch checked out.  Once the above is declared, profile scripts can be referenced like normal:  stdlib.profile openstack/keystone  Profile names are based on the repository name. Waffles will split the repository name by dashes ( - ) and use the last portion of the name.  stdlib.git_profile  has the following syntax:  stdlib.git_profile https://github.com/jtopjian/waffles-profile-openstack\nstdlib.git_profile https://github.com/jtopjian/waffles-profile-openstack branch dev\nstdlib.git_profile https://github.com/jtopjian/waffles-profile-openstack tag 0.5.1\nstdlib.git_profile https://github.com/jtopjian/waffles-profile-openstack commit 023a83  In addition to  stdlib.git_profile , there is  stdlib.git_profile_push  which works the same way as  stdlib.git_profile , but the repository is downloaded on the Waffles \"server\" and then pushed to the remote node. This is useful in cases when the nodes do not have direct access to the git repository.  The Hosts Profile  Waffles supports an optional special profile called  host_files , located at  site/profiles/host_files . The purpose of this profile is to provide an area where files and scripts specific to individual hosts can be stored. This is beneficial because, normally, the entire profile is copied to each node that uses the profile. If you are storing files such as SSL certs in a profile, all SSL certs would be then copied to all hosts that share the profile.  The  host_files  profile has the following structure:  site/profiles/host_files/\n\u251c\u2500\u2500 mysql-01\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 files\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 mysql-01.crt\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 mysql-01.key\n\u251c\u2500\u2500 mysql-02\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 files\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 mysql-02.crt\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 mysql-02.key\n\u2514\u2500\u2500 rabbit-01\n    \u251c\u2500\u2500 files\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 rabbit-01.crt\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 rabbit-01.key\n    \u2514\u2500\u2500 scripts\n        \u2514\u2500\u2500 custom.sh  Each subdirectory of the  host_files  profile is an individual host or node, named after the hostname (not FQDN). The directory of these subdirectories is like a normal profile with the usual  files  and  scripts  subdirectories.  Inside your role, you can enable this special profile by doing:  stdlib.profile host_files   Warning  This means that  host_files  is a reserved name.", 
            "title": "Profiles"
        }, 
        {
            "location": "/usage/#roles", 
            "text": "A \"role\" is a name that identifies a unique configuration set. Examples of roles could be:   memcached  memcached_apt  memcached_yum  memcached_yum_lxc  memcached_and_redis   Role names are up to you -- just make sure  you  understand that applying the  memcached_yum_lxc  role to an Ubuntu-based KVM virtual machine probably won't work.  Roles are defined in  site/roles .   Note  A role is really just another Bash script. It's possible to use Waffles to organize a collection of deployment scripts simply by placing them under the  site/roles  directory.   To use roles most effectively, think of them as glue between  data  and  profiles :  A very simple role could look like this:  # Reads data from site/data/common.sh\nstdlib.data common\n\n# Reads data from site/data/memcached.sh\nstdlib.data memcached\n\n# Reads site/profiles/common/scripts/users.sh\nstdlib.profile common/users\n\n# Reads site/profiles/common/scripts/packages.sh\nstdlib.profile common/packages\n\n# Reads site/profiles/memcached/scripts/init.sh\nstdlib.profile memcached", 
            "title": "Roles"
        }, 
        {
            "location": "/usage/#applying-roles", 
            "text": "Waffles supports two ways of applying roles:  Local Execution  You can run  waffles.sh  directly on a node and Waffles will apply the role to that node. For example:  $ waffles.sh -r memcached  This is most useful when you copy the entire contents of the  waffles  directory to a node, log into the node, and manually run  waffles.sh .  Remote Execution (push)  It's possible to run Waffles on a remote node by pushing the configuration via rsync and SSH. To do this, use the  -s  server  flag. For example:  $ waffles.sh -s www.example.com -r web  The benefit of this method is that only the data and profiles referenced in the role will be copied to the remote node. So if you have several other profiles, such as for MySQL or RabbitMQ, those profiles will not be copied to a node acting as a  memcached  node.   Note  At this time, both the Waffles server and destination node must have rsync and installed.", 
            "title": "Applying Roles"
        }, 
        {
            "location": "/modules/", 
            "text": "Modules\n\n\nAt this time, Waffles has no concept of \"modules\" or \"plug-ins\". This is intentional.\n\n\nAll resources are currently being bundled into \n/lib\n. This is because the resource files are so small, it's not expensive (in terms of disk space or bandwidth transfer) to have one large bundle of resources. This also means that there might be some disagreement on the best way a resource is implemented. We'll see how that goes.\n\n\nProfiles can be thought of as the closest thing to a \"module\" as they have a defined structure that includes areas for static files and scripts. Profiles may be interchangeable between your various projects, sites, and environments, but they might not be usable for people outside of your domain of responsibility. This is also intentional.\n\n\nI want Waffles to help people quickly deploy and configure different types of services, but I also want to ensure they learn how the deployment is done and how the software works. I do not want to create a module ecosystem that is taken for granted instead of actually learning and understanding what is being deployed.", 
            "title": "Modules"
        }, 
        {
            "location": "/modules/#modules", 
            "text": "At this time, Waffles has no concept of \"modules\" or \"plug-ins\". This is intentional.  All resources are currently being bundled into  /lib . This is because the resource files are so small, it's not expensive (in terms of disk space or bandwidth transfer) to have one large bundle of resources. This also means that there might be some disagreement on the best way a resource is implemented. We'll see how that goes.  Profiles can be thought of as the closest thing to a \"module\" as they have a defined structure that includes areas for static files and scripts. Profiles may be interchangeable between your various projects, sites, and environments, but they might not be usable for people outside of your domain of responsibility. This is also intentional.  I want Waffles to help people quickly deploy and configure different types of services, but I also want to ensure they learn how the deployment is done and how the software works. I do not want to create a module ecosystem that is taken for granted instead of actually learning and understanding what is being deployed.", 
            "title": "Modules"
        }, 
        {
            "location": "/functions/types/", 
            "text": "Types of Functions\n\n\n\n\n\n\nTypes of Functions\n\n\nstdlib\n\n\nnon-stdlib\n\n\n\n\n\n\n\n\n\n\nWaffles is built around Bash functions. Some are only used internally, but others are available for use in your roles and profiles.\n\n\nstdlib\n\n\nFunctions that are prefixed with \nstdlib\n are considered core to Waffles. They can be used anywhere.\n\n\nnon-stdlib\n\n\nFunctions that are not prefixed with \nstdlib\n should be considered optional. Anything not prefixed with \nstdlib\n should \nnot\n be used in an \nstdlib\n function.", 
            "title": "Types"
        }, 
        {
            "location": "/functions/types/#types-of-functions", 
            "text": "Types of Functions  stdlib  non-stdlib      Waffles is built around Bash functions. Some are only used internally, but others are available for use in your roles and profiles.", 
            "title": "Types of Functions"
        }, 
        {
            "location": "/functions/types/#stdlib", 
            "text": "Functions that are prefixed with  stdlib  are considered core to Waffles. They can be used anywhere.", 
            "title": "stdlib"
        }, 
        {
            "location": "/functions/types/#non-stdlib", 
            "text": "Functions that are not prefixed with  stdlib  should be considered optional. Anything not prefixed with  stdlib  should  not  be used in an  stdlib  function.", 
            "title": "non-stdlib"
        }, 
        {
            "location": "/functions/system/", 
            "text": "System Functions\n\n\nlib/system.sh\n contains functions that are considered core to Waffles.\n\n\n\n\n\n\nSystem Functions\n\n\nstdlib.array_contains\n\n\nstdlib.array_join\n\n\nstdlib.array_length\n\n\nstdlib.array_pop\n\n\nstdlib.array_push\n\n\nstdlib.array_shift\n\n\nstdlib.array_unshift\n\n\nstdlib.capture_error\n\n\nstdlib.command_exists\n\n\nstdlib.data\n\n\nstdlib.debug\n\n\nstdlib.debug?\n\n\nstdlib.debug_mute\n\n\nstdlib.dir\n\n\nstdlib.error\n\n\nstdlib.exec\n\n\nstdlib.git_profile\n\n\nstdlib.git_profile_push\n\n\nstdlib.hash_keys\n\n\nstdlib.include\n\n\nstdlib.info\n\n\nstdlib.mute\n\n\nstdlib.noop?\n\n\nstdlib.profile\n\n\nstdlib.split\n\n\nstdlib.subtitle\n\n\nstdlib.title\n\n\nstdlib.trim\n\n\nstdlib.warn\n\n\n\n\n\n\n\n\n\n\nstdlib.array_contains\n\n\nReports true if element exists in an array.\n\n\nx=(foo bar baz)\nif stdlib.array_contains \nx\n \nfoo\n ; then\n  echo \nExists\n\nfi\n\n\n\n\nstdlib.array_join\n\n\nJoins an array into a string.\n\n\nx=(foo bar baz)\nstdlib.array_join x ,\n=\n foo,bar,baz\n\n\n\n\nstdlib.array_length\n\n\nReturns the length of an array.\n\n\nx=(a b c)\nstdlib.array_length x\n=\n 3\n\n\n\n\nstdlib.array_pop\n\n\nRemoves and the last element from array $1 and optionally stores it in $2\n\n\nx=(a b c)\nstdlib.array_pop x y\necho $y\n=\n c\n\n\n\n\nstdlib.array_push\n\n\nAdds an element to the end of an array.\n\n\nx=()\nstdlib.array_push x foo\n\n\n\n\nstdlib.array_shift\n\n\nRemoves and returns the first element from array $1 and optionally stores it in $2\n\n\nx=(a b c)\nstdlib.array_shift x y\necho $y\n=\n a\n\n\n\n\nstdlib.array_unshift\n\n\nAdds an element to the beginning of the array.\n\n\nx=(b c)\nstdlib.array_unshift x a\n\n\n\n\n\nstdlib.capture_error\n\n\nTakes a command as input, prints the command, and detects if anything was written to \nstderr\n. If there was, the error is printed to \nstderr\n again, and if \nWAFFLES_EXIT_ON_ERROR\n is set, Waffles halts.\n\n\nstdlib.capture_error apt-get update\n\n\n\n\nstdlib.command_exists\n\n\nA simple wrapper around \nwhich\n.\n\n\nif [[ stdlib.command_exists apt-get ]]; then\n  stdlib.info \nWe're on a Debian-based system.\n\nfi\n\n\n\n\nstdlib.data\n\n\nThe same as \nstdlib.profiles\n but the shell scripts can be placed differently:\n\n\nstdlib.data common =\n data/common.sh\nstdlib.data common =\n data/common/init.sh\nstdlib.data common/users =\n data/common/users.sh\nstdlib.data memcached =\n data/memcached.sh\nstdlib.data memcached =\n data/memcached/init.sh\n\n\n\n\nstdlib.debug\n\n\nPrints a log message at \ndebug\n level.\n\n\nstdlib.debug \nFoobar\n\n\n\n\n\nstdlib.debug?\n\n\nDetermines if Waffles is being run in \ndebug\n mode.\n\n\nif stdlib.debug? ; then\n  stdlib.debug \nWe're in debug mode.\n\nfi\n\n\n\n\nstdlib.debug_mute\n\n\nLike \nstdlib.mute\n but messages only appear in \ndebug\n mode.\n\n\nstdlib.debug_mute apt-get update\n\n\n\n\nstdlib.dir\n\n\nA simple function that returns the current directory of the script currently being run.\n\n\nstdlib.error\n\n\nPrints an error message to \nstderr\n.\n\n\nstdlib.error \nFoobar\n\n\n\n\n\nstdlib.exec\n\n\nA simple function that takes a command as input, prints the command, and then executes it.\n\n\nstdlib.exec apt-get update\n\n\n\n\nstdlib.git_profile\n\n\nstdlib.git_profile will check a profile out from a git repository. It will be ignored if running in REMOTE mode, so repositories are only created when Waffles is run locally.\n\n\nstdlib.git_profile repositories must be named:\n\n\nwaffles-profile-$profile_name\n\n\n\n\nstdlib.git_profiles must follow the following syntax:\n\n\nstdlib.git_profile https://github.com/jtopjian/waffles-profile-openstack\nstdlib.git_profile https://github.com/jtopjian/waffles-profile-openstack branch dev\nstdlib.git_profile https://github.com/jtopjian/waffles-profile-openstack tag 0.5.1\nstdlib.git_profile https://github.com/jtopjian/waffles-profile-openstack commit 023a83\n\n\n\n\nstdlib.git_profile_push\n\n\nWorks the same way as stdlib.git_profile, but the git repository is downloaded on the Waffles \"server\" and pushed to the node. This is useful in cases when the nodes do not have direct access to the git repository.\n\n\nstdlib.hash_keys\n\n\nReturns the keys of a hash / associative array.\n\n\ndeclare -A foo=(\n  [a]=1\n  [b]=2\n  [c]=3\n)\n\nstdlib.hash_keys \nfoo\n\n=\n a b c\n\nx=($(stdlib.hash_keys \nfoo\n))\necho \n${x[1]}\n\n=\n b\n\n\n\n\nstdlib.include\n\n\nA more intelligent \nsource\n. It checks if the file being sourced / included exists, and if not, prints a warning and moves on.\n\n\nstdlib.info\n\n\nPrints a log message at \ninfo\n level.\n\n\nstdlib.info \nFoobar\n\n\n\n\n\nstdlib.mute\n\n\nPrints the command being run, but suppresses the command output.\n\n\nstdlib.mute apt-get update\n\n\n\n\nstdlib.noop?\n\n\nDetermines if Waffles is being run in \nnoop\n mode.\n\n\nif stdlib.noop? ; then\n  stdlib.info \nWe're in noop mode.\n\nfi\n\n\n\n\nstdlib.profile\n\n\nTakes a profile as input and determines the shell script attached to the profile.\n\n\nIf Waffles is being run locally, then \nstdlib.include\n is run on the script. If Waffles is being run in push-based mode, then the profile is marked to be copied to the remote node.\n\n\nstdlib.profiles common/users =\n profiles/common/scripts/users.sh\nstdlib.profiles common/packages =\n profiles/common/scripts/packages.sh\nstdlib.profiles memcached =\n profiles/memcached/scripts/init.sh\nstdlib.profiles memcached/utils =\n profiles/memcached/scripts/utils.sh\n\n\n\n\nstdlib.split\n\n\nSplits a string into an array. Stores the result in \n__split\n. The delimiter can be multi-character.\n\n\nstdlib.split \nfoo/bar\n, \n/\n\nstdlib.info $__split[1] # bar\n\n\n\n\nstdlib.subtitle\n\n\nSets a subtitle context. This is usually used internally by resources. An internal counter to determine if the resource was changed:\n\n\n$ cat profiles/common/scripts/package.sh\nstdlib.title \nprofiles/common/packages\n\nstdlib.apt --package sl\n\nif [[ $stdlib_resource_change == true ]]; then\n  stdlib.info \nThe state of package sl changed\n\nfi\n\nstdlib.apt --package cowsay\n\nif [[ $stdlib_resource_change == true ]]; then\n  stdlib.info \nThe state of package cowsay changed\n\nfi\n\n\n\n\nstdlib.title\n\n\nSets a title context. A title is a major section of Waffles being run; for example, a profile. You usually being profiles by setting a title:\n\n\n$ cat profiles/common/scripts/package.sh\nstdlib.title \nprofiles/common/packages\n\nstdlib.apt --package sl\n\n\n\n\nInternal counters are reset whenever \nstdlib.title\n is used. This is useful for determining if any changes were made to a resource or the profile as a whole:\n\n\n$ cat profiles/common/scripts/package.sh\nstdlib.title \nprofiles/common/packages\n\nstdlib.apt --package sl\nstdlib.apt --package cowsay\n\nif [[ $stdlib_state_change == true ]]; then\n  stdlib.info \nOne of the above packages were updated.\n\nfi\n\n\n\n\nstdlib.trim\n\n\nTrims the whitespace on both sides of a string.\n\n\ntrimmed=$(stdlib.trim \n   foobar   \n\n\n\n\n\nstdlib.warn\n\n\nPrints a warning message.\n\n\nstdlib.warn \nFoobar", 
            "title": "system"
        }, 
        {
            "location": "/functions/system/#system-functions", 
            "text": "lib/system.sh  contains functions that are considered core to Waffles.    System Functions  stdlib.array_contains  stdlib.array_join  stdlib.array_length  stdlib.array_pop  stdlib.array_push  stdlib.array_shift  stdlib.array_unshift  stdlib.capture_error  stdlib.command_exists  stdlib.data  stdlib.debug  stdlib.debug?  stdlib.debug_mute  stdlib.dir  stdlib.error  stdlib.exec  stdlib.git_profile  stdlib.git_profile_push  stdlib.hash_keys  stdlib.include  stdlib.info  stdlib.mute  stdlib.noop?  stdlib.profile  stdlib.split  stdlib.subtitle  stdlib.title  stdlib.trim  stdlib.warn", 
            "title": "System Functions"
        }, 
        {
            "location": "/functions/system/#stdlibarray_contains", 
            "text": "Reports true if element exists in an array.  x=(foo bar baz)\nif stdlib.array_contains  x   foo  ; then\n  echo  Exists \nfi", 
            "title": "stdlib.array_contains"
        }, 
        {
            "location": "/functions/system/#stdlibarray_join", 
            "text": "Joins an array into a string.  x=(foo bar baz)\nstdlib.array_join x ,\n=  foo,bar,baz", 
            "title": "stdlib.array_join"
        }, 
        {
            "location": "/functions/system/#stdlibarray_length", 
            "text": "Returns the length of an array.  x=(a b c)\nstdlib.array_length x\n=  3", 
            "title": "stdlib.array_length"
        }, 
        {
            "location": "/functions/system/#stdlibarray_pop", 
            "text": "Removes and the last element from array $1 and optionally stores it in $2  x=(a b c)\nstdlib.array_pop x y\necho $y\n=  c", 
            "title": "stdlib.array_pop"
        }, 
        {
            "location": "/functions/system/#stdlibarray_push", 
            "text": "Adds an element to the end of an array.  x=()\nstdlib.array_push x foo", 
            "title": "stdlib.array_push"
        }, 
        {
            "location": "/functions/system/#stdlibarray_shift", 
            "text": "Removes and returns the first element from array $1 and optionally stores it in $2  x=(a b c)\nstdlib.array_shift x y\necho $y\n=  a", 
            "title": "stdlib.array_shift"
        }, 
        {
            "location": "/functions/system/#stdlibarray_unshift", 
            "text": "Adds an element to the beginning of the array.  x=(b c)\nstdlib.array_unshift x a", 
            "title": "stdlib.array_unshift"
        }, 
        {
            "location": "/functions/system/#stdlibcapture_error", 
            "text": "Takes a command as input, prints the command, and detects if anything was written to  stderr . If there was, the error is printed to  stderr  again, and if  WAFFLES_EXIT_ON_ERROR  is set, Waffles halts.  stdlib.capture_error apt-get update", 
            "title": "stdlib.capture_error"
        }, 
        {
            "location": "/functions/system/#stdlibcommand_exists", 
            "text": "A simple wrapper around  which .  if [[ stdlib.command_exists apt-get ]]; then\n  stdlib.info  We're on a Debian-based system. \nfi", 
            "title": "stdlib.command_exists"
        }, 
        {
            "location": "/functions/system/#stdlibdata", 
            "text": "The same as  stdlib.profiles  but the shell scripts can be placed differently:  stdlib.data common =  data/common.sh\nstdlib.data common =  data/common/init.sh\nstdlib.data common/users =  data/common/users.sh\nstdlib.data memcached =  data/memcached.sh\nstdlib.data memcached =  data/memcached/init.sh", 
            "title": "stdlib.data"
        }, 
        {
            "location": "/functions/system/#stdlibdebug", 
            "text": "Prints a log message at  debug  level.  stdlib.debug  Foobar", 
            "title": "stdlib.debug"
        }, 
        {
            "location": "/functions/system/#stdlibdebug_1", 
            "text": "Determines if Waffles is being run in  debug  mode.  if stdlib.debug? ; then\n  stdlib.debug  We're in debug mode. \nfi", 
            "title": "stdlib.debug?"
        }, 
        {
            "location": "/functions/system/#stdlibdebug_mute", 
            "text": "Like  stdlib.mute  but messages only appear in  debug  mode.  stdlib.debug_mute apt-get update", 
            "title": "stdlib.debug_mute"
        }, 
        {
            "location": "/functions/system/#stdlibdir", 
            "text": "A simple function that returns the current directory of the script currently being run.", 
            "title": "stdlib.dir"
        }, 
        {
            "location": "/functions/system/#stdliberror", 
            "text": "Prints an error message to  stderr .  stdlib.error  Foobar", 
            "title": "stdlib.error"
        }, 
        {
            "location": "/functions/system/#stdlibexec", 
            "text": "A simple function that takes a command as input, prints the command, and then executes it.  stdlib.exec apt-get update", 
            "title": "stdlib.exec"
        }, 
        {
            "location": "/functions/system/#stdlibgit_profile", 
            "text": "stdlib.git_profile will check a profile out from a git repository. It will be ignored if running in REMOTE mode, so repositories are only created when Waffles is run locally.  stdlib.git_profile repositories must be named:  waffles-profile-$profile_name  stdlib.git_profiles must follow the following syntax:  stdlib.git_profile https://github.com/jtopjian/waffles-profile-openstack\nstdlib.git_profile https://github.com/jtopjian/waffles-profile-openstack branch dev\nstdlib.git_profile https://github.com/jtopjian/waffles-profile-openstack tag 0.5.1\nstdlib.git_profile https://github.com/jtopjian/waffles-profile-openstack commit 023a83", 
            "title": "stdlib.git_profile"
        }, 
        {
            "location": "/functions/system/#stdlibgit_profile_push", 
            "text": "Works the same way as stdlib.git_profile, but the git repository is downloaded on the Waffles \"server\" and pushed to the node. This is useful in cases when the nodes do not have direct access to the git repository.", 
            "title": "stdlib.git_profile_push"
        }, 
        {
            "location": "/functions/system/#stdlibhash_keys", 
            "text": "Returns the keys of a hash / associative array.  declare -A foo=(\n  [a]=1\n  [b]=2\n  [c]=3\n)\n\nstdlib.hash_keys  foo \n=  a b c\n\nx=($(stdlib.hash_keys  foo ))\necho  ${x[1]} \n=  b", 
            "title": "stdlib.hash_keys"
        }, 
        {
            "location": "/functions/system/#stdlibinclude", 
            "text": "A more intelligent  source . It checks if the file being sourced / included exists, and if not, prints a warning and moves on.", 
            "title": "stdlib.include"
        }, 
        {
            "location": "/functions/system/#stdlibinfo", 
            "text": "Prints a log message at  info  level.  stdlib.info  Foobar", 
            "title": "stdlib.info"
        }, 
        {
            "location": "/functions/system/#stdlibmute", 
            "text": "Prints the command being run, but suppresses the command output.  stdlib.mute apt-get update", 
            "title": "stdlib.mute"
        }, 
        {
            "location": "/functions/system/#stdlibnoop", 
            "text": "Determines if Waffles is being run in  noop  mode.  if stdlib.noop? ; then\n  stdlib.info  We're in noop mode. \nfi", 
            "title": "stdlib.noop?"
        }, 
        {
            "location": "/functions/system/#stdlibprofile", 
            "text": "Takes a profile as input and determines the shell script attached to the profile.  If Waffles is being run locally, then  stdlib.include  is run on the script. If Waffles is being run in push-based mode, then the profile is marked to be copied to the remote node.  stdlib.profiles common/users =  profiles/common/scripts/users.sh\nstdlib.profiles common/packages =  profiles/common/scripts/packages.sh\nstdlib.profiles memcached =  profiles/memcached/scripts/init.sh\nstdlib.profiles memcached/utils =  profiles/memcached/scripts/utils.sh", 
            "title": "stdlib.profile"
        }, 
        {
            "location": "/functions/system/#stdlibsplit", 
            "text": "Splits a string into an array. Stores the result in  __split . The delimiter can be multi-character.  stdlib.split  foo/bar ,  / \nstdlib.info $__split[1] # bar", 
            "title": "stdlib.split"
        }, 
        {
            "location": "/functions/system/#stdlibsubtitle", 
            "text": "Sets a subtitle context. This is usually used internally by resources. An internal counter to determine if the resource was changed:  $ cat profiles/common/scripts/package.sh\nstdlib.title  profiles/common/packages \nstdlib.apt --package sl\n\nif [[ $stdlib_resource_change == true ]]; then\n  stdlib.info  The state of package sl changed \nfi\n\nstdlib.apt --package cowsay\n\nif [[ $stdlib_resource_change == true ]]; then\n  stdlib.info  The state of package cowsay changed \nfi", 
            "title": "stdlib.subtitle"
        }, 
        {
            "location": "/functions/system/#stdlibtitle", 
            "text": "Sets a title context. A title is a major section of Waffles being run; for example, a profile. You usually being profiles by setting a title:  $ cat profiles/common/scripts/package.sh\nstdlib.title  profiles/common/packages \nstdlib.apt --package sl  Internal counters are reset whenever  stdlib.title  is used. This is useful for determining if any changes were made to a resource or the profile as a whole:  $ cat profiles/common/scripts/package.sh\nstdlib.title  profiles/common/packages \nstdlib.apt --package sl\nstdlib.apt --package cowsay\n\nif [[ $stdlib_state_change == true ]]; then\n  stdlib.info  One of the above packages were updated. \nfi", 
            "title": "stdlib.title"
        }, 
        {
            "location": "/functions/system/#stdlibtrim", 
            "text": "Trims the whitespace on both sides of a string.  trimmed=$(stdlib.trim     foobar", 
            "title": "stdlib.trim"
        }, 
        {
            "location": "/functions/system/#stdlibwarn", 
            "text": "Prints a warning message.  stdlib.warn  Foobar", 
            "title": "stdlib.warn"
        }, 
        {
            "location": "/functions/catalog/", 
            "text": "Catalog Functions\n\n\n\n\n\n\nCatalog Functions\n\n\nstdlib.catalog.add\n\n\nstdlib.catalog.exists?\n\n\n\n\n\n\n\n\n\n\nlib/catalog.sh\n contains functions related to the Waffles catalog. The catalog is an inventory of all resources that have been used in a role.\n\n\nAt this time, the catalog is built as Waffles is run. This means that you cannot use the catalog to see what resources will be used in the future.\n\n\nThe catalog is used internally to Waffles.\n\n\nstdlib.catalog.add\n\n\nAdds a resource to the catalog. If a resource of the same type and name exist, Waffles will either:\n\n\n\n\nError and halt if \nWAFFLES_EXIT_ON_DUPLICATE_RESOURCE\n is set.\n\n\nPrint a warning if not.\n\n\n\n\nstdlib.catalog.exists?\n\n\nReturns \ntrue\n or \nfalse\n if a resource is in the catalog.", 
            "title": "catalog"
        }, 
        {
            "location": "/functions/catalog/#catalog-functions", 
            "text": "Catalog Functions  stdlib.catalog.add  stdlib.catalog.exists?      lib/catalog.sh  contains functions related to the Waffles catalog. The catalog is an inventory of all resources that have been used in a role.  At this time, the catalog is built as Waffles is run. This means that you cannot use the catalog to see what resources will be used in the future.  The catalog is used internally to Waffles.", 
            "title": "Catalog Functions"
        }, 
        {
            "location": "/functions/catalog/#stdlibcatalogadd", 
            "text": "Adds a resource to the catalog. If a resource of the same type and name exist, Waffles will either:   Error and halt if  WAFFLES_EXIT_ON_DUPLICATE_RESOURCE  is set.  Print a warning if not.", 
            "title": "stdlib.catalog.add"
        }, 
        {
            "location": "/functions/catalog/#stdlibcatalogexists", 
            "text": "Returns  true  or  false  if a resource is in the catalog.", 
            "title": "stdlib.catalog.exists?"
        }, 
        {
            "location": "/functions/options/", 
            "text": "Options Options\n\n\n\n\n\n\nOptions Options\n\n\nstdlib.options.create_option\n\n\nstdlib.options.create_mv_option\n\n\nstdlib.options.parse_options\n\n\n\n\n\n\n\n\n\n\nlib/options.sh\n contains functions related to parsing resource options.\n\n\nstdlib.options.create_option\n\n\nThis function creates an option in a resource.\n\n\nlocal -A options\nstdlib.options.create_option state   \npresent\n\nstdlib.options.create_option package \n__required__\n\nstdlib.options.create_option version\nstdlib.options.parse_options \n$@\n\n\n\n\n\nTo successfully create a set of options:\n\n\n\n\nA local \noptions\n variable must be created. If not, the options will be appended to the last resource declared.\n\n\nstdlib.options.create_option\n is used with the first argument being the option name and the second argument being an optional default value.\n\n\nIf the default value is \n__required__\n, Waffles will error and halt if the option was not set.\n\n\n\n\nstdlib.options.create_mv_option\n\n\nThis function creates a multi-value option. These types of options can be specified multiple times. In order to use, you must declare\nan array of the same name as the option. For example, the \naugeas.mail_alias\n resource looks like this:\n\n\nlocal -A options\nlocal -a destination\nstdlib.options.create_option    state       \npresent\n\nstdlib.options.create_option    account     \n__required__\n\nstdlib.options.create_mv_option destination \n__required__\n\nstdlib.options.create_option    file        \n/etc/aliases\n\nstdlib.options.parse_options    \n$@\n\n\n\n\n\nNow when declaring an alias, you can do:\n\n\naugeas.mail_alias --root --destination jdoe --destination jsmith --destination foobar\n\n\n\n\nstdlib.options.parse_options\n\n\nThis function cycles through all options that were given in a declared resource. It will report if any required options were not set.", 
            "title": "options"
        }, 
        {
            "location": "/functions/options/#options-options", 
            "text": "Options Options  stdlib.options.create_option  stdlib.options.create_mv_option  stdlib.options.parse_options      lib/options.sh  contains functions related to parsing resource options.", 
            "title": "Options Options"
        }, 
        {
            "location": "/functions/options/#stdliboptionscreate_option", 
            "text": "This function creates an option in a resource.  local -A options\nstdlib.options.create_option state    present \nstdlib.options.create_option package  __required__ \nstdlib.options.create_option version\nstdlib.options.parse_options  $@   To successfully create a set of options:   A local  options  variable must be created. If not, the options will be appended to the last resource declared.  stdlib.options.create_option  is used with the first argument being the option name and the second argument being an optional default value.  If the default value is  __required__ , Waffles will error and halt if the option was not set.", 
            "title": "stdlib.options.create_option"
        }, 
        {
            "location": "/functions/options/#stdliboptionscreate_mv_option", 
            "text": "This function creates a multi-value option. These types of options can be specified multiple times. In order to use, you must declare\nan array of the same name as the option. For example, the  augeas.mail_alias  resource looks like this:  local -A options\nlocal -a destination\nstdlib.options.create_option    state        present \nstdlib.options.create_option    account      __required__ \nstdlib.options.create_mv_option destination  __required__ \nstdlib.options.create_option    file         /etc/aliases \nstdlib.options.parse_options     $@   Now when declaring an alias, you can do:  augeas.mail_alias --root --destination jdoe --destination jsmith --destination foobar", 
            "title": "stdlib.options.create_mv_option"
        }, 
        {
            "location": "/functions/options/#stdliboptionsparse_options", 
            "text": "This function cycles through all options that were given in a declared resource. It will report if any required options were not set.", 
            "title": "stdlib.options.parse_options"
        }, 
        {
            "location": "/functions/resource/", 
            "text": "Resource Functions\n\n\n\n\n\n\nResource Functions\n\n\nstdlib.resource.process\n\n\nstdlib.resource.read\n\n\nstdlib.resource.create\n\n\nstdlib.resource.update\n\n\nstdlib.resource.delete\n\n\n\n\n\n\n\n\n\n\nlib/resource.sh\n contains functions that coordinate resource execution.\n\n\nstdlib.resource.process\n\n\nThis function does several things:\n\n\n\n\nCreates a catalog entry of the resource.\n\n\nCalls \nstdlib.resource.read\n, which in turn calls \ncalling_resource.read\n.\n\n\nCompares the resource state versus the state that the resource has been requested to be in.\n\n\nDepending on the results of the above, calls \nstdlib.resource.x\n, which in turn calls \ncalling_resource.x\n.\n\n\n\n\nThis function requires two arguments:\n\n\n\n\n$1\n: The resource type (\nstdlib.apt\n)\n\n\n$2\n: The resource name (\napache2\n)\n\n\n\n\nstdlib.resource.read\n\n\nCalls \nresource_type.read\n. May also perform pre and post actions.\n\n\nstdlib.resource.create\n\n\nCalls \nresource_type.create\n.\n\n\nAlso flags that a resource has changed and increments the amount of total changes made throughout the Waffles run.\n\n\nstdlib.resource.update\n\n\nCalls \nresource_type.update\n.\n\n\nAlso flags that a resource has changed and increments the amount of total changes made throughout the Waffles run.\n\n\nstdlib.resource.delete\n\n\nCalls \nresource_type.delete\n.\n\n\nAlso flags that a resource has changed and increments the amount of total changes made throughout the Waffles run.", 
            "title": "resource"
        }, 
        {
            "location": "/functions/resource/#resource-functions", 
            "text": "Resource Functions  stdlib.resource.process  stdlib.resource.read  stdlib.resource.create  stdlib.resource.update  stdlib.resource.delete      lib/resource.sh  contains functions that coordinate resource execution.", 
            "title": "Resource Functions"
        }, 
        {
            "location": "/functions/resource/#stdlibresourceprocess", 
            "text": "This function does several things:   Creates a catalog entry of the resource.  Calls  stdlib.resource.read , which in turn calls  calling_resource.read .  Compares the resource state versus the state that the resource has been requested to be in.  Depending on the results of the above, calls  stdlib.resource.x , which in turn calls  calling_resource.x .   This function requires two arguments:   $1 : The resource type ( stdlib.apt )  $2 : The resource name ( apache2 )", 
            "title": "stdlib.resource.process"
        }, 
        {
            "location": "/functions/resource/#stdlibresourceread", 
            "text": "Calls  resource_type.read . May also perform pre and post actions.", 
            "title": "stdlib.resource.read"
        }, 
        {
            "location": "/functions/resource/#stdlibresourcecreate", 
            "text": "Calls  resource_type.create .  Also flags that a resource has changed and increments the amount of total changes made throughout the Waffles run.", 
            "title": "stdlib.resource.create"
        }, 
        {
            "location": "/functions/resource/#stdlibresourceupdate", 
            "text": "Calls  resource_type.update .  Also flags that a resource has changed and increments the amount of total changes made throughout the Waffles run.", 
            "title": "stdlib.resource.update"
        }, 
        {
            "location": "/functions/resource/#stdlibresourcedelete", 
            "text": "Calls  resource_type.delete .  Also flags that a resource has changed and increments the amount of total changes made throughout the Waffles run.", 
            "title": "stdlib.resource.delete"
        }, 
        {
            "location": "/functions/augeas/", 
            "text": "Augeas Functions\n\n\n\n\n\n\nAugeas Functions\n\n\naugeas.run\n\n\naugeas.get\n\n\n\n\n\n\n\n\n\n\nlib/augeas/augeas.sh\n contains helper functions for the Augeas resources. These are all used internally in the Augeas resources and you shouldn't need to use them anywhere else.\n\n\naugeas.run\n\n\nRuns a series of Augeas commands on a file.\n\n\naugeas.get\n\n\nChecks the state of an Augeas-based resource.", 
            "title": "augeas"
        }, 
        {
            "location": "/functions/augeas/#augeas-functions", 
            "text": "Augeas Functions  augeas.run  augeas.get      lib/augeas/augeas.sh  contains helper functions for the Augeas resources. These are all used internally in the Augeas resources and you shouldn't need to use them anywhere else.", 
            "title": "Augeas Functions"
        }, 
        {
            "location": "/functions/augeas/#augeasrun", 
            "text": "Runs a series of Augeas commands on a file.", 
            "title": "augeas.run"
        }, 
        {
            "location": "/functions/augeas/#augeasget", 
            "text": "Checks the state of an Augeas-based resource.", 
            "title": "augeas.get"
        }, 
        {
            "location": "/functions/consul/", 
            "text": "Consul Functions\n\n\n\n\n\n\nConsul Functions\n\n\nconsul.get_nodes\n\n\nconsul.get_services\n\n\nconsul.get_kv\n\n\nconsul.set_kv\n\n\nconsul.delete_kv\n\n\n\n\n\n\n\n\n\n\nlib/consul/consul.sh\n contains helper functions for the Consul resources\n\n\nconsul.get_nodes\n\n\nReturns a list of nodes. Results are stored in \n$consul_nodes\n hash.\n\n\nOption \n--service\n: Optional. Limits results to a set of services.\n\n\nconsul.get_nodes --service consul\n\nconsul_nodes[consul-01]=\n192.168.1.1\n\nconsul_nodes[consul-02]=\n192.168.1.2\n\nconsul_nodes[consul-03]=\n192.168.1.3\n\nconsul_nodes[consul-01|port]=\n8300\n\nconsul_nodes[consul-02|port]=\n8300\n\nconsul_nodes[consul-03|port]=\n8300\n\n\n\n\n\nconsul.get_services\n\n\nReturns a list of services in the Consul catalog. Results are stored in \n$consul_services array\n.\n\n\nconsul.get_services\n\nconsul_services=(consul mysql)\n\n\n\n\nconsul.get_kv\n\n\nRetrieves the value of a key.\n\n\nconsul.get_kv --key foobar\n=\n barfoo\n\n\n\n\nconsul.set_kv\n\n\nSets a value for a key.\n\n\nconsul.set_kv --key foobar --value barfoo\n\n\n\n\nconsul.delete_kv\n\n\nDeletes a key.\n\n\nconsul.delete_kv --key foobar", 
            "title": "consul"
        }, 
        {
            "location": "/functions/consul/#consul-functions", 
            "text": "Consul Functions  consul.get_nodes  consul.get_services  consul.get_kv  consul.set_kv  consul.delete_kv      lib/consul/consul.sh  contains helper functions for the Consul resources", 
            "title": "Consul Functions"
        }, 
        {
            "location": "/functions/consul/#consulget_nodes", 
            "text": "Returns a list of nodes. Results are stored in  $consul_nodes  hash.  Option  --service : Optional. Limits results to a set of services.  consul.get_nodes --service consul\n\nconsul_nodes[consul-01]= 192.168.1.1 \nconsul_nodes[consul-02]= 192.168.1.2 \nconsul_nodes[consul-03]= 192.168.1.3 \nconsul_nodes[consul-01|port]= 8300 \nconsul_nodes[consul-02|port]= 8300 \nconsul_nodes[consul-03|port]= 8300", 
            "title": "consul.get_nodes"
        }, 
        {
            "location": "/functions/consul/#consulget_services", 
            "text": "Returns a list of services in the Consul catalog. Results are stored in  $consul_services array .  consul.get_services\n\nconsul_services=(consul mysql)", 
            "title": "consul.get_services"
        }, 
        {
            "location": "/functions/consul/#consulget_kv", 
            "text": "Retrieves the value of a key.  consul.get_kv --key foobar\n=  barfoo", 
            "title": "consul.get_kv"
        }, 
        {
            "location": "/functions/consul/#consulset_kv", 
            "text": "Sets a value for a key.  consul.set_kv --key foobar --value barfoo", 
            "title": "consul.set_kv"
        }, 
        {
            "location": "/functions/consul/#consuldelete_kv", 
            "text": "Deletes a key.  consul.delete_kv --key foobar", 
            "title": "consul.delete_kv"
        }, 
        {
            "location": "/functions/mysql/", 
            "text": "MySQL Functions\n\n\n\n\n\n\nMySQL Functions\n\n\nmysql.admin_password_set?\n\n\nmysql.mycnf\n\n\n\n\n\n\n\n\n\n\nlib/mysql/mysql.sh\n contains helper functions for the MySQL resources\n\n\nmysql.admin_password_set?\n\n\nA simple function that checks if the MySQL service has an admin password set.\n\n\nmysql.mycnf\n\n\nA function that generates a \n.my.cnf\n file.\n\n\nmysql.mycnf --filename \n/root/.my.cnf\n --user root --password password\n\n\n\n\nThis isn't a first-class resource because it simply builds on other resources.", 
            "title": "mysql"
        }, 
        {
            "location": "/functions/mysql/#mysql-functions", 
            "text": "MySQL Functions  mysql.admin_password_set?  mysql.mycnf      lib/mysql/mysql.sh  contains helper functions for the MySQL resources", 
            "title": "MySQL Functions"
        }, 
        {
            "location": "/functions/mysql/#mysqladmin_password_set", 
            "text": "A simple function that checks if the MySQL service has an admin password set.", 
            "title": "mysql.admin_password_set?"
        }, 
        {
            "location": "/functions/mysql/#mysqlmycnf", 
            "text": "A function that generates a  .my.cnf  file.  mysql.mycnf --filename  /root/.my.cnf  --user root --password password  This isn't a first-class resource because it simply builds on other resources.", 
            "title": "mysql.mycnf"
        }, 
        {
            "location": "/functions/rabbitmq/", 
            "text": "RabbitMQ Options\n\n\n\n\n\n\nRabbitMQ Options\n\n\nrabbitmq.generic_value_create\n\n\nrabbitmq.generic_value_read\n\n\nrabbitmq.generic_value_delete\n\n\nrabbitmq.list_value_create\n\n\nrabbitmq.list_value_read\n\n\nrabbitmq.list_value_delete\n\n\n\n\n\n\n\n\n\n\nlib/rabbitmq/rabbitmq.sh\n contains helper functions for the RabbitMQ resources. You should not need to use these functions directly.\n\n\nrabbitmq.generic_value_create\n\n\nCreates a \"generic\" RabbitMQ config file setting.\n\n\nrabbitmq.generic_value_read\n\n\nReads a \"generic\" RabbitMQ config file setting.\n\n\nrabbitmq.generic_value_delete\n\n\nDeletes a \"generic\" RabbitMQ config file setting.\n\n\nrabbitmq.list_value_create\n\n\nCreates a RabbitMQ config file setting of type \"list\".\n\n\nrabbitmq.list_value_read\n\n\nReads a RabbitMQ config file setting of type \"list\".\n\n\nrabbitmq.list_value_delete\n\n\nDeletes a RabbitMQ config file setting of type \"list\".", 
            "title": "rabbitmq"
        }, 
        {
            "location": "/functions/rabbitmq/#rabbitmq-options", 
            "text": "RabbitMQ Options  rabbitmq.generic_value_create  rabbitmq.generic_value_read  rabbitmq.generic_value_delete  rabbitmq.list_value_create  rabbitmq.list_value_read  rabbitmq.list_value_delete      lib/rabbitmq/rabbitmq.sh  contains helper functions for the RabbitMQ resources. You should not need to use these functions directly.", 
            "title": "RabbitMQ Options"
        }, 
        {
            "location": "/functions/rabbitmq/#rabbitmqgeneric_value_create", 
            "text": "Creates a \"generic\" RabbitMQ config file setting.", 
            "title": "rabbitmq.generic_value_create"
        }, 
        {
            "location": "/functions/rabbitmq/#rabbitmqgeneric_value_read", 
            "text": "Reads a \"generic\" RabbitMQ config file setting.", 
            "title": "rabbitmq.generic_value_read"
        }, 
        {
            "location": "/functions/rabbitmq/#rabbitmqgeneric_value_delete", 
            "text": "Deletes a \"generic\" RabbitMQ config file setting.", 
            "title": "rabbitmq.generic_value_delete"
        }, 
        {
            "location": "/functions/rabbitmq/#rabbitmqlist_value_create", 
            "text": "Creates a RabbitMQ config file setting of type \"list\".", 
            "title": "rabbitmq.list_value_create"
        }, 
        {
            "location": "/functions/rabbitmq/#rabbitmqlist_value_read", 
            "text": "Reads a RabbitMQ config file setting of type \"list\".", 
            "title": "rabbitmq.list_value_read"
        }, 
        {
            "location": "/functions/rabbitmq/#rabbitmqlist_value_delete", 
            "text": "Deletes a RabbitMQ config file setting of type \"list\".", 
            "title": "rabbitmq.list_value_delete"
        }, 
        {
            "location": "/guides/environment-vars/", 
            "text": "Environment Variable Support\n\n\n\n\n\n\nEnvironment Variable Support\n\n\nDescription\n\n\nWAFFLES_NOOP\n\n\nSteps\n\n\nComments\n\n\n\n\n\n\nWAFFLES_DEBUG\n\n\nSteps\n\n\nComments\n\n\n\n\n\n\nTEST\n\n\nSteps\n\n\nComments\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDescription\n\n\nThis guide will show how to alter Waffles's behavior by setting different environment variables.\n\n\nWAFFLES_NOOP\n\n\nno-op stands for \"no operation\". Rather than actually executing commands, it will print what \nwould have\n happened if Waffles was run in normal mode.\n\n\nSteps\n\n\n\n\nRun Waffles with \nWAFFLES_NOOP\n set:\n\n\n\n\n$ WAFFLES_NOOP=1 waffles.sh memcached\n\n\n\n\nComments\n\n\nYou can also use the \n-n\n flag when running Waffles.\n\n\nWAFFLES_DEBUG\n\n\nThis will print extra information about each action. If Waffles is not working correctly, try running in \"debug\" mode and see if you can spot the error.\n\n\nThe output from \"debug\" mode is also the best way to report bugs.\n\n\nSteps\n\n\n\n\nRun Waffles with \nWAFFLES_DEBUG\n set:\n\n\n\n\n$ WAFFLES_DEBUG=1 waffles.sh memcached\n\n\n\n\nComments\n\n\nYou can also use the \n-d\n flag when running Waffles.\n\n\nTEST\n\n\nWhen TEST is set, Waffles will exit 1 if any changes were made. This is useful to verify the previous run was successful because no changes should need to be made upon the second execution.\n\n\nSteps\n\n\n\n\nRun Waffles with \nWAFFLES_TEST\n set:\n\n\n\n\n$ WAFFLES_TEST=1 waffles.sh memcached\n\n\n\n\nComments\n\n\nYou can also use the \n-t\n flag when running Waffles.", 
            "title": "Environment Variables"
        }, 
        {
            "location": "/guides/environment-vars/#environment-variable-support", 
            "text": "Environment Variable Support  Description  WAFFLES_NOOP  Steps  Comments    WAFFLES_DEBUG  Steps  Comments    TEST  Steps  Comments", 
            "title": "Environment Variable Support"
        }, 
        {
            "location": "/guides/environment-vars/#description", 
            "text": "This guide will show how to alter Waffles's behavior by setting different environment variables.", 
            "title": "Description"
        }, 
        {
            "location": "/guides/environment-vars/#waffles_noop", 
            "text": "no-op stands for \"no operation\". Rather than actually executing commands, it will print what  would have  happened if Waffles was run in normal mode.  Steps   Run Waffles with  WAFFLES_NOOP  set:   $ WAFFLES_NOOP=1 waffles.sh memcached  Comments  You can also use the  -n  flag when running Waffles.", 
            "title": "WAFFLES_NOOP"
        }, 
        {
            "location": "/guides/environment-vars/#waffles_debug", 
            "text": "This will print extra information about each action. If Waffles is not working correctly, try running in \"debug\" mode and see if you can spot the error.  The output from \"debug\" mode is also the best way to report bugs.  Steps   Run Waffles with  WAFFLES_DEBUG  set:   $ WAFFLES_DEBUG=1 waffles.sh memcached  Comments  You can also use the  -d  flag when running Waffles.", 
            "title": "WAFFLES_DEBUG"
        }, 
        {
            "location": "/guides/environment-vars/#test", 
            "text": "When TEST is set, Waffles will exit 1 if any changes were made. This is useful to verify the previous run was successful because no changes should need to be made upon the second execution.  Steps   Run Waffles with  WAFFLES_TEST  set:   $ WAFFLES_TEST=1 waffles.sh memcached  Comments  You can also use the  -t  flag when running Waffles.", 
            "title": "TEST"
        }, 
        {
            "location": "/guides/deploying-a-mysql-server/", 
            "text": "Deploying a MySQL Server\n\n\n\n\n\n\nDeploying a MySQL Server\n\n\nDescription\n\n\nSteps\n\n\nData\n\n\nProfiles\n\n\nRoles\n\n\n\n\n\n\nComments and Conclusion\n\n\n\n\n\n\n\n\n\n\nDescription\n\n\nThis guide will show one way of deploying a MySQL server with Waffles. In particular, Percona MySQL.\n\n\nSteps\n\n\nData\n\n\nThere will only be one data item: the MySQL root password. This example will store the password in plain text -- note that a best practice would be to install it either in an encrypted repository, an encrypted string, or something along those lines.\n\n\n$ cat site/data/mysql.sh\ndata_mysql_root_password=\npassword\n\n\n\n\n\nProfiles\n\n\nWe'll use two profile scripts for the MySQL server: the first will configure the Percona repo and the second will install and configure MySQL itself.\n\n\nFirst, make the directory structure\n\n\n$ mkdir -p site/profiles/mysql/scripts\n\n\n\n\nNext, make the repo profile script, located at \nsite/profiles/mysql/scripts/percona_repo.sh\n:\n\n\nstdlib.title \nmysql/percona/repo\n\n\nsource /etc/lsb-release\n\nstdlib.apt_key --name percona --keyserver keys.gnupg.net --key 1C4CBDCDCD2EFD2A\nstdlib.apt_source --name percona --uri http://repo.percona.com/apt --distribution $DISTRIB_CODENAME --component main --include_src true\n\n\n\n\nNext, make the MySQL profile script, located at \nsites/profilfes/mysql/scripts/percona_server.sh\n:\n\n\nstdlib.title \nmysql/percona/server\n\n\nhostname=$(hostname | sed -e 's/_/\\\\\\_/g')\n\nstdlib.apt --package percona-server-server-5.6\n\nmysql.user --user root --host localhost --password password\nmysql.mycnf --filename \n/root/.my.cnf\n --user root --password password\n\nmysql.user --state absent --user root --host 127.0.0.1 --password \n\nmysql.user --state absent --user root --host ::1 --password \n\nmysql.user --state absent --user \n --host localhost --password \n\nmysql.user --state absent --user root --host $hostname --password \n\nmysql.user --state absent --user \n --host $hostname --password \n\n\nmysql.database --state absent --name test\n\nstdlib.ini --file /etc/mysql/my.cnf --section mysqld --option bind-address --value 0.0.0.0\n\nif [[ $stdlib_state_change == true ]]; then\n  /etc/init.d/mysql restart\nfi\n\n\n\n\nThis script is rather simple in concept. Some notes about it:\n\n\n\n\nThe \nhostname\n variable is doing some shell escaping for MySQL commands.\n\n\nA \nroot@localhost\n user is being configured with the password set in the data file.\n\n\nMySQL installs several other default \nroot\n and \"blank\" users. We want to ensure these users are removed.\n\n\nWe also want to ensure that the \ntest\n database is removed.\n\n\nMySQL listens on localhost by default. We want it to listen on all interfaces, so we change the \nbind-address\n setting to \n0.0.0.0\n.\n\n\nThe special variable \n$stdlib_state_change\n will be \ntrue\n if any changes were made at all in the file. If they were, we want to restart the MySQL service. This will not happen if no changes were made.\n\n\n\n\nRoles\n\n\nFinally, combine the above Data and Profiles to build the role, located at \nsite/roles/mysql.sh\n:\n\n\nstdlib.enable_mysql\n\nstdlib.data mysql\n\nstdlib.profile mysql/percona_repo\nstdlib.profile mysql/percona_server\n\n\n\n\nThe \nstdlib.enable_mysql\n function is a special function that will source all of the relevant MySQL functions and resources located under \nlib\n.\n\n\nThe rest of the role should be self-explanatory.\n\n\nComments and Conclusion\n\n\nThe above example describes a simple way of deploying a Percona MySQL server using Waffles. It should be easy enough to modify and add other profiles to make a more well-rounded and robust service for you to use.", 
            "title": "Deploying a MySQL Server"
        }, 
        {
            "location": "/guides/deploying-a-mysql-server/#deploying-a-mysql-server", 
            "text": "Deploying a MySQL Server  Description  Steps  Data  Profiles  Roles    Comments and Conclusion", 
            "title": "Deploying a MySQL Server"
        }, 
        {
            "location": "/guides/deploying-a-mysql-server/#description", 
            "text": "This guide will show one way of deploying a MySQL server with Waffles. In particular, Percona MySQL.", 
            "title": "Description"
        }, 
        {
            "location": "/guides/deploying-a-mysql-server/#steps", 
            "text": "Data  There will only be one data item: the MySQL root password. This example will store the password in plain text -- note that a best practice would be to install it either in an encrypted repository, an encrypted string, or something along those lines.  $ cat site/data/mysql.sh\ndata_mysql_root_password= password   Profiles  We'll use two profile scripts for the MySQL server: the first will configure the Percona repo and the second will install and configure MySQL itself.  First, make the directory structure  $ mkdir -p site/profiles/mysql/scripts  Next, make the repo profile script, located at  site/profiles/mysql/scripts/percona_repo.sh :  stdlib.title  mysql/percona/repo \n\nsource /etc/lsb-release\n\nstdlib.apt_key --name percona --keyserver keys.gnupg.net --key 1C4CBDCDCD2EFD2A\nstdlib.apt_source --name percona --uri http://repo.percona.com/apt --distribution $DISTRIB_CODENAME --component main --include_src true  Next, make the MySQL profile script, located at  sites/profilfes/mysql/scripts/percona_server.sh :  stdlib.title  mysql/percona/server \n\nhostname=$(hostname | sed -e 's/_/\\\\\\_/g')\n\nstdlib.apt --package percona-server-server-5.6\n\nmysql.user --user root --host localhost --password password\nmysql.mycnf --filename  /root/.my.cnf  --user root --password password\n\nmysql.user --state absent --user root --host 127.0.0.1 --password  \nmysql.user --state absent --user root --host ::1 --password  \nmysql.user --state absent --user   --host localhost --password  \nmysql.user --state absent --user root --host $hostname --password  \nmysql.user --state absent --user   --host $hostname --password  \n\nmysql.database --state absent --name test\n\nstdlib.ini --file /etc/mysql/my.cnf --section mysqld --option bind-address --value 0.0.0.0\n\nif [[ $stdlib_state_change == true ]]; then\n  /etc/init.d/mysql restart\nfi  This script is rather simple in concept. Some notes about it:   The  hostname  variable is doing some shell escaping for MySQL commands.  A  root@localhost  user is being configured with the password set in the data file.  MySQL installs several other default  root  and \"blank\" users. We want to ensure these users are removed.  We also want to ensure that the  test  database is removed.  MySQL listens on localhost by default. We want it to listen on all interfaces, so we change the  bind-address  setting to  0.0.0.0 .  The special variable  $stdlib_state_change  will be  true  if any changes were made at all in the file. If they were, we want to restart the MySQL service. This will not happen if no changes were made.   Roles  Finally, combine the above Data and Profiles to build the role, located at  site/roles/mysql.sh :  stdlib.enable_mysql\n\nstdlib.data mysql\n\nstdlib.profile mysql/percona_repo\nstdlib.profile mysql/percona_server  The  stdlib.enable_mysql  function is a special function that will source all of the relevant MySQL functions and resources located under  lib .  The rest of the role should be self-explanatory.", 
            "title": "Steps"
        }, 
        {
            "location": "/guides/deploying-a-mysql-server/#comments-and-conclusion", 
            "text": "The above example describes a simple way of deploying a Percona MySQL server using Waffles. It should be easy enough to modify and add other profiles to make a more well-rounded and robust service for you to use.", 
            "title": "Comments and Conclusion"
        }, 
        {
            "location": "/guides/deploying-a-mysql-galera-cluster/", 
            "text": "Deploying a MySQL Galera Cluster\n\n\n\n\n\n\nDeploying a MySQL Galera Cluster\n\n\nDescription\n\n\nSteps\n\n\nData\n\n\nProfiles\n\n\nRoles\n\n\n\n\n\n\nRun\n\n\nComments and Conclusion\n\n\n\n\n\n\n\n\n\n\nDescription\n\n\nThis guide will show one way of deploying a MySQL Galera cluster with Waffles. In particular, Percona XtraDB Cluster.\n\n\nSteps\n\n\nData\n\n\nThe data file will contain a few items:\n\n\n\n\nThe MySQL root password\n\n\nThe SST password\n\n\nThe name of the node which will act as the \"bootstrap\" node.\n\n\n\n\nThis example will store the password in plain text -- note that a best practice would be to install it either in an encrypted repository, an encrypted string, or something along those lines.\n\n\n$ cat site/data/mysql.sh\ndata_mysql_root_password=\npassword\n\ndata_mysql_sst_password=\npassword\n\ndata_galera_bootstrap_node=\nmysql-01\n\n\n\n\n\nProfiles\n\n\nWe'll use two profile scripts for the Galera cluster: the first will configure the Percona repo and the second will install and configure MySQL and Galera.\n\n\nFirst, make the directory structure\n\n\n$ mkdir -p site/profiles/mysql/scripts\n\n\n\n\nNext, make the repo profile script, located at \nsite/profiles/mysql/scripts/percona_repo.sh\n:\n\n\nstdlib.title \nmysql/percona/repo\n\n\nsource /etc/lsb-release\n\nstdlib.apt_key --name percona --keyserver keys.gnupg.net --key 1C4CBDCDCD2EFD2A\nstdlib.apt_source --name percona --uri http://repo.percona.com/apt --distribution $DISTRIB_CODENAME --component main --include_src true\n\n\n\n\nNext, make the MySQL profile script, located at \nsites/profiles/mysql/scripts/percona_xtradb_cluster.sh\n:\n\n\nstdlib.title \nmysql/percona/xtradb-cluster\n\n\n# Get some information useful for the configuration\nhostname=$(hostname)\nmysql_hostname=$(hostname | sed -e 's/_/\\\\\\_/g')\nmy_ip=$(/sbin/ifconfig eth0 | grep 'inet addr:' | cut -d: -f2 | awk '{ print $1}')\n\n# Install the percona cluster package\nstdlib.apt --package percona-xtradb-cluster-56\n\n# Record of the MySQL sysv service\nstdlib.sysvinit --name mysql\n\n# Configure the MySQL root user\nmysql.user --user root --host localhost --password \n$data_mysql_root_password\n\nmysql.mycnf --filename \n/root/.my.cnf\n --user root --password \n$data_mysql_root_password\n\n\n# Remove some of the default accounts\nmysql.user --state absent --user root --host 127.0.0.1 --password \n\nmysql.user --state absent --user root --host ::1 --password \n\nmysql.user --state absent --user \n --host localhost --password \n\nmysql.user --state absent --user root --host $mysql_hostname --password \n\nmysql.user --state absent --user \n --host $mysql_hostname --password \n\n\n# Create the sst user\nmysql.user --user sst --host localhost --password \n$data_mysql_sst_password\n\nmysql.grant --user sst --host localhost --database \n*\n --privileges \nRELOAD, LOCK TABLES, REPLICATION CLIENT\n\n\n# Configure `/etc/mysql/my.cnf`\nstdlib.ini --file /etc/mysql/my.cnf --section mysqld --option wsrep_provider --value /usr/lib/libgalera_smm.so\nstdlib.ini --file /etc/mysql/my.cnf --section mysqld --option wsrep_sst_method --value xtrabackup-v2\nstdlib.ini --file /etc/mysql/my.cnf --section mysqld --option binlog_format --value ROW\nstdlib.ini --file /etc/mysql/my.cnf --section mysqld --option default_storage_engine --value InnoDB\nstdlib.ini --file /etc/mysql/my.cnf --section mysqld --option innodb_autoinc_lock_mode --value 2\nstdlib.ini --file /etc/mysql/my.cnf --section mysqld --option wsrep_node_address --value $my_ip\nstdlib.ini --file /etc/mysql/my.cnf --section mysqld --option wsrep_cluster_name --value my_cluster\nstdlib.ini --file /etc/mysql/my.cnf --section mysqld --option wsrep_sst_auth --value \nsst:${data_mysql_sst_password}\n\n\n# If the hostname is config_galera1, do not set gcomm\nif [[ $hostname == $data_galera_bootstrap_node ]]; then\n  stdlib.ini --file /etc/mysql/my.cnf --section mysqld --option wsrep_cluster_address --value \ngcomm://\n\nelse\n  stdlib.ini --file /etc/mysql/my.cnf --section mysqld --option wsrep_cluster_address --value \ngcomm://mysql-01,mysql-02,mysql-03\n\nfi\n\n# If any of the above settings changed, restart MySQL\nif [[ $stdlib_state_change == true ]]; then\n  /etc/init.d/mysql restart\nfi\n\n\n\n\nThis script may be a little long, but it shouldn't be difficult to understand. Some notes about it:\n\n\n\n\nThe \nhostname\n is captured to determine if the node should be the bootstrap node. It's also used for some MySQL configuration.\n\n\nA \nroot@localhost\n user is being configured with the password set in the data file.\n\n\nMySQL installs several other default \nroot\n and \"blank\" users. We want to ensure these users are removed.\n\n\nWe also want to ensure that the \ntest\n database is removed.\n\n\nMySQL listens on localhost by default. We want it to listen on all interfaces, so we change the \nbind-address\n setting to \n0.0.0.0\n.\n\n\nThe \nstdlib.ini\n resources are configuring MySQL, wsrep, and SST.\n\n\nIf the node is the bootstrap node, the \nwsrep_cluster_address\n is set to the special \ngcomm://\n. If not, it is set to all other nodes in the cluster. Once the cluster has been bootstrapped, you should remove the \nif\n conditional and only leave the \nelse\n portion.\n\n\nThe special variable \n$stdlib_state_change\n will be \ntrue\n if any changes were made at all in the file. If they were, we want to restart the MySQL service. This will not happen if no changes were made.\n\n\n\n\nRoles\n\n\nFinally, combine the above Data and Profiles to build the role, located at \nsite/roles/mysql.sh\n:\n\n\nstdlib.enable_mysql\n\nstdlib.data mysql\n\nstdlib.profile mysql/percona_repo\nstdlib.profile mysql/percona_xtradb_cluster\n\n\n\n\nThe \nstdlib.enable_mysql\n function is a special function that will source all of the relevant MySQL functions and resources located under \nlib\n.\n\n\nThe rest of the role should be self-explanatory.\n\n\nRun\n\n\nYou should now run this against 3 servers, containers, or virtual machines of your choice. The bootstrap node must be run and completed before all others.\n\n\nComments and Conclusion\n\n\nThe above example describes a simple way of deploying a Percona MySQL Galera cluster using Waffles. It should be easy enough to modify and add other profiles to make a more well-rounded and robust service for you to use.\n\n\nPlease be aware that \nmysql-01\n, \nmysql-02\n, and \nmysql-03\n are all hostnames that can be resolved. If you are unable to add these to a DNS service, use IP addresses for testing.", 
            "title": "Deploying a MySQL Galera Cluster"
        }, 
        {
            "location": "/guides/deploying-a-mysql-galera-cluster/#deploying-a-mysql-galera-cluster", 
            "text": "Deploying a MySQL Galera Cluster  Description  Steps  Data  Profiles  Roles    Run  Comments and Conclusion", 
            "title": "Deploying a MySQL Galera Cluster"
        }, 
        {
            "location": "/guides/deploying-a-mysql-galera-cluster/#description", 
            "text": "This guide will show one way of deploying a MySQL Galera cluster with Waffles. In particular, Percona XtraDB Cluster.", 
            "title": "Description"
        }, 
        {
            "location": "/guides/deploying-a-mysql-galera-cluster/#steps", 
            "text": "Data  The data file will contain a few items:   The MySQL root password  The SST password  The name of the node which will act as the \"bootstrap\" node.   This example will store the password in plain text -- note that a best practice would be to install it either in an encrypted repository, an encrypted string, or something along those lines.  $ cat site/data/mysql.sh\ndata_mysql_root_password= password \ndata_mysql_sst_password= password \ndata_galera_bootstrap_node= mysql-01   Profiles  We'll use two profile scripts for the Galera cluster: the first will configure the Percona repo and the second will install and configure MySQL and Galera.  First, make the directory structure  $ mkdir -p site/profiles/mysql/scripts  Next, make the repo profile script, located at  site/profiles/mysql/scripts/percona_repo.sh :  stdlib.title  mysql/percona/repo \n\nsource /etc/lsb-release\n\nstdlib.apt_key --name percona --keyserver keys.gnupg.net --key 1C4CBDCDCD2EFD2A\nstdlib.apt_source --name percona --uri http://repo.percona.com/apt --distribution $DISTRIB_CODENAME --component main --include_src true  Next, make the MySQL profile script, located at  sites/profiles/mysql/scripts/percona_xtradb_cluster.sh :  stdlib.title  mysql/percona/xtradb-cluster \n\n# Get some information useful for the configuration\nhostname=$(hostname)\nmysql_hostname=$(hostname | sed -e 's/_/\\\\\\_/g')\nmy_ip=$(/sbin/ifconfig eth0 | grep 'inet addr:' | cut -d: -f2 | awk '{ print $1}')\n\n# Install the percona cluster package\nstdlib.apt --package percona-xtradb-cluster-56\n\n# Record of the MySQL sysv service\nstdlib.sysvinit --name mysql\n\n# Configure the MySQL root user\nmysql.user --user root --host localhost --password  $data_mysql_root_password \nmysql.mycnf --filename  /root/.my.cnf  --user root --password  $data_mysql_root_password \n\n# Remove some of the default accounts\nmysql.user --state absent --user root --host 127.0.0.1 --password  \nmysql.user --state absent --user root --host ::1 --password  \nmysql.user --state absent --user   --host localhost --password  \nmysql.user --state absent --user root --host $mysql_hostname --password  \nmysql.user --state absent --user   --host $mysql_hostname --password  \n\n# Create the sst user\nmysql.user --user sst --host localhost --password  $data_mysql_sst_password \nmysql.grant --user sst --host localhost --database  *  --privileges  RELOAD, LOCK TABLES, REPLICATION CLIENT \n\n# Configure `/etc/mysql/my.cnf`\nstdlib.ini --file /etc/mysql/my.cnf --section mysqld --option wsrep_provider --value /usr/lib/libgalera_smm.so\nstdlib.ini --file /etc/mysql/my.cnf --section mysqld --option wsrep_sst_method --value xtrabackup-v2\nstdlib.ini --file /etc/mysql/my.cnf --section mysqld --option binlog_format --value ROW\nstdlib.ini --file /etc/mysql/my.cnf --section mysqld --option default_storage_engine --value InnoDB\nstdlib.ini --file /etc/mysql/my.cnf --section mysqld --option innodb_autoinc_lock_mode --value 2\nstdlib.ini --file /etc/mysql/my.cnf --section mysqld --option wsrep_node_address --value $my_ip\nstdlib.ini --file /etc/mysql/my.cnf --section mysqld --option wsrep_cluster_name --value my_cluster\nstdlib.ini --file /etc/mysql/my.cnf --section mysqld --option wsrep_sst_auth --value  sst:${data_mysql_sst_password} \n\n# If the hostname is config_galera1, do not set gcomm\nif [[ $hostname == $data_galera_bootstrap_node ]]; then\n  stdlib.ini --file /etc/mysql/my.cnf --section mysqld --option wsrep_cluster_address --value  gcomm:// \nelse\n  stdlib.ini --file /etc/mysql/my.cnf --section mysqld --option wsrep_cluster_address --value  gcomm://mysql-01,mysql-02,mysql-03 \nfi\n\n# If any of the above settings changed, restart MySQL\nif [[ $stdlib_state_change == true ]]; then\n  /etc/init.d/mysql restart\nfi  This script may be a little long, but it shouldn't be difficult to understand. Some notes about it:   The  hostname  is captured to determine if the node should be the bootstrap node. It's also used for some MySQL configuration.  A  root@localhost  user is being configured with the password set in the data file.  MySQL installs several other default  root  and \"blank\" users. We want to ensure these users are removed.  We also want to ensure that the  test  database is removed.  MySQL listens on localhost by default. We want it to listen on all interfaces, so we change the  bind-address  setting to  0.0.0.0 .  The  stdlib.ini  resources are configuring MySQL, wsrep, and SST.  If the node is the bootstrap node, the  wsrep_cluster_address  is set to the special  gcomm:// . If not, it is set to all other nodes in the cluster. Once the cluster has been bootstrapped, you should remove the  if  conditional and only leave the  else  portion.  The special variable  $stdlib_state_change  will be  true  if any changes were made at all in the file. If they were, we want to restart the MySQL service. This will not happen if no changes were made.   Roles  Finally, combine the above Data and Profiles to build the role, located at  site/roles/mysql.sh :  stdlib.enable_mysql\n\nstdlib.data mysql\n\nstdlib.profile mysql/percona_repo\nstdlib.profile mysql/percona_xtradb_cluster  The  stdlib.enable_mysql  function is a special function that will source all of the relevant MySQL functions and resources located under  lib .  The rest of the role should be self-explanatory.", 
            "title": "Steps"
        }, 
        {
            "location": "/guides/deploying-a-mysql-galera-cluster/#run", 
            "text": "You should now run this against 3 servers, containers, or virtual machines of your choice. The bootstrap node must be run and completed before all others.", 
            "title": "Run"
        }, 
        {
            "location": "/guides/deploying-a-mysql-galera-cluster/#comments-and-conclusion", 
            "text": "The above example describes a simple way of deploying a Percona MySQL Galera cluster using Waffles. It should be easy enough to modify and add other profiles to make a more well-rounded and robust service for you to use.  Please be aware that  mysql-01 ,  mysql-02 , and  mysql-03  are all hostnames that can be resolved. If you are unable to add these to a DNS service, use IP addresses for testing.", 
            "title": "Comments and Conclusion"
        }, 
        {
            "location": "/guides/deploying-a-consul-cluster/", 
            "text": "Deploying a Consul Cluster\n\n\n\n\n\n\nDeploying a Consul Cluster\n\n\nDescription\n\n\nSteps\n\n\nData\n\n\nProfiles\n\n\nBase Packages\n\n\nConsul\n\n\nAugeas\n\n\n\n\n\n\nRoles\n\n\n\n\n\n\nRun\n\n\nComments and Conclusion\n\n\n\n\n\n\n\n\n\n\nDescription\n\n\nThis guide will show one way of deploying a Consul cluster with Waffles.\n\n\nSteps\n\n\nData\n\n\nThe data file will have the version of Consul to install, a secret key for the cluster, the nodes that are in the cluster, and an associative array of Consul settings.\n\n\n$ cat site/data/consul.sh\n# Consul Version\ndata_consul_version=\n0.5.2\n\n\n# Secret key\ndata_consul_key=\njXwOaTXJFf4//4QGrpONBg==\n\n\n# Nodes in the cluster\ndata_consul_nodes=(\n  consul-01\n  consul-02\n  consul-03\n)\n\n# Bootstrap node\ndata_consul_bootstrap_node=\nconsul-03\n\n\n# Consul config\ndeclare -Ag data_consul_config\ndata_consul_config=(\n  [server]=\ntrue\n\n  [bootstrap_expect]=\n${#data_consul_nodes[@]}\n\n  [client_addr]=\n0.0.0.0\n\n  [datacenter]=\nhonolulu\n\n  [data_dir]=\n/var/lib/consul\n\n  [encrypt]=\n${data_consul_key}\n\n  [enable_syslog]=\ntrue\n\n  [log_level]=\nINFO\n\n)\n\n\n\n\nProfiles\n\n\nBase Packages\n\n\nIn order to successfully execute the other profiles, we'll need to ensure the Consul server has a few base packages installed. Create \nsite/profiles/common/scripts/packages.sh\n with the following contents:\n\n\nstdlib.apt --package wget\nstdlib.apt --package software-properties-common\n\n\n\n\nConsul\n\n\nWe'll use two profile scripts for the Consul cluster: the first will install Consul and the second will set up the Consul cluster.\n\n\nFirst, make the directory structure\n\n\n$ mkdir -p site/profiles/consul/scripts\n\n\n\n\nNext, make the repo profile script, located at \nsite/profiles/consul/scripts/install.sh\n:\n\n\nstdlib.title \nprofiles/consul/install\n\n\nstdlib.apt --package unzip\n\nstdlib.useradd --user consul --homedir /var/lib/consul --createhome true\nstdlib.directory --name /etc/consul.d --owner consul --group consul\n\nif [[ ! -f /usr/local/bin/consul ]]; then\n  stdlib.mute pushd /tmp\n  stdlib.capture_error wget https://dl.bintray.com/mitchellh/consul/${data_consul_version}_linux_amd64.zip\n  stdlib.capture_error unzip ${data_consul_version}_linux_amd64.zip\n  stdlib.capture_error mv consul /usr/local/bin\n  stdlib.mute popd\nfi\n\n\n\n\nThis install script is rather simple. It's doing the following:\n\n\n\n\nInstalls the \nunzip\n package\n\n\nCreates a \nconsul\n system user with a homedir of \n/var/lib/consul\n\n\nDownloads the Consul binary of the version we specified in the data\n\n\nUnzips it and installs it to \n/usr/local/bin\n.\n\n\n\n\nNote: the way this script determines if Consul is installed is by the presence of the \n/usr/local/bin/consul\n file. If this method is too simplistic for you, feel free to package Consul into a \ndeb\n or \nrpm\n package.\n\n\nNext, make the Consul server script, located at \nsites/profiles/consul/scripts/server.sh\n:\n\n\nstdlib.title \nprofiles/consul/server\n\n\nstdlib.file --name /etc/init/consul.conf --source \n$WAFFLES_SITE_DIR/profiles/consul/files/consul.conf\n\n\nfor key in \n${!data_consul_config[@]}\n; do\n  augeas.json_dict --file /etc/consul.d/config.json --path / --key \n$key\n --value \n${data_consul_config[$key]}\n\ndone\n\nstdlib.upstart --name consul --state running\n\nhostname=$(hostname)\nif [[ $hostname == $data_consul_bootstrap_node ]]; then\n  sleep 10\n  for i in \n${data_consul_nodes[@]}\n; do\n    if [[ $hostname != $i ]]; then\n      /usr/local/bin/consul join $i\n    fi\n  done\nfi\n\n\n\n\n\nHere are some notes on the above:\n\n\n\n\nstdlib.file\n is able to copy a static file from \nsite/profiles/consul/files\n. It is \nhighly\n recommended to bundle your static files into the profile that they are being called from. This ensures that they get copied to the remote node during remote deployment. Alternatively, while there are not yet resources for commands such as \nscp\n or \nwget\n, you could use them similarly to how the Consul zip file was downloaded.\n\n\naugeas.json_dict\n is an Augeas-based resource that allows JSON files to be built on the command-line. In order to use Augeas, it must be installed. See the next section.\n\n\nstdlib.upstart\n ensures that the Consul service is running.\n\n\nFinally, the \nfor\n loop will run if the node is the bootstrap node. It'll loop through all other existing nodes and join them. The existing nodes must be up and running first, which is why the bootstrap node was set to the last node in the cluster.\n\n\n\n\nFinally, create \nsite/profiles/consul/files/consul.conf\n with the following content:\n\n\ndescription \nConsul agent\n\n\nstart on runlevel [2345]\nstop on runlevel [!2345]\n\nrespawn\n\nscript\n  if [ -f \n/etc/default/consul\n ]; then\n    # Gives us the CONSUL_FLAGS variable\n    . /etc/default/consul\n  fi\n\n  # Make sure to use all our CPUs, because Consul can block a scheduler thread\n  export GOMAXPROCS=`nproc`\n\n  exec /usr/local/bin/consul agent \\\n    -config-dir=\n/etc/consul.d\n \\\n    ${CONSUL_FLAGS} \\\n    \n/var/log/consul.log 2\n1\nend script\n\n\n\n\nAugeas\n\n\nTo install Augeas, create \nsite/profiles/augeas/scripts/install_apt.sh\n with the following content:\n\n\nstdlib.title \nprofiles/augeas/install_apt\n\n\nstdlib.apt_ppa --ppa raphink/augeas\nstdlib.apt --package augeas-tools --version latest\n\n\n\n\nRoles\n\n\nFinally, combine the above Data and Profiles to build the role, located at \nsite/roles/consul.sh\n:\n\n\nstdlib.enable_augeas\n\nstdlib.data consul\n\nstdlib.profile common/packages\nstdlib.profile augeas/install_apt\nstdlib.profile consul/install\nstdlib.profile consul/server\n\n\n\n\nThe \nstdlib.enable_augeas\n function is a special function that will source all of the relevant Augeas functions and resources located under \nlib\n.\n\n\nThe rest of the role should be self-explanatory.\n\n\nRun\n\n\nYou should now run this against 3 servers, containers, or virtual machines of your choice.\n\n\nComments and Conclusion\n\n\nThe above example describes a simple way of deploying a Consul cluster using Waffles. It should be easy enough to modify and add other profiles to make a more well-rounded and robust service for you to use.\n\n\nPlease be aware that \nconsul-01\n, \nconsul-02\n, and \nconsul-03\n are all hostnames that can be resolved. If you are unable to add these to a DNS service, use IP addresses for testing.", 
            "title": "Deploying a Consul Cluster"
        }, 
        {
            "location": "/guides/deploying-a-consul-cluster/#deploying-a-consul-cluster", 
            "text": "Deploying a Consul Cluster  Description  Steps  Data  Profiles  Base Packages  Consul  Augeas    Roles    Run  Comments and Conclusion", 
            "title": "Deploying a Consul Cluster"
        }, 
        {
            "location": "/guides/deploying-a-consul-cluster/#description", 
            "text": "This guide will show one way of deploying a Consul cluster with Waffles.", 
            "title": "Description"
        }, 
        {
            "location": "/guides/deploying-a-consul-cluster/#steps", 
            "text": "Data  The data file will have the version of Consul to install, a secret key for the cluster, the nodes that are in the cluster, and an associative array of Consul settings.  $ cat site/data/consul.sh\n# Consul Version\ndata_consul_version= 0.5.2 \n\n# Secret key\ndata_consul_key= jXwOaTXJFf4//4QGrpONBg== \n\n# Nodes in the cluster\ndata_consul_nodes=(\n  consul-01\n  consul-02\n  consul-03\n)\n\n# Bootstrap node\ndata_consul_bootstrap_node= consul-03 \n\n# Consul config\ndeclare -Ag data_consul_config\ndata_consul_config=(\n  [server]= true \n  [bootstrap_expect]= ${#data_consul_nodes[@]} \n  [client_addr]= 0.0.0.0 \n  [datacenter]= honolulu \n  [data_dir]= /var/lib/consul \n  [encrypt]= ${data_consul_key} \n  [enable_syslog]= true \n  [log_level]= INFO \n)  Profiles  Base Packages  In order to successfully execute the other profiles, we'll need to ensure the Consul server has a few base packages installed. Create  site/profiles/common/scripts/packages.sh  with the following contents:  stdlib.apt --package wget\nstdlib.apt --package software-properties-common  Consul  We'll use two profile scripts for the Consul cluster: the first will install Consul and the second will set up the Consul cluster.  First, make the directory structure  $ mkdir -p site/profiles/consul/scripts  Next, make the repo profile script, located at  site/profiles/consul/scripts/install.sh :  stdlib.title  profiles/consul/install \n\nstdlib.apt --package unzip\n\nstdlib.useradd --user consul --homedir /var/lib/consul --createhome true\nstdlib.directory --name /etc/consul.d --owner consul --group consul\n\nif [[ ! -f /usr/local/bin/consul ]]; then\n  stdlib.mute pushd /tmp\n  stdlib.capture_error wget https://dl.bintray.com/mitchellh/consul/${data_consul_version}_linux_amd64.zip\n  stdlib.capture_error unzip ${data_consul_version}_linux_amd64.zip\n  stdlib.capture_error mv consul /usr/local/bin\n  stdlib.mute popd\nfi  This install script is rather simple. It's doing the following:   Installs the  unzip  package  Creates a  consul  system user with a homedir of  /var/lib/consul  Downloads the Consul binary of the version we specified in the data  Unzips it and installs it to  /usr/local/bin .   Note: the way this script determines if Consul is installed is by the presence of the  /usr/local/bin/consul  file. If this method is too simplistic for you, feel free to package Consul into a  deb  or  rpm  package.  Next, make the Consul server script, located at  sites/profiles/consul/scripts/server.sh :  stdlib.title  profiles/consul/server \n\nstdlib.file --name /etc/init/consul.conf --source  $WAFFLES_SITE_DIR/profiles/consul/files/consul.conf \n\nfor key in  ${!data_consul_config[@]} ; do\n  augeas.json_dict --file /etc/consul.d/config.json --path / --key  $key  --value  ${data_consul_config[$key]} \ndone\n\nstdlib.upstart --name consul --state running\n\nhostname=$(hostname)\nif [[ $hostname == $data_consul_bootstrap_node ]]; then\n  sleep 10\n  for i in  ${data_consul_nodes[@]} ; do\n    if [[ $hostname != $i ]]; then\n      /usr/local/bin/consul join $i\n    fi\n  done\nfi  Here are some notes on the above:   stdlib.file  is able to copy a static file from  site/profiles/consul/files . It is  highly  recommended to bundle your static files into the profile that they are being called from. This ensures that they get copied to the remote node during remote deployment. Alternatively, while there are not yet resources for commands such as  scp  or  wget , you could use them similarly to how the Consul zip file was downloaded.  augeas.json_dict  is an Augeas-based resource that allows JSON files to be built on the command-line. In order to use Augeas, it must be installed. See the next section.  stdlib.upstart  ensures that the Consul service is running.  Finally, the  for  loop will run if the node is the bootstrap node. It'll loop through all other existing nodes and join them. The existing nodes must be up and running first, which is why the bootstrap node was set to the last node in the cluster.   Finally, create  site/profiles/consul/files/consul.conf  with the following content:  description  Consul agent \n\nstart on runlevel [2345]\nstop on runlevel [!2345]\n\nrespawn\n\nscript\n  if [ -f  /etc/default/consul  ]; then\n    # Gives us the CONSUL_FLAGS variable\n    . /etc/default/consul\n  fi\n\n  # Make sure to use all our CPUs, because Consul can block a scheduler thread\n  export GOMAXPROCS=`nproc`\n\n  exec /usr/local/bin/consul agent \\\n    -config-dir= /etc/consul.d  \\\n    ${CONSUL_FLAGS} \\\n     /var/log/consul.log 2 1\nend script  Augeas  To install Augeas, create  site/profiles/augeas/scripts/install_apt.sh  with the following content:  stdlib.title  profiles/augeas/install_apt \n\nstdlib.apt_ppa --ppa raphink/augeas\nstdlib.apt --package augeas-tools --version latest  Roles  Finally, combine the above Data and Profiles to build the role, located at  site/roles/consul.sh :  stdlib.enable_augeas\n\nstdlib.data consul\n\nstdlib.profile common/packages\nstdlib.profile augeas/install_apt\nstdlib.profile consul/install\nstdlib.profile consul/server  The  stdlib.enable_augeas  function is a special function that will source all of the relevant Augeas functions and resources located under  lib .  The rest of the role should be self-explanatory.", 
            "title": "Steps"
        }, 
        {
            "location": "/guides/deploying-a-consul-cluster/#run", 
            "text": "You should now run this against 3 servers, containers, or virtual machines of your choice.", 
            "title": "Run"
        }, 
        {
            "location": "/guides/deploying-a-consul-cluster/#comments-and-conclusion", 
            "text": "The above example describes a simple way of deploying a Consul cluster using Waffles. It should be easy enough to modify and add other profiles to make a more well-rounded and robust service for you to use.  Please be aware that  consul-01 ,  consul-02 , and  consul-03  are all hostnames that can be resolved. If you are unable to add these to a DNS service, use IP addresses for testing.", 
            "title": "Comments and Conclusion"
        }, 
        {
            "location": "/guides/override-data/", 
            "text": "Override Data\n\n\n\n\n\n\nOverride Data\n\n\nDescription\n\n\nSteps\n\n\nComments\n\n\n\n\n\n\n\n\n\n\nDescription\n\n\nThis guide will show how to easily override data in two different data files\n\n\nSteps\n\n\n\n\nCreate the initial data file:\n\n\n\n\n$ cat site/data/common.sh \nEOF\ndata_memcached_uid=\n999\n\nEOF\n\n\n\n\n\n\nCreate the second data file:\n\n\n\n\n$ cat site/data/memcached.sh \nEOF\ndata_memcached_uid=\n700\n\nEOF\n\n\n\n\n\n\nAdd both data files to your role. The file called last will take precedence:\n\n\n\n\nsite.data common\nsite.data memcached\n\n\n\n\nComments\n\n\nThis is useful for when you want to keep data that can be used across multiple roles in a single file, but some roles need individual pieces of data overridden. A common case for this is when you are introducing a configuration management system into an existing environment and something like user UIDs have not been made standard.", 
            "title": "Overriding Data"
        }, 
        {
            "location": "/guides/override-data/#override-data", 
            "text": "Override Data  Description  Steps  Comments", 
            "title": "Override Data"
        }, 
        {
            "location": "/guides/override-data/#description", 
            "text": "This guide will show how to easily override data in two different data files", 
            "title": "Description"
        }, 
        {
            "location": "/guides/override-data/#steps", 
            "text": "Create the initial data file:   $ cat site/data/common.sh  EOF\ndata_memcached_uid= 999 \nEOF   Create the second data file:   $ cat site/data/memcached.sh  EOF\ndata_memcached_uid= 700 \nEOF   Add both data files to your role. The file called last will take precedence:   site.data common\nsite.data memcached", 
            "title": "Steps"
        }, 
        {
            "location": "/guides/override-data/#comments", 
            "text": "This is useful for when you want to keep data that can be used across multiple roles in a single file, but some roles need individual pieces of data overridden. A common case for this is when you are introducing a configuration management system into an existing environment and something like user UIDs have not been made standard.", 
            "title": "Comments"
        }, 
        {
            "location": "/guides/referencing-data-from-data/", 
            "text": "Referencing Data from Data Files\n\n\n\n\n\n\nReferencing Data from Data Files\n\n\nDescription\n\n\nSteps\n\n\nComments\n\n\n\n\n\n\n\n\n\n\nDescription\n\n\nThis guide will show how you can reference previously declared data in subsequent data files.\n\n\nSteps\n\n\n\n\nCreate an initial data file:\n\n\n\n\n$ cat \n site/data/common.sh \nEOF\ndata_common_packages=(\n  \nvim\n\n  \ntmux\n\n)\nEOF\n\n\n\n\n\n\nCreate a second data file that references data from the first:\n\n\n\n\n$ cat \n site/data/memcached.sh \nEOF\ndata_common_packages=(\n  \nhtop\n\n  \n${data_common_packages[@]}\n\n)\nEOF\n\n\n\n\n\n\nDeclare the data files in order in your role:\n\n\n\n\nstdlib.data common\nstdlib.data memcached\n\n\n\n\nComments\n\n\nThis is possible because data files are just regular Bash scripts. The variables that have been sourced earlier in the chain are naturally available to files later in the chain. By using regular Bash syntax, you can manipulate the available data in any legal way.", 
            "title": "Referencing Data from Data"
        }, 
        {
            "location": "/guides/referencing-data-from-data/#referencing-data-from-data-files", 
            "text": "Referencing Data from Data Files  Description  Steps  Comments", 
            "title": "Referencing Data from Data Files"
        }, 
        {
            "location": "/guides/referencing-data-from-data/#description", 
            "text": "This guide will show how you can reference previously declared data in subsequent data files.", 
            "title": "Description"
        }, 
        {
            "location": "/guides/referencing-data-from-data/#steps", 
            "text": "Create an initial data file:   $ cat   site/data/common.sh  EOF\ndata_common_packages=(\n   vim \n   tmux \n)\nEOF   Create a second data file that references data from the first:   $ cat   site/data/memcached.sh  EOF\ndata_common_packages=(\n   htop \n   ${data_common_packages[@]} \n)\nEOF   Declare the data files in order in your role:   stdlib.data common\nstdlib.data memcached", 
            "title": "Steps"
        }, 
        {
            "location": "/guides/referencing-data-from-data/#comments", 
            "text": "This is possible because data files are just regular Bash scripts. The variables that have been sourced earlier in the chain are naturally available to files later in the chain. By using regular Bash syntax, you can manipulate the available data in any legal way.", 
            "title": "Comments"
        }, 
        {
            "location": "/guides/testing-with-test-kitchen/", 
            "text": "Testing With Test Kitchen\n\n\n\n\n\n\nTesting With Test Kitchen\n\n\nDescription\n\n\nSteps\n\n\nComments\n\n\n\n\n\n\n\n\n\n\nDescription\n\n\nThis guide will show how to set up Test Kitchen so you can run various acceptance and integration tests on Waffles.\n\n\nSteps\n\n\n\n\n\n\nProvision a virtual machine that will be used for Test Kitchen.\n\n\n\n\n\n\nRun the following commands:\n\n\n\n\n\n\napt-get update\napt-get install -y ruby\nwget -qO- https://get.docker.com/\ngem install test-kitchen\ngem install kitchen-docker\ngem install busser-bash\ngem install busser-bats\ngem install busser-serverspec\nkitchen init --driver=kitchen-docker\n\n\n\n\n\n\n\n\nDownload Waffles to \n/root/.waffles\n.\n\n\n\n\n\n\nThe \n/root/.waffles/kitchen\n directory contains everything you need to get started with testing. Review \n/root/.waffles/kitchen/.kitchen.yml\n and make any necessary changes.\n\n\n\n\n\n\nType the following command to run all tests:\n\n\n\n\n\n\ncd /root/.waffles/kitchen\nkitchen test\n\n\n\n\nComments\n\n\nFor information on how to use Test Kitchen, see the \nTest Kitchen\n home page.", 
            "title": "Testing Waffles with Test Kitchen"
        }, 
        {
            "location": "/guides/testing-with-test-kitchen/#testing-with-test-kitchen", 
            "text": "Testing With Test Kitchen  Description  Steps  Comments", 
            "title": "Testing With Test Kitchen"
        }, 
        {
            "location": "/guides/testing-with-test-kitchen/#description", 
            "text": "This guide will show how to set up Test Kitchen so you can run various acceptance and integration tests on Waffles.", 
            "title": "Description"
        }, 
        {
            "location": "/guides/testing-with-test-kitchen/#steps", 
            "text": "Provision a virtual machine that will be used for Test Kitchen.    Run the following commands:    apt-get update\napt-get install -y ruby\nwget -qO- https://get.docker.com/\ngem install test-kitchen\ngem install kitchen-docker\ngem install busser-bash\ngem install busser-bats\ngem install busser-serverspec\nkitchen init --driver=kitchen-docker    Download Waffles to  /root/.waffles .    The  /root/.waffles/kitchen  directory contains everything you need to get started with testing. Review  /root/.waffles/kitchen/.kitchen.yml  and make any necessary changes.    Type the following command to run all tests:    cd /root/.waffles/kitchen\nkitchen test", 
            "title": "Steps"
        }, 
        {
            "location": "/guides/testing-with-test-kitchen/#comments", 
            "text": "For information on how to use Test Kitchen, see the  Test Kitchen  home page.", 
            "title": "Comments"
        }, 
        {
            "location": "/guides/waffles-and-lxc/", 
            "text": "Using Waffles with LXC\n\n\n\n\n\n\nUsing Waffles with LXC\n\n\nDescription\n\n\nSteps\n\n\nInstalling LXC\n\n\nCreating a Base Container\n\n\nWaffles LXC Script\n\n\n\n\n\n\nConclusion\n\n\n\n\n\n\n\n\n\n\nDescription\n\n\nThis guide will describe how to configure LXC containers with Waffles.\n\n\nSteps\n\n\nInstalling LXC\n\n\nFirst, set up an LXC server. I've written a blog post \nhere\n that may be used as a reference.\n\n\nCreating a Base Container\n\n\nI find it very useful to have a standard container that's used as the basis for all other containers. If anything, it makes the creation of new containers almost instant since cloning a container is much quicker than creating an entirely new container.\n\n\nTo create a base container, just create a standard container and turn it off with \nlxc-stop\n.\n\n\nWaffles LXC Script\n\n\nI've been using the following script for the past few months and find it works very well. Comments and improvements are definitely welcome, though.\n\n\n#!/bin/bash\n\nif [ -z $1 ]; then\n  echo \nRole required.\n\n  exit 1\nfi\n\nlxc-ls | grep -q waffles_$1\nif [ $? == 0 ]; then\n  echo \nShutting down and destroying waffles_$1\n\n  lxc-stop -n waffles_$1\n  lxc-destroy -n waffles_$1\nfi\n\necho \nCloning LXC container waffles_base to waffles_$1\n\nlxc-clone -o waffles_base -n waffles_$1 -s\n\necho \nCopying root key to container\n\nmkdir /var/lib/lxc/waffles_$1/rootfs/root/.ssh\ncat /root/.ssh/id_rsa.pub \n /var/lib/lxc/waffles_$1/rootfs/root/.ssh/authorized_keys\n\necho \nStarting waffles_$1 and waiting until it has an IP\n\nlxc-start -d -n waffles_$1\n\nrunning=false\nwhile [ \n$running\n == false ]; do\n  lxc-info -i -n waffles_$1 | grep -q 10\n  if [ $? == 0 ]; then\n    ip=$(lxc-info -i -n waffles_$1 | awk '{print $2}')\n    running=true\n  else\n    echo \nwaffles_$1 not up yet. Sleeping...\n\n    sleep 2\n  fi\ndone\n\ngrep -q waffles_$1 /etc/hosts\nif [ $? == 0 ]; then\n  sed -i -e \n/waffles_$1/d\n /etc/hosts\nfi\necho \n$ip waffles_$1\n \n /etc/hosts\n\npkill -HUP dnsmasq\n\necho \nRunning waffles\n\nlxc-attach -n waffles_$1 -- apt-get update\nlxc-attach -n waffles_$1 -- apt-get install -y rsync\ncd /root/.waffles \n bash waffles.sh -s waffles_$1 -r $1\n\n\n\n\nThis script assumes the following:\n\n\n\n\nYou have a base container called \nwaffles_base\n.\n\n\nYou have Waffles installed under \n/root/.waffles\n.\n\n\n\n\nTo use this script, run it like so:\n\n\n$ waffles_lxc.sh memcached\n\n\n\n\nThe script will then clone \nwaffles_base\n as \nwaffles_memcached\n and create an \n/etc/hosts\n entry for it so all other containers can reference it by name.\n\n\nIf you'd prefer not to have all containers prefixed with \nwaffles_\n, just edit the script.\n\n\nConclusion\n\n\nThis guide detailed one way of using Waffles with LXC by using a simple Bash script that automates the creation of a container and applies a role to it using Waffles.", 
            "title": "Waffles and LXC"
        }, 
        {
            "location": "/guides/waffles-and-lxc/#using-waffles-with-lxc", 
            "text": "Using Waffles with LXC  Description  Steps  Installing LXC  Creating a Base Container  Waffles LXC Script    Conclusion", 
            "title": "Using Waffles with LXC"
        }, 
        {
            "location": "/guides/waffles-and-lxc/#description", 
            "text": "This guide will describe how to configure LXC containers with Waffles.", 
            "title": "Description"
        }, 
        {
            "location": "/guides/waffles-and-lxc/#steps", 
            "text": "Installing LXC  First, set up an LXC server. I've written a blog post  here  that may be used as a reference.  Creating a Base Container  I find it very useful to have a standard container that's used as the basis for all other containers. If anything, it makes the creation of new containers almost instant since cloning a container is much quicker than creating an entirely new container.  To create a base container, just create a standard container and turn it off with  lxc-stop .  Waffles LXC Script  I've been using the following script for the past few months and find it works very well. Comments and improvements are definitely welcome, though.  #!/bin/bash\n\nif [ -z $1 ]; then\n  echo  Role required. \n  exit 1\nfi\n\nlxc-ls | grep -q waffles_$1\nif [ $? == 0 ]; then\n  echo  Shutting down and destroying waffles_$1 \n  lxc-stop -n waffles_$1\n  lxc-destroy -n waffles_$1\nfi\n\necho  Cloning LXC container waffles_base to waffles_$1 \nlxc-clone -o waffles_base -n waffles_$1 -s\n\necho  Copying root key to container \nmkdir /var/lib/lxc/waffles_$1/rootfs/root/.ssh\ncat /root/.ssh/id_rsa.pub   /var/lib/lxc/waffles_$1/rootfs/root/.ssh/authorized_keys\n\necho  Starting waffles_$1 and waiting until it has an IP \nlxc-start -d -n waffles_$1\n\nrunning=false\nwhile [  $running  == false ]; do\n  lxc-info -i -n waffles_$1 | grep -q 10\n  if [ $? == 0 ]; then\n    ip=$(lxc-info -i -n waffles_$1 | awk '{print $2}')\n    running=true\n  else\n    echo  waffles_$1 not up yet. Sleeping... \n    sleep 2\n  fi\ndone\n\ngrep -q waffles_$1 /etc/hosts\nif [ $? == 0 ]; then\n  sed -i -e  /waffles_$1/d  /etc/hosts\nfi\necho  $ip waffles_$1    /etc/hosts\n\npkill -HUP dnsmasq\n\necho  Running waffles \nlxc-attach -n waffles_$1 -- apt-get update\nlxc-attach -n waffles_$1 -- apt-get install -y rsync\ncd /root/.waffles   bash waffles.sh -s waffles_$1 -r $1  This script assumes the following:   You have a base container called  waffles_base .  You have Waffles installed under  /root/.waffles .   To use this script, run it like so:  $ waffles_lxc.sh memcached  The script will then clone  waffles_base  as  waffles_memcached  and create an  /etc/hosts  entry for it so all other containers can reference it by name.  If you'd prefer not to have all containers prefixed with  waffles_ , just edit the script.", 
            "title": "Steps"
        }, 
        {
            "location": "/guides/waffles-and-lxc/#conclusion", 
            "text": "This guide detailed one way of using Waffles with LXC by using a simple Bash script that automates the creation of a container and applies a role to it using Waffles.", 
            "title": "Conclusion"
        }, 
        {
            "location": "/guides/waffles-and-terraform/", 
            "text": "Using Waffles with Terraform\n\n\n\n\n\n\nUsing Waffles with Terraform\n\n\nDescription\n\n\nSteps\n\n\nInstalling Terraform\n\n\nCreating a Terraform Configuration\n\n\nApply the Terraform Configuration\n\n\n\n\n\n\nComments\n\n\nConclusion\n\n\n\n\n\n\n\n\n\n\nDescription\n\n\nThis guide will show how to use Waffles with \nTerraform\n. The Terraform OpenStack provider will be used, but these concepts should be applicable to any provider.\n\n\nSteps\n\n\nInstalling Terraform\n\n\nFirst, set up and install Terraform. Instructions can be found on Terraform's \nhomepage\n.\n\n\nCreating a Terraform Configuration\n\n\nThe following Terraform Configuration is all that is required to use Waffles with Terraform:\n\n\nresource \nopenstack_compute_keypair_v2\n \nwaffles\n {\n  name = \nwaffles\n\n  public_key = \n${file(\n/root/.ssh/id_rsa.pub\n)}\n\n}\n\nresource \nopenstack_compute_instance_v2\n \nwaffles\n {\n  name = \nwaffles\n\n  image_name = \nUbuntu 14.04\n\n  flavor_name = \nm1.tiny\n\n\n  key_pair = \n${openstack_compute_keypair_v2.waffles.name}\n\n  security_groups = [\ndefault\n]\n\n  connection {\n    user = \nubuntu\n\n    key_file = \n/root/.ssh/id_rsa\n\n    host = \n${openstack_compute_instance_v2.waffles.access_ip_v6}\n\n  }\n\n  provisioner \nlocal-exec\n {\n    command = \nsleep 10 \n cd /root/.waffles \n bash waffles.sh -r memcached -s ${openstack_compute_instance_v2.waffles.access_ip_v6} -u ubuntu -y\n\n  }\n\n}\n\n\n\n\nSave the above as something like \n~/waffles-tform/main.tf\n\n\nApply the Terraform Configuration\n\n\nNow just apply the configuration with:\n\n\n$ cd waffles-tform\n$ terraform apply\n\n\n\n\nComments\n\n\nThe above configuration makes a few assumptions:\n\n\n\n\nrsync\n is already installed on the image you'll be using. If yours doesn't, use \ncloud-init\n or a similar system to pre-install it.\n\n\nThe virtual machine that Terraform creates is accessible via IPv6. If yours isn't, either attach a Floating or Elastic IP or use the fixed IP somehow.\n\n\nThe SSH key being used is \n/root/.ssh/id_rsa\n. This is because Waffles does not support non-default SSH keys yet.\n\n\nSSH access is allowed through the security group.\n\n\n\n\nConclusion\n\n\nThis guide showed one way of using Waffles with Terraform. Both systems are extremely flexible and complement each other well, so there may be other ways of achieving the same result.\n\n\nFor example, you could use Terraform's \nfile\n provisioner to copy the entire \n~/.waffles\n directory to the remote virtual machine. The benefit of using Waffles's built-in push is that only the files which the role requires are copied over.", 
            "title": "Waffles and Terraform"
        }, 
        {
            "location": "/guides/waffles-and-terraform/#using-waffles-with-terraform", 
            "text": "Using Waffles with Terraform  Description  Steps  Installing Terraform  Creating a Terraform Configuration  Apply the Terraform Configuration    Comments  Conclusion", 
            "title": "Using Waffles with Terraform"
        }, 
        {
            "location": "/guides/waffles-and-terraform/#description", 
            "text": "This guide will show how to use Waffles with  Terraform . The Terraform OpenStack provider will be used, but these concepts should be applicable to any provider.", 
            "title": "Description"
        }, 
        {
            "location": "/guides/waffles-and-terraform/#steps", 
            "text": "Installing Terraform  First, set up and install Terraform. Instructions can be found on Terraform's  homepage .  Creating a Terraform Configuration  The following Terraform Configuration is all that is required to use Waffles with Terraform:  resource  openstack_compute_keypair_v2   waffles  {\n  name =  waffles \n  public_key =  ${file( /root/.ssh/id_rsa.pub )} \n}\n\nresource  openstack_compute_instance_v2   waffles  {\n  name =  waffles \n  image_name =  Ubuntu 14.04 \n  flavor_name =  m1.tiny \n\n  key_pair =  ${openstack_compute_keypair_v2.waffles.name} \n  security_groups = [ default ]\n\n  connection {\n    user =  ubuntu \n    key_file =  /root/.ssh/id_rsa \n    host =  ${openstack_compute_instance_v2.waffles.access_ip_v6} \n  }\n\n  provisioner  local-exec  {\n    command =  sleep 10   cd /root/.waffles   bash waffles.sh -r memcached -s ${openstack_compute_instance_v2.waffles.access_ip_v6} -u ubuntu -y \n  }\n\n}  Save the above as something like  ~/waffles-tform/main.tf  Apply the Terraform Configuration  Now just apply the configuration with:  $ cd waffles-tform\n$ terraform apply", 
            "title": "Steps"
        }, 
        {
            "location": "/guides/waffles-and-terraform/#comments", 
            "text": "The above configuration makes a few assumptions:   rsync  is already installed on the image you'll be using. If yours doesn't, use  cloud-init  or a similar system to pre-install it.  The virtual machine that Terraform creates is accessible via IPv6. If yours isn't, either attach a Floating or Elastic IP or use the fixed IP somehow.  The SSH key being used is  /root/.ssh/id_rsa . This is because Waffles does not support non-default SSH keys yet.  SSH access is allowed through the security group.", 
            "title": "Comments"
        }, 
        {
            "location": "/guides/waffles-and-terraform/#conclusion", 
            "text": "This guide showed one way of using Waffles with Terraform. Both systems are extremely flexible and complement each other well, so there may be other ways of achieving the same result.  For example, you could use Terraform's  file  provisioner to copy the entire  ~/.waffles  directory to the remote virtual machine. The benefit of using Waffles's built-in push is that only the files which the role requires are copied over.", 
            "title": "Conclusion"
        }, 
        {
            "location": "/guides/infra/intro/", 
            "text": "Deploying Infrastructure with Waffles\n\n\n\n\n\n\nDeploying Infrastructure with Waffles\n\n\nDescription\n\n\nFirst Steps\n\n\nCloud Access\n\n\nInstall Waffles\n\n\nInfrastructure Code Directory\n\n\nInfrastructure Makefile\n\n\nNode Inventory\n\n\n\n\n\n\nFoundational Components\n\n\nCommon Waffles Settings\n\n\nacng.sh\n\n\npackages.sh\n\n\nsudo.sh\n\n\nupdates.sh\n\n\nusers.sh\n\n\n\n\n\n\nAugeas\n\n\napt_install.sh\n\n\nupdate_lenses.sh\n\n\n\n\n\n\nFinal Base Directory Structure\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDescription\n\n\nThis series will describe how to deploy infrastructure in a cloud environment using Waffles.\n\n\nThe combination of tools and methods used in this series is only one of many. By swapping out any of the components (even Waffles), you should be able to achieve the same results. In this way, this guide can serve as a general-purpose document for deploying cloud services.\n\n\nThis document will use the following combination of tools and services:\n\n\n\n\nCloud Environment: OpenStack, specifically with IPv6 support and a single public subnet\n\n\nCloud Environment: Amazon AWS, specifically for Route53 DNSaaS\n\n\nCloud Infrastructure Deployment: Terraform\n\n\nConfiguration Management: Waffles\n\n\nOperating System: Ubuntu 14.04\n\n\n\n\nFirst Steps\n\n\nCloud Access\n\n\nMake sure you have proper access to the required cloud environments. For this guide, OpenStack and AWS will be used. Make note of the credentials needed to access these environments.\n\n\nAmazon's Route53 service will be used for DNSaaS. Make sure you have delegated a domain or subdomain to Route53.\n\n\nInstall Waffles\n\n\nTo begin, first install Waffles to the \n/etc/waffles\n directory:\n\n\n$ cd /etc\n$ sudo git clone https://github.com/jtopjian/waffles\n\n\n\n\nInfrastructure Code Directory\n\n\nNext, create a directory that will be used to hold the infrastructure code:\n\n\n$ cd\n$ mkdir infrastructure\n$ cd infrastructure\n\n\n\n\nThis directory will have several subdirectories. The first is a \nkeys\n directory to hold SSH keys:\n\n\n$ mkdir keys\n$ cd keys\n$ ssh-keygen -t rsa -N '' -f infra\n$ cd ..\n\n\n\n\nThe next directory is \nrc\n, which will hold the credentials to the cloud services being used:\n\n\n$ mkdir rc\n$ cd rc\n$ touch openstack\n$ touch aws\n$ cd ..\n\n\n\n\nThe third directory is for Waffles. Though Waffles was installed in \n/etc/waffles\n, this directory will be used to hold the site-specific configuration. By doing this, you can create a whole other infrastructure directory (maybe \ninfrastructure2\n, for a lack of a creative name) that will contain a different set of infrastructure.\n\n\n$ mkdir -p waffles/{data,profiles,roles}\n\n\n\n\nThe fourth directory is for Terraform. This will hold all Terraform configurations:\n\n\n$ mkdir terraform\n\n\n\n\nInfrastructure Makefile\n\n\nThis guide will use a \nMakefile\n to assist with common tasks. Create a file called \nMakefile\n located in the \ninfrastructure\n directory. We'll add tasks to the \nMakefile\n as this guide goes on, but for now, start with:\n\n\nWSD = waffles\n\ntplan:\n  @. cd terraform/$(ROLE) \n terraform plan\n\ntapply:\n  @. cd terraform/$(ROLE) \n terraform apply\n\ntdestroy:\n  @. cd terraform/$(ROLE) \n terraform destroy\n\n.PHONY: waffles\nwaffles:\n  WAFFLES_SITE_DIR=$(WSD) /etc/waffles/waffles.sh -s $(NODE) -k keys/infra -r $(ROLE)\n\n\n\n\nNode Inventory\n\n\nFinally, create a blank file called \nnodes\n. This will be used to hold an inventory of the deployed nodes:\n\n\n$ touch nodes\n\n\n\n\nFoundational Components\n\n\nBefore we start deploying actual services, some foundational pieces need to be created, specifically an OpenStack Security Group and SSH Key Pair.\n\n\nCreate the directory \ninfrastructure/terraform/support\n and in that directory, create the file \nmain.tf\n with the following contents:\n\n\nresource \nopenstack_compute_keypair_v2\n \nsupport\n {\n  name = \ninfra\n\n  public_key = \n${file(\n~/infrastructure/keys/infra.pub\n)}\n\n}\n\nresource \nopenstack_compute_secgroup_v2\n \nsupport\n {\n  name = \nAllowAll\n\n  description = \nGroup to allow all traffic\n\n\n  rule {\n    ip_protocol = \ntcp\n\n    from_port = 1\n    to_port = 65535\n    cidr = \n0.0.0.0/0\n\n  }\n\n  rule {\n    ip_protocol = \nudp\n\n    from_port = 1\n    to_port = 65535\n    cidr = \n0.0.0.0/0\n\n  }\n\n  rule {\n    ip_protocol = \nicmp\n\n    from_port = -1\n    to_port = -1\n    cidr = \n0.0.0.0/0\n\n  }\n\n  rule {\n    ip_protocol = \ntcp\n\n    from_port = 1\n    to_port = 65535\n    cidr = \n::/0\n\n  }\n  rule {\n    ip_protocol = \nudp\n\n    from_port = 1\n    to_port = 65535\n    cidr = \n::/0\n\n  }\n\n  rule {\n    ip_protocol = \nicmp\n\n    from_port = -1\n    to_port = -1\n    cidr = \n::/0\n\n  }\n}\n\n\n\n\nNext, source the \nrc/openstack\n file and deploy the infrastructure:\n\n\n$ source rc/openstack\n$ make tplan ROLE=support\n$ make tapply ROLE=support\n\n\n\n\nAt this point, Terraform has deployed the Security Group and Key Pair.\n\n\nCommon Waffles Settings\n\n\nWhen configuring each individual node, a lot of settings will be common amongst all of them. These settings can be added to a single \"common\" data file called \ninfrastructure/waffles/data/common.sh\n:\n\n\n# Declare global variables\ndeclare -ag data_users=()\ndeclare -Ag data_user_info=()\ndeclare -ag data_services=()\ndeclare -Ag data_service_info=()\n\n# Standard node information\ndeclare -Ag data_node_info=()\ndata_node_info[domain]=\nexample.com\n\ndata_node_info[hostname]=$(hostname)\ndata_node_info[ip]=$(ip addr show dev eth0 | grep 'inet ' | awk '{print $2}' | cut -d/ -f1 | head -1)\ndata_node_info[ip6]=$(ip addr show dev eth0 | grep inet6 | awk '{print $2}' | head -1 | cut -d/ -f1)\ndata_node_info[nproc]=$(nproc)\n\n# Packages to be installed on all nodes\ndeclare -ag data_packages=()\nstdlib.array_push data_packages wget\nstdlib.array_push data_packages curl\nstdlib.array_push data_packages tmux\nstdlib.array_push data_packages vim\nstdlib.array_push data_packages iptables\n\n# ACNG server\ndata_acng_server=\nacng.example.com\n\n\n\n\n\nThe above script is simply building some hashes and arrays to store common settings. This includes common packages, the node's hostname and domain name, its IPv4 and IPv6 address, and the \napt-cacher-ng\n server it should use.\n\n\nNext, we'll create a \"common\" profile. This profile will contain scripts that are applicable to any type of node in the environment. First, create the directory structure \ninfrastructure/waffles/profiles/common/scripts\n. And then create the following scripts under it:\n\n\nacng.sh\n\n\nstdlib.title \ncommon/acng\n\n\nstdlib.file --name /etc/apt/apt.conf.d/01acng --content \nAcquire::http { Proxy \\\nhttp://$data_acng_server:3142\\\n; };\n\n\n\n\n\npackages.sh\n\n\nstdlib.title \ncommon/packages\n\n\nfor pkg in \n${data_packages[@]}\n; do\n  stdlib.split $pkg '='\n  stdlib.apt --state present --package \n${__split[0]}\n --version \n${__split[1]}\n\ndone\n\n\n\n\nsudo.sh\n\n\nstdlib.title \ncommon/sudo\n\n\nstdlib.file_line --name \nsudoers.d/00-common/always_set_home\n --file /etc/sudoers.d/00-common --line \nDefaults always_set_home\n\n\n\n\n\nupdates.sh\n\n\nstdlib.title \ncommon/updates\n\n\nread -r -d '' _security_updates \nEOF\nAPT::Periodic::Update-Package-Lists \n1\n;\nAPT::Periodic::Unattended-Upgrade \n1\n;\nEOF\nstdlib.file --name /etc/apt/apt.conf.d/20auto-upgrades --content \n$_security_updates\n\n\n\n\n\nusers.sh\n\n\nstdlib.title \ncommon/users\n\n\nfor user in \n${data_users[@]}\n; do\n  _state=\n${data_user_info[$user|state]:-present}\n\n  _username=\n${data_user_info[$user|name]:-present}\n\n  _homedir=\n${data_user_info[$user|homedir]:-\n}\n\n  _uid=\n${data_user_info[$user|uid]:-\n}\n\n  _gid=\n${data_user_info[$user|gid]:-\n}\n\n  _comment=\n${data_user_info[$user|comment]:-\n}\n\n  _shell=\n${data_user_info[$user|shell]:-\n}\n\n  _passwd=\n${data_user_info[$user|password]:-\n}\n\n  _create_home=\n${data_user_info[$user|create_home]:-\ntrue\n}\n\n  _create_group=\n${data_user_info[$user|create_group]:-\ntrue\n}\n\n  _groups=\n${data_user_info[$user|groups]:-\n}\n\n  _sudo=\n${data_user_info[$user|sudo]:-\n}\n\n  _system=\n${data_user_info[$user|system]:-\n}\n\n\n  if [[ $_create_group == \ntrue\n ]]; then\n    stdlib.groupadd --state $_state --group \n$_username\n --gid \n$_gid\n\n  fi\n\n  stdlib.useradd --state $_state --user \n$_username\n --uid \n$_uid\n --gid \n$_gid\n --comment \n$_comment\n --homedir \n$_homedir\n --shell \n$_shell\n --passwd \n$_passwd\n --groups \n$_groups\n --createhome \n$_createhome\n\ndone\n\n\n\n\nAugeas\n\n\nAlong with the Waffles Common profile, create a profile that will install and configure Augeas.  Augeas is used to manipulate configuration files that have more difficult styles and formats.\n\n\nWaffles includes a set of Augeas-based resources, but Waffles does not handle the actual installation and configuration of Augeas.\n\n\nCreate the \ninfrastructure/waffles/profiles/augeas/scripts\n directory and the following scripts:\n\n\napt_install.sh\n\n\nstdlib.title \naugeas/apt_install\n\n\nstdlib.apt_key --name augeas --key AE498453 --keyserver keyserver.ubuntu.com\nstdlib.apt_source --name augeas --uri http://ppa.launchpad.net/raphink/augeas/ubuntu --distribution trusty --component main\nstdlib.apt --package augeas-tools --version latest\n\n\n\n\nupdate_lenses.sh\n\n\nstdlib.title \naugeas/update_lenses\n\n\nstdlib.git --state latest --name /usr/src/augeas --source https://github.com/hercules-team/augeas\n\nif [[ $stdlib_resource_change == \ntrue\n ]]; then\n  stdlib.info \nUpdating lenses\n\n  stdlib.capture_error cp \n/usr/src/augeas/lenses/*.aug\n /usr/share/augeas/lenses/dist/\nfi\n\n\n\n\nFinal Base Directory Structure\n\n\nAt this point, the infrastructure directory should look like this:\n\n\ninfrastructure\n\u251c\u2500\u2500 keys\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 infra\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 infra.pub\n\u251c\u2500\u2500 Makefile\n\u251c\u2500\u2500 nodes\n\u251c\u2500\u2500 rc\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 aws\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 openstack\n\u251c\u2500\u2500 terraform\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 support\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 main.tf\n\u2514\u2500\u2500 waffles\n    \u251c\u2500\u2500 data\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 common.sh\n    \u251c\u2500\u2500 profiles\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 augeas\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 scripts\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 apt_install.sh\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 update_lenses.sh\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 common\n    \u2502\u00a0\u00a0     \u2514\u2500\u2500 scripts\n    \u2502\u00a0\u00a0         \u251c\u2500\u2500 acng.sh\n    \u2502\u00a0\u00a0         \u251c\u2500\u2500 packages.sh\n    \u2502\u00a0\u00a0         \u251c\u2500\u2500 sudo.sh\n    \u2502\u00a0\u00a0         \u251c\u2500\u2500 updates.sh\n    \u2502\u00a0\u00a0         \u2514\u2500\u2500 users.sh\n    \u2514\u2500\u2500 roles\n\n\n\n\nYou can also reference \nthis\n Git repository for a snapshot of how everything should look at this point.", 
            "title": "Intro"
        }, 
        {
            "location": "/guides/infra/intro/#deploying-infrastructure-with-waffles", 
            "text": "Deploying Infrastructure with Waffles  Description  First Steps  Cloud Access  Install Waffles  Infrastructure Code Directory  Infrastructure Makefile  Node Inventory    Foundational Components  Common Waffles Settings  acng.sh  packages.sh  sudo.sh  updates.sh  users.sh    Augeas  apt_install.sh  update_lenses.sh    Final Base Directory Structure", 
            "title": "Deploying Infrastructure with Waffles"
        }, 
        {
            "location": "/guides/infra/intro/#description", 
            "text": "This series will describe how to deploy infrastructure in a cloud environment using Waffles.  The combination of tools and methods used in this series is only one of many. By swapping out any of the components (even Waffles), you should be able to achieve the same results. In this way, this guide can serve as a general-purpose document for deploying cloud services.  This document will use the following combination of tools and services:   Cloud Environment: OpenStack, specifically with IPv6 support and a single public subnet  Cloud Environment: Amazon AWS, specifically for Route53 DNSaaS  Cloud Infrastructure Deployment: Terraform  Configuration Management: Waffles  Operating System: Ubuntu 14.04", 
            "title": "Description"
        }, 
        {
            "location": "/guides/infra/intro/#first-steps", 
            "text": "Cloud Access  Make sure you have proper access to the required cloud environments. For this guide, OpenStack and AWS will be used. Make note of the credentials needed to access these environments.  Amazon's Route53 service will be used for DNSaaS. Make sure you have delegated a domain or subdomain to Route53.  Install Waffles  To begin, first install Waffles to the  /etc/waffles  directory:  $ cd /etc\n$ sudo git clone https://github.com/jtopjian/waffles  Infrastructure Code Directory  Next, create a directory that will be used to hold the infrastructure code:  $ cd\n$ mkdir infrastructure\n$ cd infrastructure  This directory will have several subdirectories. The first is a  keys  directory to hold SSH keys:  $ mkdir keys\n$ cd keys\n$ ssh-keygen -t rsa -N '' -f infra\n$ cd ..  The next directory is  rc , which will hold the credentials to the cloud services being used:  $ mkdir rc\n$ cd rc\n$ touch openstack\n$ touch aws\n$ cd ..  The third directory is for Waffles. Though Waffles was installed in  /etc/waffles , this directory will be used to hold the site-specific configuration. By doing this, you can create a whole other infrastructure directory (maybe  infrastructure2 , for a lack of a creative name) that will contain a different set of infrastructure.  $ mkdir -p waffles/{data,profiles,roles}  The fourth directory is for Terraform. This will hold all Terraform configurations:  $ mkdir terraform  Infrastructure Makefile  This guide will use a  Makefile  to assist with common tasks. Create a file called  Makefile  located in the  infrastructure  directory. We'll add tasks to the  Makefile  as this guide goes on, but for now, start with:  WSD = waffles\n\ntplan:\n  @. cd terraform/$(ROLE)   terraform plan\n\ntapply:\n  @. cd terraform/$(ROLE)   terraform apply\n\ntdestroy:\n  @. cd terraform/$(ROLE)   terraform destroy\n\n.PHONY: waffles\nwaffles:\n  WAFFLES_SITE_DIR=$(WSD) /etc/waffles/waffles.sh -s $(NODE) -k keys/infra -r $(ROLE)  Node Inventory  Finally, create a blank file called  nodes . This will be used to hold an inventory of the deployed nodes:  $ touch nodes", 
            "title": "First Steps"
        }, 
        {
            "location": "/guides/infra/intro/#foundational-components", 
            "text": "Before we start deploying actual services, some foundational pieces need to be created, specifically an OpenStack Security Group and SSH Key Pair.  Create the directory  infrastructure/terraform/support  and in that directory, create the file  main.tf  with the following contents:  resource  openstack_compute_keypair_v2   support  {\n  name =  infra \n  public_key =  ${file( ~/infrastructure/keys/infra.pub )} \n}\n\nresource  openstack_compute_secgroup_v2   support  {\n  name =  AllowAll \n  description =  Group to allow all traffic \n\n  rule {\n    ip_protocol =  tcp \n    from_port = 1\n    to_port = 65535\n    cidr =  0.0.0.0/0 \n  }\n\n  rule {\n    ip_protocol =  udp \n    from_port = 1\n    to_port = 65535\n    cidr =  0.0.0.0/0 \n  }\n\n  rule {\n    ip_protocol =  icmp \n    from_port = -1\n    to_port = -1\n    cidr =  0.0.0.0/0 \n  }\n\n  rule {\n    ip_protocol =  tcp \n    from_port = 1\n    to_port = 65535\n    cidr =  ::/0 \n  }\n  rule {\n    ip_protocol =  udp \n    from_port = 1\n    to_port = 65535\n    cidr =  ::/0 \n  }\n\n  rule {\n    ip_protocol =  icmp \n    from_port = -1\n    to_port = -1\n    cidr =  ::/0 \n  }\n}  Next, source the  rc/openstack  file and deploy the infrastructure:  $ source rc/openstack\n$ make tplan ROLE=support\n$ make tapply ROLE=support  At this point, Terraform has deployed the Security Group and Key Pair.  Common Waffles Settings  When configuring each individual node, a lot of settings will be common amongst all of them. These settings can be added to a single \"common\" data file called  infrastructure/waffles/data/common.sh :  # Declare global variables\ndeclare -ag data_users=()\ndeclare -Ag data_user_info=()\ndeclare -ag data_services=()\ndeclare -Ag data_service_info=()\n\n# Standard node information\ndeclare -Ag data_node_info=()\ndata_node_info[domain]= example.com \ndata_node_info[hostname]=$(hostname)\ndata_node_info[ip]=$(ip addr show dev eth0 | grep 'inet ' | awk '{print $2}' | cut -d/ -f1 | head -1)\ndata_node_info[ip6]=$(ip addr show dev eth0 | grep inet6 | awk '{print $2}' | head -1 | cut -d/ -f1)\ndata_node_info[nproc]=$(nproc)\n\n# Packages to be installed on all nodes\ndeclare -ag data_packages=()\nstdlib.array_push data_packages wget\nstdlib.array_push data_packages curl\nstdlib.array_push data_packages tmux\nstdlib.array_push data_packages vim\nstdlib.array_push data_packages iptables\n\n# ACNG server\ndata_acng_server= acng.example.com   The above script is simply building some hashes and arrays to store common settings. This includes common packages, the node's hostname and domain name, its IPv4 and IPv6 address, and the  apt-cacher-ng  server it should use.  Next, we'll create a \"common\" profile. This profile will contain scripts that are applicable to any type of node in the environment. First, create the directory structure  infrastructure/waffles/profiles/common/scripts . And then create the following scripts under it:  acng.sh  stdlib.title  common/acng \n\nstdlib.file --name /etc/apt/apt.conf.d/01acng --content  Acquire::http { Proxy \\ http://$data_acng_server:3142\\ ; };   packages.sh  stdlib.title  common/packages \n\nfor pkg in  ${data_packages[@]} ; do\n  stdlib.split $pkg '='\n  stdlib.apt --state present --package  ${__split[0]}  --version  ${__split[1]} \ndone  sudo.sh  stdlib.title  common/sudo \n\nstdlib.file_line --name  sudoers.d/00-common/always_set_home  --file /etc/sudoers.d/00-common --line  Defaults always_set_home   updates.sh  stdlib.title  common/updates \n\nread -r -d '' _security_updates  EOF\nAPT::Periodic::Update-Package-Lists  1 ;\nAPT::Periodic::Unattended-Upgrade  1 ;\nEOF\nstdlib.file --name /etc/apt/apt.conf.d/20auto-upgrades --content  $_security_updates   users.sh  stdlib.title  common/users \n\nfor user in  ${data_users[@]} ; do\n  _state= ${data_user_info[$user|state]:-present} \n  _username= ${data_user_info[$user|name]:-present} \n  _homedir= ${data_user_info[$user|homedir]:- } \n  _uid= ${data_user_info[$user|uid]:- } \n  _gid= ${data_user_info[$user|gid]:- } \n  _comment= ${data_user_info[$user|comment]:- } \n  _shell= ${data_user_info[$user|shell]:- } \n  _passwd= ${data_user_info[$user|password]:- } \n  _create_home= ${data_user_info[$user|create_home]:- true } \n  _create_group= ${data_user_info[$user|create_group]:- true } \n  _groups= ${data_user_info[$user|groups]:- } \n  _sudo= ${data_user_info[$user|sudo]:- } \n  _system= ${data_user_info[$user|system]:- } \n\n  if [[ $_create_group ==  true  ]]; then\n    stdlib.groupadd --state $_state --group  $_username  --gid  $_gid \n  fi\n\n  stdlib.useradd --state $_state --user  $_username  --uid  $_uid  --gid  $_gid  --comment  $_comment  --homedir  $_homedir  --shell  $_shell  --passwd  $_passwd  --groups  $_groups  --createhome  $_createhome \ndone  Augeas  Along with the Waffles Common profile, create a profile that will install and configure Augeas.  Augeas is used to manipulate configuration files that have more difficult styles and formats.  Waffles includes a set of Augeas-based resources, but Waffles does not handle the actual installation and configuration of Augeas.  Create the  infrastructure/waffles/profiles/augeas/scripts  directory and the following scripts:  apt_install.sh  stdlib.title  augeas/apt_install \n\nstdlib.apt_key --name augeas --key AE498453 --keyserver keyserver.ubuntu.com\nstdlib.apt_source --name augeas --uri http://ppa.launchpad.net/raphink/augeas/ubuntu --distribution trusty --component main\nstdlib.apt --package augeas-tools --version latest  update_lenses.sh  stdlib.title  augeas/update_lenses \n\nstdlib.git --state latest --name /usr/src/augeas --source https://github.com/hercules-team/augeas\n\nif [[ $stdlib_resource_change ==  true  ]]; then\n  stdlib.info  Updating lenses \n  stdlib.capture_error cp  /usr/src/augeas/lenses/*.aug  /usr/share/augeas/lenses/dist/\nfi  Final Base Directory Structure  At this point, the infrastructure directory should look like this:  infrastructure\n\u251c\u2500\u2500 keys\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 infra\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 infra.pub\n\u251c\u2500\u2500 Makefile\n\u251c\u2500\u2500 nodes\n\u251c\u2500\u2500 rc\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 aws\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 openstack\n\u251c\u2500\u2500 terraform\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 support\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 main.tf\n\u2514\u2500\u2500 waffles\n    \u251c\u2500\u2500 data\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 common.sh\n    \u251c\u2500\u2500 profiles\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 augeas\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 scripts\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 apt_install.sh\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 update_lenses.sh\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 common\n    \u2502\u00a0\u00a0     \u2514\u2500\u2500 scripts\n    \u2502\u00a0\u00a0         \u251c\u2500\u2500 acng.sh\n    \u2502\u00a0\u00a0         \u251c\u2500\u2500 packages.sh\n    \u2502\u00a0\u00a0         \u251c\u2500\u2500 sudo.sh\n    \u2502\u00a0\u00a0         \u251c\u2500\u2500 updates.sh\n    \u2502\u00a0\u00a0         \u2514\u2500\u2500 users.sh\n    \u2514\u2500\u2500 roles  You can also reference  this  Git repository for a snapshot of how everything should look at this point.", 
            "title": "Foundational Components"
        }, 
        {
            "location": "/guides/infra/consul/", 
            "text": "Deploying Consul\n\n\n\n\n\n\nDeploying Consul\n\n\nIntroduction\n\n\nTerraform\n\n\nCount\n\n\nServer Group\n\n\nInstance\n\n\nDNS Records\n\n\nProvisioner\n\n\n\n\n\n\nWaffles\n\n\nData\n\n\nconsul.sh\n\n\n\n\n\n\nProfile\n\n\nclient.sh\n\n\nserver.sh\n\n\ntemplate.sh\n\n\ntemplate-hosts.sh\n\n\nFiles\n\n\n\n\n\n\nRole\n\n\n\n\n\n\nDeploying\n\n\nConsul Key-Value Storage\n\n\nConclusion\n\n\n\n\n\n\n\n\n\n\nIntroduction\n\n\nTo efficiently build and maintain infrastructure, we need to be able to monitor the running nodes, the services they host, and enable them to share information amongst each other. Since this service is so core to the infrastructure, it will be the first service deployed.\n\n\nThis guide will use Consul for this service. Alternatives could be Etcd in combination with Nagios or Sensu.\n\n\nTerraform\n\n\nLet's begin by creating the Terraform structure. First, create the required directories:\n\n\n$ mkdir -p terraform/consul/scripts\n\n\n\n\nNext, create a small bootstrap script for the Consul nodes that will be launched. Save this script as \nterraform/consul/scripts/bootstrap.sh\n:\n\n\n#!/bin/bash\n\ncp /home/ubuntu/.ssh/authorized_keys /root/.ssh\n\n\n\n\nThis is just a quick hack to allow us to log into the nodes as the \nroot\n user.\n\n\nNext, create the \nterraform/consul/main.tf\n file:\n\n\nvariable \ncount\n {\n  default = 3\n}\n\nresource \nopenstack_compute_servergroup_v2\n \nconsul\n {\n  name = \nconsul\n\n  policies = [\nanti-affinity\n]\n}\n\nresource \nopenstack_compute_instance_v2\n \nconsul\n {\n  count = \n${var.count}\n\n  name = \n${format(\nconsul-%02d\n, count.index+1)}\n\n  image_name = \nUbuntu 14.04\n\n  flavor_name = \nm1.small\n\n  key_pair = \ninfra\n\n  security_groups = [\nAllowAll\n]\n  config_drive = true\n  user_data = \n${file(\nscripts/bootstrap.sh\n)}\n\n  scheduler_hints {\n    group = \n${openstack_compute_servergroup_v2.consul.id}\n\n  }\n\n  provisioner \nlocal-exec\n {\n    command = \nsed -i -e '/${self.name}/d' ~/infrastructure/nodes \n echo ${self.name} ${self.access_ip_v6} consul \n ~/infrastructure/nodes\n\n  }\n}\n\nresource \naws_route53_record\n \nconsul-v6\n {\n  zone_id = \nREPLACEME\n\n  name = \nconsul.example.com\n\n  type = \nAAAA\n\n  ttl = \n60\n\n  records = [\n${replace(openstack_compute_instance_v2.consul.*.access_ip_v6, \n/[\\[\\]]/\n, \n)}\n]\n}\n\nresource \naws_route53_record\n \nconsul-txt\n {\n  zone_id = \nREPLACEME\n\n  name = \nconsul.example.com\n\n  type = \nTXT\n\n  ttl = \n60\n\n  records = [\n${formatlist(\n%s.example.com\n, openstack_compute_instance_v2.consul.*.name)}\n]\n}\n\nresource \naws_route53_record\n \nconsul-individual\n {\n  count = \n${var.count}\n\n\n  zone_id = \nREPLACEME\n\n  name = \n${format(\nconsul-%02d.example.com\n, count.index+1)}\n\n  type = \nAAAA\n\n  ttl = \n60\n\n  records = [\n${replace(element(openstack_compute_instance_v2.consul.*.access_ip_v6, count.index), \n/[\\[\\]]/\n, \n)}\n]\n}\n\n\nresource \nnull_resource\n \nconsul\n {\n  count = \n${var.count}\n\n\n  provisioner \nlocal-exec\n {\n    command = \nsleep 10 \n cd ~/infrastructure \n make waffles NODE=${element(aws_route53_record.consul-individual.*.name, count.index)} KEY=keys/infra ROLE=consul\n\n  }\n}\n\n\n\n\nThere's a lot going on here, so let's go over each component. Some of these components will become common to see as they'll be re-used many times in future Terraform configurations.\n\n\nCount\n\n\nvariable \ncount\n {\n  default = 3\n}\n\n\n\n\nThis determines how many nodes will make up the Consul cluster. By default, this configuration will create three, however, you can choose a larger number when Terraform prompts you.\n\n\nServer Group\n\n\nresource \nopenstack_compute_servergroup_v2\n \nconsul\n {\n  name = \nconsul\n\n  policies = [\nanti-affinity\n]\n}\n\n\n\n\nA \"Server Group\" is an OpenStack-specific feature that allows instances (virtual machines / nodes) to have a common policy applied to them. In this case, an \"anti-affinity\" policy is applied. This ensures that each Consul node is hosted on a different Compute Node. This way, if there's an underlying hardware failure on one of the Compute Nodes in the OpenStack cloud, the entire Consul cluster will not be affected.\n\n\nInstance\n\n\nresource \nopenstack_compute_instance_v2\n \nconsul\n {\n  count = \n${var.count}\n\n  name = \n${format(\nconsul-%02d\n, count.index+1)}\n\n  image_name = \nUbuntu 14.04\n\n  flavor_name = \nm1.small\n\n  key_pair = \ninfra\n\n  security_groups = [\nAllowAll\n]\n  config_drive = true\n  user_data = \n${file(\nscripts/bootstrap.sh\n)}\n\n  scheduler_hints {\n    group = \n${openstack_compute_servergroup_v2.consul.id}\n\n  }\n\n  provisioner \nlocal-exec\n {\n    command = \nsed -i -e '/${self.name}/d' ~/infrastructure/nodes \n echo ${self.name} ${self.access_ip_v6} consul \n ~/infrastructure/nodes\n\n  }\n}\n\n\n\n\nThe \"Instance\" resource is the heart of this configuration. Some notes:\n\n\n\n\nNotice that there's only one \"Instance\" defined, but because \ncount\n is set to the \"count\" variable, three (by default) will be created.\n\n\nThe name of each instance will take the format \nconsul-NN\n where \nNN\n is the count in sequence.\n\n\nThe \nuser_data\n parameter will cause the \nscripts/bootstrap.sh\n script to run when the instance launches.\n\n\nscheduler_hints\n places the instance in the Server Group previously created.\n\n\n\n\nAlso note the \nlocal-exec\n provisioner. This runs a simple shell command that adds the following pieces of information to \ninfrastructure/nodes\n:\n  * name\n  * IPv6 Address\n  * Role\n\n\nDNS Records\n\n\nresource \naws_route53_record\n \nconsul-v6\n {\n  zone_id = \nREPLACEME\n\n  name = \nconsul.example.com\n\n  type = \nAAAA\n\n  ttl = \n60\n\n  records = [\n${replace(openstack_compute_instance_v2.consul.*.access_ip_v6, \n/[\\[\\]]/\n, \n)}\n]\n}\n\nresource \naws_route53_record\n \nconsul-txt\n {\n  zone_id = \nREPLACEME\n\n  name = \nconsul.example.com\n\n  type = \nTXT\n\n  ttl = \n60\n\n  records = [\n${formatlist(\n%s.example.com\n, openstack_compute_instance_v2.consul.*.name)}\n]\n}\n\nresource \naws_route53_record\n \nconsul-individual\n {\n  count = \n${var.count}\n\n\n  zone_id = \nREPLACEME\n\n  name = \n${format(\nconsul-%02d.example.com\n, count.index+1)}\n\n  type = \nAAAA\n\n  ttl = \n60\n\n  records = [\n${replace(element(openstack_compute_instance_v2.consul.*.access_ip_v6, count.index), \n/[\\[\\]]/\n, \n)}\n]\n}\n\n\n\n\nThese three resources create a series of DNS records on Amazon Route53. The first record creates an \nAAAA\n record called \nconsul.example.com\n. This record contains the IPv6 address of each created Consul node. Since this record holds more than one IP address, Route53 will return each address in a round-robin fashion.\n\n\nThe second DNS record creates a \nTXT\n record. This record acts as a piece of scratch paper in the DNS system. It holds the hostnames of each created Consul node and will help with bootstrapping Consul.\n\n\nThe third DNS record creates individual \nAAAA\n records for each of the Consul nodes.\n\n\nProvisioner\n\n\nresource \nnull_resource\n \nconsul\n {\n  count = \n${var.count}\n\n\n  provisioner \nlocal-exec\n {\n    command = \nsleep 10 \n cd ~/infrastructure \n make waffles NODE=${element(aws_route53_record.consul-individual.*.name, count.index)} KEY=keys/infra ROLE=consul\n\n  }\n}\n\n\n\n\nThe final resource is a \"Null\" resource. This is a bit of a hack in Terraform to get around the fact that \"Provisioners\" must be attached to a resource of some type. It's not possible to simply have a \"Provisioning\" step.\n\n\nThis resource will run the commands in the \ncommand\n parameter for each of the created Consul nodes. An example of the rendered command is:\n\n\nsleep 10\nmake waffles NODE=consul-01.example.com KEY=keys/infra ROLE=consul\n\n\n\n\nmake\n corresponds to the \nMakefile\n created in the Intro part of this guide. \nmake waffles\n is an actual task that was added to the \nMakefile\n.\n\n\nOf course, the Provisioner could have just gone in the Instance resource, but we want \nall\n resources to be created before any provisioning begins to take place. In this specific case, it's because we want the DNS records to be populated before Consul is built.\n\n\nWith all of this in place, let's move on to the Waffles side:\n\n\nWaffles\n\n\nData\n\n\nTo begin, create a Waffles \ndata\n file to hold the Consul configuration data. This file will be \nwaffles/data/consul.sh\n:\n\n\nconsul.sh\n\n\n# Tell Waffles about the user and service\nstdlib.array_push data_users \nconsul\n\nstdlib.array_push data_services \nconsul\n\n\n# Consul Version\ndata_consul_version=\n0.5.2\n\ndata_consul_template_version=\n0.10.0\n\n\n# Consul Tokens and Keys\ndata_consul_encrypt_key=\nCHANGEME\n\ndata_consul_cluster_name=\nconsul.example.com\n\n\n# Describe the user\n# This user is added by common/users\ndata_user_info[consul|name]=\nconsul\n\ndata_user_info[consul|uid]=\n900\n\ndata_user_info[consul|gid]=\n900\n\ndata_user_info[consul|homedir]=\n/var/lib/consul\n\n\n# Any extra generic packages\n# This package is installed by common/packages\nstdlib.array_push data_packages unzip\n\n# Consul config\ndeclare -Ag data_consul_server_config=(\n  [server]=\ntrue\n\n  [advertise_addr]=\n${data_node_info[ip6]}\n\n  [client_addr]=\n127.0.0.1\n\n  [bind_addr]=\n0.0.0.0\n\n  [bootstrap_expect]=\n3\n\n  [datacenter]=\nhonolulu\n\n  [data_dir]=\n/var/lib/consul\n\n  [encrypt]=\n${data_consul_encrypt_key}\n\n  [enable_syslog]=\ntrue\n\n  [log_level]=\nINFO\n\n  [rejoin_after_leave]=\ntrue\n\n  [retry_interval]=\n30s\n\n  [ui_dir]=\n/opt/consul-web/dist\n\n)\n\ndeclare -Ag data_consul_client_config=(\n  [advertise_addr]=\n${data_node_info[ip6]}\n\n  [client_addr]=\n127.0.0.1\n\n  [datacenter]=\nhonolulu\n\n  [data_dir]=\n/var/lib/consul\n\n  [encrypt]=\n${data_consul_encrypt_key}\n\n  [enable_syslog]=\ntrue\n\n  [log_level]=\nINFO\n\n  [rejoin_after_leave]=\ntrue\n\n  [retry_interval]=\n30s\n\n)\n\ndeclare -Ag data_consul_template_config=(\n  [global|consul]=\nlocalhost:8500\n\n  [global|retry]=\n10s\n\n  [global|max_stale]=\n10m\n\n  [global|log_level]=\nINFO\n\n  [syslog|enabled]=\ntrue\n\n  [syslog|facility]=\nLOCAL5\n\n)\n\n\n\n\nProfile\n\n\nNext, create the Consul profile. Start with the directory structure: \nwaffles/profiles/consul/scripts\n. Inside \nscripts\n, create the following scripts:\n\n\nclient.sh\n\n\nstdlib.title \nconsul/client\n\n\n_user=\n${data_user_info[consul|name]}\n\n\n# Consul Directories\nstdlib.directory --name /var/lib/consul --owner $_user --group $_user --mode 750\nstdlib.directory --name /etc/consul --owner $_user --group $_user --mode 750\nstdlib.directory --name /etc/consul/agent --owner $_user --group $_user --mode 750\nstdlib.directory --name /etc/consul/agent/conf.d --owner $_user --group $_user --mode 750\nstdlib.file --name /var/log/consul.log --owner $_user --group $_user --mode 640\n\n# Install Consul\nif [[ ! -f /usr/local/bin/consul ]]; then\n  stdlib.mute pushd /tmp\n    stdlib.capture_error wget https://dl.bintray.com/mitchellh/consul/${data_consul_version}_linux_amd64.zip\n    stdlib.capture_error unzip ${data_consul_version}_linux_amd64.zip\n    stdlib.capture_error mv consul /usr/local/bin\n  stdlib.mute popd\nfi\n\n# Configure Consul\nfor key in \n${!data_consul_client_config[@]}\n; do\n  augeas.json_dict --file \n/etc/consul/agent/conf.d/config.json\n --path / --key \n$key\n --value \n${data_consul_client_config[$key]}\n\ndone\n\naugeas.json_array --file \n/etc/consul/agent/conf.d/config.json\n --path / --key \nretry_join\n --value \n$data_consul_cluster_name\n\n\n# Consul Service\nstdlib.file --name /etc/init/consul.conf --source \n$WAFFLES_SITE_DIR/profiles/consul/files/consul.conf\n\nstdlib.upstart --name consul --state running\n\n\n\n\nserver.sh\n\n\nstdlib.title \nconsul/server\n\n\n_user=\n${data_user_info[consul|name]}\n\n\n# Consul Directories\nstdlib.directory --name /var/lib/consul --owner $_user --group $_user --mode 750\nstdlib.directory --name /etc/consul --owner $_user --group $_user --mode 750\nstdlib.directory --name /etc/consul/agent --owner $_user --group $_user --mode 750\nstdlib.directory --name /etc/consul/agent/conf.d --owner $_user --group $_user --mode 750\nstdlib.directory --name /opt/consul-web --owner $_user --group $_user --mode 750\nstdlib.file --name /var/log/consul.log --owner $_user --group $_user --mode 640\n\n# Install Consul\nif [[ ! -f /usr/local/bin/consul ]]; then\n  stdlib.mute pushd /tmp\n    stdlib.capture_error wget https://dl.bintray.com/mitchellh/consul/${data_consul_version}_linux_amd64.zip\n    stdlib.capture_error unzip ${data_consul_version}_linux_amd64.zip\n    stdlib.capture_error mv consul /usr/local/bin\n  stdlib.mute popd\nfi\n\n# Configure Consul\nfor key in \n${!data_consul_server_config[@]}\n; do\n  augeas.json_dict --file \n/etc/consul/agent/conf.d/config.json\n --path / --key \n$key\n --value \n${data_consul_server_config[$key]}\n\ndone\n\nfor attempt in {1..10}; do\n  _nodes=($(dig +short -t txt $data_consul_cluster_name | sort | tr -d \\\n))\n  if [[ -z \n$_nodes\n ]]; then\n    stdlib.warn \nNo consul nodes found. Sleeping\n\n    sleep 60\n  else\n    break\n  fi\ndone\n\nfor _node in \n${_nodes[@]}\n; do\n  _consul_nodes=\n${_consul_nodes}--value ${_node} \n\ndone\n\naugeas.json_array --file \n/etc/consul/agent/conf.d/config.json\n --path / --key \nretry_join\n $_consul_nodes\n\nstdlib.file --name /usr/local/bin/purge_failed.sh --mode \n750\n --source \n$WAFFLES_SITE_DIR/profiles/consul/files/purge_failed.sh\n\nstdlib.cron --name consul_purge_failed_nodes --cmd /usr/local/bin/purge_failed.sh\n\n# Server nodes get the web UI\nif [[ ! -d /opt/consul-web/dist ]]; then\n  stdlib.mute pushd /tmp\n    stdlib.capture_error wget https://dl.bintray.com/mitchellh/consul/${data_consul_version}_web_ui.zip\n    stdlib.capture_error unzip -d /opt/consul-web ${data_consul_version}_web_ui.zip\n    stdlib.capture_error chown -R consul: /opt/consul-web\n  stdlib.mute popd\nfi\n\n# Consul Service\nstdlib.file --name /etc/init/consul.conf --source \n$WAFFLES_SITE_DIR/profiles/consul/files/consul.conf\n\nstdlib.upstart --name consul --state running\n\n\n\n\nThe unique thing about this script is the use of polling the \nTXT\n file created by Terraform. In order for Consul to bootstrap itself, it needs to first know of a few neighboring nodes. By polling the \nTXT\n record, it can get a list of those nodes.\n\n\ntemplate.sh\n\n\nstdlib.title \nconsul/template\n\n\n_user=\n${data_user_info[consul|name]}\n\n\n# Consul Template Directories\nstdlib.directory --name /etc/consul/template --owner $_user --group $_user --mode 750\nstdlib.directory --name /etc/consul/template/ctmpl --owner $_user --group $_user --mode 750\nstdlib.directory --name /etc/consul/template/conf.d --owner $_user --group $_user --mode 750\nstdlib.file --name /var/log/consul-template.log --owner root --group syslog --mode 640\nstdlib.file --name /etc/init/consul-template.conf --source \n$WAFFLES_SITE_DIR/profiles/consul/files/consul-template.conf\n\n\nif [[ ! -f /usr/local/bin/consul-template ]]; then\n  stdlib.mute pushd /tmp\n    stdlib.capture_error wget https://github.com/hashicorp/consul-template/releases/download/v${data_consul_template_version}/consul-template_${data_consul_template_version}_linux_amd64.tar.gz\n    stdlib.capture_error tar xzvf consul-template_${data_consul_template_version}_linux_amd64.tar.gz\n    stdlib.capture_error mv consul-template_${data_consul_template_version}_linux_amd64/consul-template /usr/local/bin\n  stdlib.mute popd\nfi\n\nfor key in \n${!data_consul_template_config[@]}\n; do\n  stdlib.split $key \n|\n\n  _section=\n${__split[0]}\n\n  _option=\n${__split[1]}\n\n\n  if [[ $_section == \nglobal\n ]]; then\n    augeas.json_dict --file \n/etc/consul/template/conf.d/config.json\n --path / --key \n$_option\n --value \n${data_consul_template_config[$key]}\n\n  else\n    augeas.json_dict --file \n/etc/consul/template/conf.d/config.json\n --path \n/$_section\n --key \n$_option\n --value \n${data_consul_template_config[$key]}\n\n  fi\ndone\n\nstdlib.upstart --name consul-template --state running\n\n\n\n\nThe above script sets up \nConsul Template\n\n\ntemplate-hosts.sh\n\n\nstdlib.title \nconsul/template_hosts\n\n\nconsul.template --name hosts --destination /etc/hosts\nstdlib.file --name /etc/consul/template/ctmpl/hosts.ctmpl --mode 640 --source \n$WAFFLES_SITE_DIR/profiles/consul/files/hosts.ctmpl\n\n\nif [[ $stdlib_state_change == \ntrue\n ]]; then\n  restart consul-template\nfi\n\n\n\n\nThe above script configures the \n/etc/hosts\n file to be populated by the nodes that Consul knows about.\n\n\nFiles\n\n\nThe above scripts reference some static files that need to be installed on the nodes. For brevity, you can find these scripts in the Git repo linked at the end of this document.\n\n\nRole\n\n\nWith the Consul Data and Profile in place, it's time to build the role. Create the file \nwaffles/roles/consul.sh\n with the following contents:\n\n\nstdlib.enable_augeas\nstdlib.enable_consul\n\nstdlib.data common\nstdlib.data consul\n\nstdlib.profile common/acng\nstdlib.profile common/packages\nstdlib.profile common/users\nstdlib.profile common/updates\nstdlib.profile common/sudo\n\nstdlib.profile augeas/apt_install\nstdlib.profile augeas/update_lenses\n\nstdlib.profile consul/server\nstdlib.profile consul/template\nstdlib.profile consul/template_hosts\n\n\n\n\nThe \nstdlib.enable_augeas\n and \nstdlib.enable_consul\n commands are built-in to Waffles. They enable augeas and consul-specific functions and resources. See the Waffles documentation for more information.\n\n\nThe rest of the role should be self-explanatory: the \ncommon\n and \nconsul\n data files are being read, then the \ncommon\n, \naugeas\n and \nconsul\n profiles. Everything combined makes up a unique \"Consul\" role.\n\n\nDeploying\n\n\nTo deploy the cluster, do the following:\n\n\n$ make tplan ROLE=consul\n$ make tapply ROLE=consul\n\n\n\n\nIf everything was successful, you should have a running Consul cluster. You can verify this by doing:\n\n\n$ ssh -i keys/infra consul.example.com\n$ consul status\n\n\n\n\nConsul Key-Value Storage\n\n\nConsul was setup in a way that restricts access to the key-value store to only nodes running Consul. Terraform provides a \nconsul_keys\n resource that can store data from the Terraform configuration in Consul. Rather than installing Consul on your workstation, an alternative is to SSH into the Consul cluster and forward the port 8500. To do this, make a new task in the \nMakefile\n called \nctunnel\n:\n\n\nctunnel:\n  ssh -i keys/infra -L 8500:localhost:8500 consul.example.com\n\n\n\n\nNow run the task:\n\n\n$ make ctunnel\n\n\n\n\nYou should now have forwarded access to your Consul cluster.\n\n\nConclusion\n\n\nThis part of the Infrastructure guide detailed how to deploy a Consul cluster. At this point, your directory structure should look like:\n\n\ninfrastructure\n\u251c\u2500\u2500 keys\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 infra\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 infra.pub\n\u251c\u2500\u2500 Makefile\n\u251c\u2500\u2500 nodes\n\u251c\u2500\u2500 rc\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 aws\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 openstack\n\u251c\u2500\u2500 terraform\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 consul\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 main.tf\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 scripts\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 bootstrap.sh\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 support\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 main.tf\n\u2514\u2500\u2500 waffles\n    \u251c\u2500\u2500 data\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 common.sh\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 consul.sh\n    \u251c\u2500\u2500 profiles\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 augeas\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 scripts\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 apt_install.sh\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 update_lenses.sh\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 common\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 scripts\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 acng.sh\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 packages.sh\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 sudo.sh\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 updates.sh\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 users.sh\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 consul\n    \u2502\u00a0\u00a0     \u251c\u2500\u2500 files\n    \u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 consul.conf\n    \u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 consul-template.conf\n    \u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 hosts.ctmpl\n    \u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2514\u2500\u2500 purge_failed.sh\n    \u2502\u00a0\u00a0     \u2514\u2500\u2500 scripts\n    \u2502\u00a0\u00a0         \u251c\u2500\u2500 client.sh\n    \u2502\u00a0\u00a0         \u251c\u2500\u2500 server.sh\n    \u2502\u00a0\u00a0         \u251c\u2500\u2500 template_hosts.sh\n    \u2502\u00a0\u00a0         \u2514\u2500\u2500 template.sh\n    \u2514\u2500\u2500 roles\n        \u2514\u2500\u2500 consul.sh\n\n\n\n\nYou can find the final scripts and structure \nhere\n.", 
            "title": "Consul"
        }, 
        {
            "location": "/guides/infra/consul/#deploying-consul", 
            "text": "Deploying Consul  Introduction  Terraform  Count  Server Group  Instance  DNS Records  Provisioner    Waffles  Data  consul.sh    Profile  client.sh  server.sh  template.sh  template-hosts.sh  Files    Role    Deploying  Consul Key-Value Storage  Conclusion", 
            "title": "Deploying Consul"
        }, 
        {
            "location": "/guides/infra/consul/#introduction", 
            "text": "To efficiently build and maintain infrastructure, we need to be able to monitor the running nodes, the services they host, and enable them to share information amongst each other. Since this service is so core to the infrastructure, it will be the first service deployed.  This guide will use Consul for this service. Alternatives could be Etcd in combination with Nagios or Sensu.", 
            "title": "Introduction"
        }, 
        {
            "location": "/guides/infra/consul/#terraform", 
            "text": "Let's begin by creating the Terraform structure. First, create the required directories:  $ mkdir -p terraform/consul/scripts  Next, create a small bootstrap script for the Consul nodes that will be launched. Save this script as  terraform/consul/scripts/bootstrap.sh :  #!/bin/bash\n\ncp /home/ubuntu/.ssh/authorized_keys /root/.ssh  This is just a quick hack to allow us to log into the nodes as the  root  user.  Next, create the  terraform/consul/main.tf  file:  variable  count  {\n  default = 3\n}\n\nresource  openstack_compute_servergroup_v2   consul  {\n  name =  consul \n  policies = [ anti-affinity ]\n}\n\nresource  openstack_compute_instance_v2   consul  {\n  count =  ${var.count} \n  name =  ${format( consul-%02d , count.index+1)} \n  image_name =  Ubuntu 14.04 \n  flavor_name =  m1.small \n  key_pair =  infra \n  security_groups = [ AllowAll ]\n  config_drive = true\n  user_data =  ${file( scripts/bootstrap.sh )} \n  scheduler_hints {\n    group =  ${openstack_compute_servergroup_v2.consul.id} \n  }\n\n  provisioner  local-exec  {\n    command =  sed -i -e '/${self.name}/d' ~/infrastructure/nodes   echo ${self.name} ${self.access_ip_v6} consul   ~/infrastructure/nodes \n  }\n}\n\nresource  aws_route53_record   consul-v6  {\n  zone_id =  REPLACEME \n  name =  consul.example.com \n  type =  AAAA \n  ttl =  60 \n  records = [ ${replace(openstack_compute_instance_v2.consul.*.access_ip_v6,  /[\\[\\]]/ ,  )} ]\n}\n\nresource  aws_route53_record   consul-txt  {\n  zone_id =  REPLACEME \n  name =  consul.example.com \n  type =  TXT \n  ttl =  60 \n  records = [ ${formatlist( %s.example.com , openstack_compute_instance_v2.consul.*.name)} ]\n}\n\nresource  aws_route53_record   consul-individual  {\n  count =  ${var.count} \n\n  zone_id =  REPLACEME \n  name =  ${format( consul-%02d.example.com , count.index+1)} \n  type =  AAAA \n  ttl =  60 \n  records = [ ${replace(element(openstack_compute_instance_v2.consul.*.access_ip_v6, count.index),  /[\\[\\]]/ ,  )} ]\n}\n\n\nresource  null_resource   consul  {\n  count =  ${var.count} \n\n  provisioner  local-exec  {\n    command =  sleep 10   cd ~/infrastructure   make waffles NODE=${element(aws_route53_record.consul-individual.*.name, count.index)} KEY=keys/infra ROLE=consul \n  }\n}  There's a lot going on here, so let's go over each component. Some of these components will become common to see as they'll be re-used many times in future Terraform configurations.  Count  variable  count  {\n  default = 3\n}  This determines how many nodes will make up the Consul cluster. By default, this configuration will create three, however, you can choose a larger number when Terraform prompts you.  Server Group  resource  openstack_compute_servergroup_v2   consul  {\n  name =  consul \n  policies = [ anti-affinity ]\n}  A \"Server Group\" is an OpenStack-specific feature that allows instances (virtual machines / nodes) to have a common policy applied to them. In this case, an \"anti-affinity\" policy is applied. This ensures that each Consul node is hosted on a different Compute Node. This way, if there's an underlying hardware failure on one of the Compute Nodes in the OpenStack cloud, the entire Consul cluster will not be affected.  Instance  resource  openstack_compute_instance_v2   consul  {\n  count =  ${var.count} \n  name =  ${format( consul-%02d , count.index+1)} \n  image_name =  Ubuntu 14.04 \n  flavor_name =  m1.small \n  key_pair =  infra \n  security_groups = [ AllowAll ]\n  config_drive = true\n  user_data =  ${file( scripts/bootstrap.sh )} \n  scheduler_hints {\n    group =  ${openstack_compute_servergroup_v2.consul.id} \n  }\n\n  provisioner  local-exec  {\n    command =  sed -i -e '/${self.name}/d' ~/infrastructure/nodes   echo ${self.name} ${self.access_ip_v6} consul   ~/infrastructure/nodes \n  }\n}  The \"Instance\" resource is the heart of this configuration. Some notes:   Notice that there's only one \"Instance\" defined, but because  count  is set to the \"count\" variable, three (by default) will be created.  The name of each instance will take the format  consul-NN  where  NN  is the count in sequence.  The  user_data  parameter will cause the  scripts/bootstrap.sh  script to run when the instance launches.  scheduler_hints  places the instance in the Server Group previously created.   Also note the  local-exec  provisioner. This runs a simple shell command that adds the following pieces of information to  infrastructure/nodes :\n  * name\n  * IPv6 Address\n  * Role  DNS Records  resource  aws_route53_record   consul-v6  {\n  zone_id =  REPLACEME \n  name =  consul.example.com \n  type =  AAAA \n  ttl =  60 \n  records = [ ${replace(openstack_compute_instance_v2.consul.*.access_ip_v6,  /[\\[\\]]/ ,  )} ]\n}\n\nresource  aws_route53_record   consul-txt  {\n  zone_id =  REPLACEME \n  name =  consul.example.com \n  type =  TXT \n  ttl =  60 \n  records = [ ${formatlist( %s.example.com , openstack_compute_instance_v2.consul.*.name)} ]\n}\n\nresource  aws_route53_record   consul-individual  {\n  count =  ${var.count} \n\n  zone_id =  REPLACEME \n  name =  ${format( consul-%02d.example.com , count.index+1)} \n  type =  AAAA \n  ttl =  60 \n  records = [ ${replace(element(openstack_compute_instance_v2.consul.*.access_ip_v6, count.index),  /[\\[\\]]/ ,  )} ]\n}  These three resources create a series of DNS records on Amazon Route53. The first record creates an  AAAA  record called  consul.example.com . This record contains the IPv6 address of each created Consul node. Since this record holds more than one IP address, Route53 will return each address in a round-robin fashion.  The second DNS record creates a  TXT  record. This record acts as a piece of scratch paper in the DNS system. It holds the hostnames of each created Consul node and will help with bootstrapping Consul.  The third DNS record creates individual  AAAA  records for each of the Consul nodes.  Provisioner  resource  null_resource   consul  {\n  count =  ${var.count} \n\n  provisioner  local-exec  {\n    command =  sleep 10   cd ~/infrastructure   make waffles NODE=${element(aws_route53_record.consul-individual.*.name, count.index)} KEY=keys/infra ROLE=consul \n  }\n}  The final resource is a \"Null\" resource. This is a bit of a hack in Terraform to get around the fact that \"Provisioners\" must be attached to a resource of some type. It's not possible to simply have a \"Provisioning\" step.  This resource will run the commands in the  command  parameter for each of the created Consul nodes. An example of the rendered command is:  sleep 10\nmake waffles NODE=consul-01.example.com KEY=keys/infra ROLE=consul  make  corresponds to the  Makefile  created in the Intro part of this guide.  make waffles  is an actual task that was added to the  Makefile .  Of course, the Provisioner could have just gone in the Instance resource, but we want  all  resources to be created before any provisioning begins to take place. In this specific case, it's because we want the DNS records to be populated before Consul is built.  With all of this in place, let's move on to the Waffles side:", 
            "title": "Terraform"
        }, 
        {
            "location": "/guides/infra/consul/#waffles", 
            "text": "Data  To begin, create a Waffles  data  file to hold the Consul configuration data. This file will be  waffles/data/consul.sh :  consul.sh  # Tell Waffles about the user and service\nstdlib.array_push data_users  consul \nstdlib.array_push data_services  consul \n\n# Consul Version\ndata_consul_version= 0.5.2 \ndata_consul_template_version= 0.10.0 \n\n# Consul Tokens and Keys\ndata_consul_encrypt_key= CHANGEME \ndata_consul_cluster_name= consul.example.com \n\n# Describe the user\n# This user is added by common/users\ndata_user_info[consul|name]= consul \ndata_user_info[consul|uid]= 900 \ndata_user_info[consul|gid]= 900 \ndata_user_info[consul|homedir]= /var/lib/consul \n\n# Any extra generic packages\n# This package is installed by common/packages\nstdlib.array_push data_packages unzip\n\n# Consul config\ndeclare -Ag data_consul_server_config=(\n  [server]= true \n  [advertise_addr]= ${data_node_info[ip6]} \n  [client_addr]= 127.0.0.1 \n  [bind_addr]= 0.0.0.0 \n  [bootstrap_expect]= 3 \n  [datacenter]= honolulu \n  [data_dir]= /var/lib/consul \n  [encrypt]= ${data_consul_encrypt_key} \n  [enable_syslog]= true \n  [log_level]= INFO \n  [rejoin_after_leave]= true \n  [retry_interval]= 30s \n  [ui_dir]= /opt/consul-web/dist \n)\n\ndeclare -Ag data_consul_client_config=(\n  [advertise_addr]= ${data_node_info[ip6]} \n  [client_addr]= 127.0.0.1 \n  [datacenter]= honolulu \n  [data_dir]= /var/lib/consul \n  [encrypt]= ${data_consul_encrypt_key} \n  [enable_syslog]= true \n  [log_level]= INFO \n  [rejoin_after_leave]= true \n  [retry_interval]= 30s \n)\n\ndeclare -Ag data_consul_template_config=(\n  [global|consul]= localhost:8500 \n  [global|retry]= 10s \n  [global|max_stale]= 10m \n  [global|log_level]= INFO \n  [syslog|enabled]= true \n  [syslog|facility]= LOCAL5 \n)  Profile  Next, create the Consul profile. Start with the directory structure:  waffles/profiles/consul/scripts . Inside  scripts , create the following scripts:  client.sh  stdlib.title  consul/client \n\n_user= ${data_user_info[consul|name]} \n\n# Consul Directories\nstdlib.directory --name /var/lib/consul --owner $_user --group $_user --mode 750\nstdlib.directory --name /etc/consul --owner $_user --group $_user --mode 750\nstdlib.directory --name /etc/consul/agent --owner $_user --group $_user --mode 750\nstdlib.directory --name /etc/consul/agent/conf.d --owner $_user --group $_user --mode 750\nstdlib.file --name /var/log/consul.log --owner $_user --group $_user --mode 640\n\n# Install Consul\nif [[ ! -f /usr/local/bin/consul ]]; then\n  stdlib.mute pushd /tmp\n    stdlib.capture_error wget https://dl.bintray.com/mitchellh/consul/${data_consul_version}_linux_amd64.zip\n    stdlib.capture_error unzip ${data_consul_version}_linux_amd64.zip\n    stdlib.capture_error mv consul /usr/local/bin\n  stdlib.mute popd\nfi\n\n# Configure Consul\nfor key in  ${!data_consul_client_config[@]} ; do\n  augeas.json_dict --file  /etc/consul/agent/conf.d/config.json  --path / --key  $key  --value  ${data_consul_client_config[$key]} \ndone\n\naugeas.json_array --file  /etc/consul/agent/conf.d/config.json  --path / --key  retry_join  --value  $data_consul_cluster_name \n\n# Consul Service\nstdlib.file --name /etc/init/consul.conf --source  $WAFFLES_SITE_DIR/profiles/consul/files/consul.conf \nstdlib.upstart --name consul --state running  server.sh  stdlib.title  consul/server \n\n_user= ${data_user_info[consul|name]} \n\n# Consul Directories\nstdlib.directory --name /var/lib/consul --owner $_user --group $_user --mode 750\nstdlib.directory --name /etc/consul --owner $_user --group $_user --mode 750\nstdlib.directory --name /etc/consul/agent --owner $_user --group $_user --mode 750\nstdlib.directory --name /etc/consul/agent/conf.d --owner $_user --group $_user --mode 750\nstdlib.directory --name /opt/consul-web --owner $_user --group $_user --mode 750\nstdlib.file --name /var/log/consul.log --owner $_user --group $_user --mode 640\n\n# Install Consul\nif [[ ! -f /usr/local/bin/consul ]]; then\n  stdlib.mute pushd /tmp\n    stdlib.capture_error wget https://dl.bintray.com/mitchellh/consul/${data_consul_version}_linux_amd64.zip\n    stdlib.capture_error unzip ${data_consul_version}_linux_amd64.zip\n    stdlib.capture_error mv consul /usr/local/bin\n  stdlib.mute popd\nfi\n\n# Configure Consul\nfor key in  ${!data_consul_server_config[@]} ; do\n  augeas.json_dict --file  /etc/consul/agent/conf.d/config.json  --path / --key  $key  --value  ${data_consul_server_config[$key]} \ndone\n\nfor attempt in {1..10}; do\n  _nodes=($(dig +short -t txt $data_consul_cluster_name | sort | tr -d \\ ))\n  if [[ -z  $_nodes  ]]; then\n    stdlib.warn  No consul nodes found. Sleeping \n    sleep 60\n  else\n    break\n  fi\ndone\n\nfor _node in  ${_nodes[@]} ; do\n  _consul_nodes= ${_consul_nodes}--value ${_node}  \ndone\n\naugeas.json_array --file  /etc/consul/agent/conf.d/config.json  --path / --key  retry_join  $_consul_nodes\n\nstdlib.file --name /usr/local/bin/purge_failed.sh --mode  750  --source  $WAFFLES_SITE_DIR/profiles/consul/files/purge_failed.sh \nstdlib.cron --name consul_purge_failed_nodes --cmd /usr/local/bin/purge_failed.sh\n\n# Server nodes get the web UI\nif [[ ! -d /opt/consul-web/dist ]]; then\n  stdlib.mute pushd /tmp\n    stdlib.capture_error wget https://dl.bintray.com/mitchellh/consul/${data_consul_version}_web_ui.zip\n    stdlib.capture_error unzip -d /opt/consul-web ${data_consul_version}_web_ui.zip\n    stdlib.capture_error chown -R consul: /opt/consul-web\n  stdlib.mute popd\nfi\n\n# Consul Service\nstdlib.file --name /etc/init/consul.conf --source  $WAFFLES_SITE_DIR/profiles/consul/files/consul.conf \nstdlib.upstart --name consul --state running  The unique thing about this script is the use of polling the  TXT  file created by Terraform. In order for Consul to bootstrap itself, it needs to first know of a few neighboring nodes. By polling the  TXT  record, it can get a list of those nodes.  template.sh  stdlib.title  consul/template \n\n_user= ${data_user_info[consul|name]} \n\n# Consul Template Directories\nstdlib.directory --name /etc/consul/template --owner $_user --group $_user --mode 750\nstdlib.directory --name /etc/consul/template/ctmpl --owner $_user --group $_user --mode 750\nstdlib.directory --name /etc/consul/template/conf.d --owner $_user --group $_user --mode 750\nstdlib.file --name /var/log/consul-template.log --owner root --group syslog --mode 640\nstdlib.file --name /etc/init/consul-template.conf --source  $WAFFLES_SITE_DIR/profiles/consul/files/consul-template.conf \n\nif [[ ! -f /usr/local/bin/consul-template ]]; then\n  stdlib.mute pushd /tmp\n    stdlib.capture_error wget https://github.com/hashicorp/consul-template/releases/download/v${data_consul_template_version}/consul-template_${data_consul_template_version}_linux_amd64.tar.gz\n    stdlib.capture_error tar xzvf consul-template_${data_consul_template_version}_linux_amd64.tar.gz\n    stdlib.capture_error mv consul-template_${data_consul_template_version}_linux_amd64/consul-template /usr/local/bin\n  stdlib.mute popd\nfi\n\nfor key in  ${!data_consul_template_config[@]} ; do\n  stdlib.split $key  | \n  _section= ${__split[0]} \n  _option= ${__split[1]} \n\n  if [[ $_section ==  global  ]]; then\n    augeas.json_dict --file  /etc/consul/template/conf.d/config.json  --path / --key  $_option  --value  ${data_consul_template_config[$key]} \n  else\n    augeas.json_dict --file  /etc/consul/template/conf.d/config.json  --path  /$_section  --key  $_option  --value  ${data_consul_template_config[$key]} \n  fi\ndone\n\nstdlib.upstart --name consul-template --state running  The above script sets up  Consul Template  template-hosts.sh  stdlib.title  consul/template_hosts \n\nconsul.template --name hosts --destination /etc/hosts\nstdlib.file --name /etc/consul/template/ctmpl/hosts.ctmpl --mode 640 --source  $WAFFLES_SITE_DIR/profiles/consul/files/hosts.ctmpl \n\nif [[ $stdlib_state_change ==  true  ]]; then\n  restart consul-template\nfi  The above script configures the  /etc/hosts  file to be populated by the nodes that Consul knows about.  Files  The above scripts reference some static files that need to be installed on the nodes. For brevity, you can find these scripts in the Git repo linked at the end of this document.  Role  With the Consul Data and Profile in place, it's time to build the role. Create the file  waffles/roles/consul.sh  with the following contents:  stdlib.enable_augeas\nstdlib.enable_consul\n\nstdlib.data common\nstdlib.data consul\n\nstdlib.profile common/acng\nstdlib.profile common/packages\nstdlib.profile common/users\nstdlib.profile common/updates\nstdlib.profile common/sudo\n\nstdlib.profile augeas/apt_install\nstdlib.profile augeas/update_lenses\n\nstdlib.profile consul/server\nstdlib.profile consul/template\nstdlib.profile consul/template_hosts  The  stdlib.enable_augeas  and  stdlib.enable_consul  commands are built-in to Waffles. They enable augeas and consul-specific functions and resources. See the Waffles documentation for more information.  The rest of the role should be self-explanatory: the  common  and  consul  data files are being read, then the  common ,  augeas  and  consul  profiles. Everything combined makes up a unique \"Consul\" role.", 
            "title": "Waffles"
        }, 
        {
            "location": "/guides/infra/consul/#deploying", 
            "text": "To deploy the cluster, do the following:  $ make tplan ROLE=consul\n$ make tapply ROLE=consul  If everything was successful, you should have a running Consul cluster. You can verify this by doing:  $ ssh -i keys/infra consul.example.com\n$ consul status", 
            "title": "Deploying"
        }, 
        {
            "location": "/guides/infra/consul/#consul-key-value-storage", 
            "text": "Consul was setup in a way that restricts access to the key-value store to only nodes running Consul. Terraform provides a  consul_keys  resource that can store data from the Terraform configuration in Consul. Rather than installing Consul on your workstation, an alternative is to SSH into the Consul cluster and forward the port 8500. To do this, make a new task in the  Makefile  called  ctunnel :  ctunnel:\n  ssh -i keys/infra -L 8500:localhost:8500 consul.example.com  Now run the task:  $ make ctunnel  You should now have forwarded access to your Consul cluster.", 
            "title": "Consul Key-Value Storage"
        }, 
        {
            "location": "/guides/infra/consul/#conclusion", 
            "text": "This part of the Infrastructure guide detailed how to deploy a Consul cluster. At this point, your directory structure should look like:  infrastructure\n\u251c\u2500\u2500 keys\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 infra\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 infra.pub\n\u251c\u2500\u2500 Makefile\n\u251c\u2500\u2500 nodes\n\u251c\u2500\u2500 rc\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 aws\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 openstack\n\u251c\u2500\u2500 terraform\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 consul\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 main.tf\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 scripts\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 bootstrap.sh\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 support\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 main.tf\n\u2514\u2500\u2500 waffles\n    \u251c\u2500\u2500 data\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 common.sh\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 consul.sh\n    \u251c\u2500\u2500 profiles\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 augeas\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 scripts\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 apt_install.sh\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 update_lenses.sh\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 common\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 scripts\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 acng.sh\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 packages.sh\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 sudo.sh\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 updates.sh\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 users.sh\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 consul\n    \u2502\u00a0\u00a0     \u251c\u2500\u2500 files\n    \u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 consul.conf\n    \u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 consul-template.conf\n    \u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 hosts.ctmpl\n    \u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2514\u2500\u2500 purge_failed.sh\n    \u2502\u00a0\u00a0     \u2514\u2500\u2500 scripts\n    \u2502\u00a0\u00a0         \u251c\u2500\u2500 client.sh\n    \u2502\u00a0\u00a0         \u251c\u2500\u2500 server.sh\n    \u2502\u00a0\u00a0         \u251c\u2500\u2500 template_hosts.sh\n    \u2502\u00a0\u00a0         \u2514\u2500\u2500 template.sh\n    \u2514\u2500\u2500 roles\n        \u2514\u2500\u2500 consul.sh  You can find the final scripts and structure  here .", 
            "title": "Conclusion"
        }, 
        {
            "location": "/resources/", 
            "text": "Waffles Resources\n\n\n\n\n\n\nWaffles Resources\n\n\nLocation\n\n\nEnabling Non-Standard Resources\n\n\nAnatomy of a Resource\n\n\nHeader\n\n\nfunction resource.name\n\n\nfunction stdlib.resource.process\n\n\nfunction resource.name.x\n\n\nfunction resource.name.read\n\n\nfunction resource.name.create\n\n\nfunction resource.name.update\n\n\nfunction resource.name.delete\n\n\n\n\n\n\nState Changes\n\n\nExamples\n\n\n\n\n\n\n\n\n\n\nThis document will cover how resources are used in Waffles.\n\n\nLocation\n\n\nAll resources are stored in the \n$WAFFLES_DIR/lib\n directory:\n\n\n\n\nThe Standard Library of resources is located in \n$WAFFLES_DIR/lib/resources\n.\n\n\nApache-based resources are located in \n$WAFFLES_DIR/lib/apache\n.\n\n\nAugeas-based resources are located in \n$WAFFLES_DIR/lib/augeas\n.\n\n\nConsul-based resources are located in \n$WAFFLES_DIR/lib/consul\n.\n\n\nKeepalived-based resources are located in \n$WAFFLES_DIR/lib/keepalived\n.\n\n\nMySQL-based resources are located in \n$WAFFLES_DIR/lib/mysql\n.\n\n\nNginx-based resources are located in \n$WAFFLES_DIR/lib/nginx\n.\n\n\nRabbitMQ-based resources are located in \n$WAFFLES_DIR/lib/rabbitmq\n.\n\n\n\n\nEnabling Non-Standard Resources\n\n\nBy default, only the Standard Library is enabled in Waffles. To enable the other resources, use the following functions:\n\n\n\n\nApache: \nstdlib.enable_apache\n\n\nAugeas: \nstdlib.enable_augeas\n\n\nConsul: \nstdlib.enable_consul\n\n\nKeepalived: \nstdlib.enable_keepalived\n\n\nMySQL: \nstdlib.enable_mysql\n\n\nNginx: \nstdlib.enable_nginx\n\n\nRabbitMQ: \nstdlib.enable_rabbitmq\n\n\n\n\nAnatomy of a Resource\n\n\nHeader\n\n\nEach resource has a detailed comment header. This header describes what the resource does, what parameters it takes, how to use it, and any comments. The comment header is very important as this is where the resource documentation is generated from.\n\n\nfunction resource.name\n\n\nThe next part of a resource is the first \"function\". This first function is named after the resource name. So any time you use a resource, you're actually just calling a Bash function.\n\n\nThe first thing done inside this function is to call a \"subtitle\" with \nstdlib.subtitle\n. Subtitles serve two purposes:\n\n\n\n\nThey set the name to be printed when running Waffles.\n\n\nThey reset an internal flag for changes made in the resource. This flag is called \nstdlib_resource_change\n. See the \"State Changes\" section for more details.\n\n\n\n\nNext, an \noptions\n variable is declared. It is important that this variable is declared in each resource. If not, then the resource will share variables with the last called resource. After the \noptions\n variable is declared, any parameters for the resource are declared. Finally, variables are checked via \nstdlib.options.parse_options\n. All logic related to \noptions\n can be found in \n$WAFFLES_DIR/lib/options.sh\n.\n\n\nAfter options, any local variables are defined.\n\n\nNext, any optional custom logic is defined. This usually includes local variables just for the resource or ensuring that correctly formatted parameters were given.\n\n\nNext, \nstdlib.resource.process\n is called.\n\n\nfunction stdlib.resource.process\n\n\nThis is a centralized function that was introduced to help reduce repeated code in all resources. It does the following:\n\n\n\n\nA catalog entry is made.\n\n\nstdlib.resource.read\n is called, which in turn calls \ncalling_resource.read\n.\n\n\nA comparison is made of the resource state versus the state that the resource should be in.\n\n\nDepending on the results of the above, \nstdlib.resource.x\n is called, which in turn calls \ncalling_resource.x\n.\n\n\n\n\nEach of the \nstdlib.resource.x\n functions do a few other things like determine if a resource change was made and how many changes were made throughout the entire run. In the future, these functions may also generate summary reports of the run.\n\n\nfunction resource.name.x\n\n\nThe rest of the resource is made up of four standard functions:\n\n\n\n\nfunction.name.read\n\n\nfunction.name.create\n\n\nfunction.name.update\n\n\nfunction.name.delete\n\n\n\n\nSome resources contain extra functions, but they always tie back into those standard four. Sometimes \nfunction.name.update\n just calls \ndelete\n and \ncreate\n.\n\n\nIf you create a resource that conforms to those four functions, it'll work just fine in Waffles.\n\n\nfunction resource.name.read\n\n\nThe \nread\n function determines the current state of the resource. For example, \nstdlib.apt.read\n determines if the package is installed, and if so, what version is installed.\n\n\nfunction resource.name.create\n\n\nThe \ncreate\n function does whatever is required to create the the resource. For example, \nstdlib.apt.create\n installs a package via \napt\n and \nstdlib.file_line.create\n adds a line to a given file either by \necho\n or \nsed\n.\n\n\nIt's important to try to stick with a core philosophy of Waffles: use standard nix utilities for the creation of resources.\n\n\nfunction resource.name.update\n\n\nIf the work required to update a resource is different than creating a resource, use the \nupdate\n function. However, if it's easier to simply delete the resource and recreate it, then do that instead of an update function. Just don't use that method as an excuse.\n\n\nfunction resource.name.delete\n\n\nThis function deletes the resource. For example, \nstdlib.apt.delete\n will actually remove the package.\n\n\nState Changes\n\n\nAfter you call a resource, you can check the status of the \nstdlib_resource_change\n flag. If it is true, then a change happened when you called the resource. For example:\n\n\nstdlib.apt --package sl --version latest\n\nif [[ $stdlib_resource_change == \ntrue\n ]]; then\n  stdlib.info \nPackage sl was installed or upgraded.\n\nfi\n\n\n\n\nSimilar to \nstdlib_resource_change\n is \nstdlib_state_change\n. \nstdlib_state_change\n works in the exact same way, but it is reset when a call to \nstdlib.title\n is made. You usually use \nstdlib.title\n at the beginning of Profiles.\n\n\nExamples\n\n\nUse the Standard Library and Augeas resources as examples of how resources are built.", 
            "title": "Internals"
        }, 
        {
            "location": "/resources/#waffles-resources", 
            "text": "Waffles Resources  Location  Enabling Non-Standard Resources  Anatomy of a Resource  Header  function resource.name  function stdlib.resource.process  function resource.name.x  function resource.name.read  function resource.name.create  function resource.name.update  function resource.name.delete    State Changes  Examples      This document will cover how resources are used in Waffles.", 
            "title": "Waffles Resources"
        }, 
        {
            "location": "/resources/#location", 
            "text": "All resources are stored in the  $WAFFLES_DIR/lib  directory:   The Standard Library of resources is located in  $WAFFLES_DIR/lib/resources .  Apache-based resources are located in  $WAFFLES_DIR/lib/apache .  Augeas-based resources are located in  $WAFFLES_DIR/lib/augeas .  Consul-based resources are located in  $WAFFLES_DIR/lib/consul .  Keepalived-based resources are located in  $WAFFLES_DIR/lib/keepalived .  MySQL-based resources are located in  $WAFFLES_DIR/lib/mysql .  Nginx-based resources are located in  $WAFFLES_DIR/lib/nginx .  RabbitMQ-based resources are located in  $WAFFLES_DIR/lib/rabbitmq .", 
            "title": "Location"
        }, 
        {
            "location": "/resources/#enabling-non-standard-resources", 
            "text": "By default, only the Standard Library is enabled in Waffles. To enable the other resources, use the following functions:   Apache:  stdlib.enable_apache  Augeas:  stdlib.enable_augeas  Consul:  stdlib.enable_consul  Keepalived:  stdlib.enable_keepalived  MySQL:  stdlib.enable_mysql  Nginx:  stdlib.enable_nginx  RabbitMQ:  stdlib.enable_rabbitmq", 
            "title": "Enabling Non-Standard Resources"
        }, 
        {
            "location": "/resources/#anatomy-of-a-resource", 
            "text": "Header  Each resource has a detailed comment header. This header describes what the resource does, what parameters it takes, how to use it, and any comments. The comment header is very important as this is where the resource documentation is generated from.  function resource.name  The next part of a resource is the first \"function\". This first function is named after the resource name. So any time you use a resource, you're actually just calling a Bash function.  The first thing done inside this function is to call a \"subtitle\" with  stdlib.subtitle . Subtitles serve two purposes:   They set the name to be printed when running Waffles.  They reset an internal flag for changes made in the resource. This flag is called  stdlib_resource_change . See the \"State Changes\" section for more details.   Next, an  options  variable is declared. It is important that this variable is declared in each resource. If not, then the resource will share variables with the last called resource. After the  options  variable is declared, any parameters for the resource are declared. Finally, variables are checked via  stdlib.options.parse_options . All logic related to  options  can be found in  $WAFFLES_DIR/lib/options.sh .  After options, any local variables are defined.  Next, any optional custom logic is defined. This usually includes local variables just for the resource or ensuring that correctly formatted parameters were given.  Next,  stdlib.resource.process  is called.  function stdlib.resource.process  This is a centralized function that was introduced to help reduce repeated code in all resources. It does the following:   A catalog entry is made.  stdlib.resource.read  is called, which in turn calls  calling_resource.read .  A comparison is made of the resource state versus the state that the resource should be in.  Depending on the results of the above,  stdlib.resource.x  is called, which in turn calls  calling_resource.x .   Each of the  stdlib.resource.x  functions do a few other things like determine if a resource change was made and how many changes were made throughout the entire run. In the future, these functions may also generate summary reports of the run.  function resource.name.x  The rest of the resource is made up of four standard functions:   function.name.read  function.name.create  function.name.update  function.name.delete   Some resources contain extra functions, but they always tie back into those standard four. Sometimes  function.name.update  just calls  delete  and  create .  If you create a resource that conforms to those four functions, it'll work just fine in Waffles.  function resource.name.read  The  read  function determines the current state of the resource. For example,  stdlib.apt.read  determines if the package is installed, and if so, what version is installed.  function resource.name.create  The  create  function does whatever is required to create the the resource. For example,  stdlib.apt.create  installs a package via  apt  and  stdlib.file_line.create  adds a line to a given file either by  echo  or  sed .  It's important to try to stick with a core philosophy of Waffles: use standard nix utilities for the creation of resources.  function resource.name.update  If the work required to update a resource is different than creating a resource, use the  update  function. However, if it's easier to simply delete the resource and recreate it, then do that instead of an update function. Just don't use that method as an excuse.  function resource.name.delete  This function deletes the resource. For example,  stdlib.apt.delete  will actually remove the package.", 
            "title": "Anatomy of a Resource"
        }, 
        {
            "location": "/resources/#state-changes", 
            "text": "After you call a resource, you can check the status of the  stdlib_resource_change  flag. If it is true, then a change happened when you called the resource. For example:  stdlib.apt --package sl --version latest\n\nif [[ $stdlib_resource_change ==  true  ]]; then\n  stdlib.info  Package sl was installed or upgraded. \nfi  Similar to  stdlib_resource_change  is  stdlib_state_change .  stdlib_state_change  works in the exact same way, but it is reset when a call to  stdlib.title  is made. You usually use  stdlib.title  at the beginning of Profiles.", 
            "title": "State Changes"
        }, 
        {
            "location": "/resources/#examples", 
            "text": "Use the Standard Library and Augeas resources as examples of how resources are built.", 
            "title": "Examples"
        }, 
        {
            "location": "/resources/stdlib.apt_key/", 
            "text": "stdlib.apt_key\n\n\nDescription\n\n\nManages apt keys\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nname: An arbitrary name. Required. namevar.\n\n\nkey: The key to import. Required if no remote_keyfile.\n\n\nkeyserver: The key server. Required if no remote_keyfile.\n\n\nremote_keyfile: A remote key to import. Required if no key or keyserver.\n\n\n\n\nExample\n\n\nstdlib.apt_key --name \nfoobar\n --key 1C4CBDCDCD2EFD2A", 
            "title": "stdlib.apt_key"
        }, 
        {
            "location": "/resources/stdlib.apt_key/#stdlibapt_key", 
            "text": "", 
            "title": "stdlib.apt_key"
        }, 
        {
            "location": "/resources/stdlib.apt_key/#description", 
            "text": "Manages apt keys", 
            "title": "Description"
        }, 
        {
            "location": "/resources/stdlib.apt_key/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  name: An arbitrary name. Required. namevar.  key: The key to import. Required if no remote_keyfile.  keyserver: The key server. Required if no remote_keyfile.  remote_keyfile: A remote key to import. Required if no key or keyserver.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/stdlib.apt_key/#example", 
            "text": "stdlib.apt_key --name  foobar  --key 1C4CBDCDCD2EFD2A", 
            "title": "Example"
        }, 
        {
            "location": "/resources/stdlib.apt_ppa/", 
            "text": "stdlib.apt_ppa\n\n\nDescription\n\n\nManages PPA repositories\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nppa: The PPA. Required. namevar.\n\n\nrefresh: run apt-get update if the PPA was modified. Default: true.\n\n\n\n\nExample\n\n\nstdlib.apt_ppa --ppa ppa:chris-lea/redis-server", 
            "title": "stdlib.apt_ppa"
        }, 
        {
            "location": "/resources/stdlib.apt_ppa/#stdlibapt_ppa", 
            "text": "", 
            "title": "stdlib.apt_ppa"
        }, 
        {
            "location": "/resources/stdlib.apt_ppa/#description", 
            "text": "Manages PPA repositories", 
            "title": "Description"
        }, 
        {
            "location": "/resources/stdlib.apt_ppa/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  ppa: The PPA. Required. namevar.  refresh: run apt-get update if the PPA was modified. Default: true.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/stdlib.apt_ppa/#example", 
            "text": "stdlib.apt_ppa --ppa ppa:chris-lea/redis-server", 
            "title": "Example"
        }, 
        {
            "location": "/resources/stdlib.apt/", 
            "text": "stdlib.apt\n\n\nDescription\n\n\nManage packages via apt.\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\npackage: The name of the package. Required. namevar.\n\n\nversion: The version of the package. Leave empty for first version found. Set to \"latest\" to always update.\n\n\n\n\nExample\n\n\nstdlib.apt --package tmux --version latest", 
            "title": "stdlib.apt"
        }, 
        {
            "location": "/resources/stdlib.apt/#stdlibapt", 
            "text": "", 
            "title": "stdlib.apt"
        }, 
        {
            "location": "/resources/stdlib.apt/#description", 
            "text": "Manage packages via apt.", 
            "title": "Description"
        }, 
        {
            "location": "/resources/stdlib.apt/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  package: The name of the package. Required. namevar.  version: The version of the package. Leave empty for first version found. Set to \"latest\" to always update.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/stdlib.apt/#example", 
            "text": "stdlib.apt --package tmux --version latest", 
            "title": "Example"
        }, 
        {
            "location": "/resources/stdlib.apt_source/", 
            "text": "stdlib.apt_source\n\n\nDescription\n\n\nManage /etc/apt/sources.list.d entries.\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nname: The name of the apt repo. Required.\n\n\nuri: The URI of the apt repo. Required.\n\n\ndistribution: The distribution of the apt repo. Required.\n\n\ncomponent: The component of the apt repo. Required.\n\n\ninclude_src: Whether to include the source repo. Default: false.\n\n\nrefresh: run apt-get update if the source was modified. Default: true.\n\n\n\n\nExample\n\n\nstdlib.apt_source --name lxc --uri http://ppa.launchpad.net/ubuntu-lxc/stable/ubuntu \\\n                  --distribution trusty --component main", 
            "title": "stdlib.apt_source"
        }, 
        {
            "location": "/resources/stdlib.apt_source/#stdlibapt_source", 
            "text": "", 
            "title": "stdlib.apt_source"
        }, 
        {
            "location": "/resources/stdlib.apt_source/#description", 
            "text": "Manage /etc/apt/sources.list.d entries.", 
            "title": "Description"
        }, 
        {
            "location": "/resources/stdlib.apt_source/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  name: The name of the apt repo. Required.  uri: The URI of the apt repo. Required.  distribution: The distribution of the apt repo. Required.  component: The component of the apt repo. Required.  include_src: Whether to include the source repo. Default: false.  refresh: run apt-get update if the source was modified. Default: true.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/stdlib.apt_source/#example", 
            "text": "stdlib.apt_source --name lxc --uri http://ppa.launchpad.net/ubuntu-lxc/stable/ubuntu \\\n                  --distribution trusty --component main", 
            "title": "Example"
        }, 
        {
            "location": "/resources/stdlib.cron/", 
            "text": "stdlib.cron\n\n\nDescription\n\n\nManages cron entries\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nname: A single-word name for the cron. Required. namevar.\n\n\nuser: The user to run the cron job as. Default: root.\n\n\ncmd: The command to run. Required.\n\n\nminute: The minute field of the cron. Default: *.\n\n\nhour: The hour field of the cron. Default: *.\n\n\ndom: The day of month field for the cron. Default: *.\n\n\nmonth: The month field of the cron. Default: *.\n\n\ndow: The day of week field of the cron. Default: *.\n\n\n\n\nExample\n\n\nstdlib.cron --name foobar --cmd /path/to/some/report --minute \n*/5\n\n\n\n\n\nTODO\n\n\nAdd support for prefix info such as PATH, MAILTO.", 
            "title": "stdlib.cron"
        }, 
        {
            "location": "/resources/stdlib.cron/#stdlibcron", 
            "text": "", 
            "title": "stdlib.cron"
        }, 
        {
            "location": "/resources/stdlib.cron/#description", 
            "text": "Manages cron entries", 
            "title": "Description"
        }, 
        {
            "location": "/resources/stdlib.cron/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  name: A single-word name for the cron. Required. namevar.  user: The user to run the cron job as. Default: root.  cmd: The command to run. Required.  minute: The minute field of the cron. Default: *.  hour: The hour field of the cron. Default: *.  dom: The day of month field for the cron. Default: *.  month: The month field of the cron. Default: *.  dow: The day of week field of the cron. Default: *.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/stdlib.cron/#example", 
            "text": "stdlib.cron --name foobar --cmd /path/to/some/report --minute  */5", 
            "title": "Example"
        }, 
        {
            "location": "/resources/stdlib.cron/#todo", 
            "text": "Add support for prefix info such as PATH, MAILTO.", 
            "title": "TODO"
        }, 
        {
            "location": "/resources/stdlib.debconf/", 
            "text": "stdlib.debconf\n\n\nDescription\n\n\nManages debconf entries\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nname: An arbitrary name. Required. namevar.\n\n\npackage: The package to configure. Required.\n\n\nquestion: The debconf question. Required.\n\n\nvtype: The vtype of the debconf setting. Required.\n\n\nvalue: The answer/setting. Required.\n\n\n\n\nExample\n\n\nstdlib.debconf --package mysql-server --question mysql-server/root_password\n               --vtype password --value mypassword", 
            "title": "stdlib.debconf"
        }, 
        {
            "location": "/resources/stdlib.debconf/#stdlibdebconf", 
            "text": "", 
            "title": "stdlib.debconf"
        }, 
        {
            "location": "/resources/stdlib.debconf/#description", 
            "text": "Manages debconf entries", 
            "title": "Description"
        }, 
        {
            "location": "/resources/stdlib.debconf/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  name: An arbitrary name. Required. namevar.  package: The package to configure. Required.  question: The debconf question. Required.  vtype: The vtype of the debconf setting. Required.  value: The answer/setting. Required.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/stdlib.debconf/#example", 
            "text": "stdlib.debconf --package mysql-server --question mysql-server/root_password\n               --vtype password --value mypassword", 
            "title": "Example"
        }, 
        {
            "location": "/resources/stdlib.directory/", 
            "text": "stdlib.directory\n\n\nDescription\n\n\nManages directories\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nowner: The owner of the directory. Default: root.\n\n\ngroup: The group of the directory. Default: root.\n\n\nmode: The perms/mode of the directory. Default: 750.\n\n\nname: The destination directory. Required. namevar.\n\n\nsource: Optional source directory to copy.\n\n\nrecurse: Whether to apply all settings recursively. Optional.\n\n\nparent: Whether to make the parent directories. Optional.\n\n\n\n\nExample\n\n\nstdlib.directory --source $WAFFLES_SITE_DIR/profiles/foo/files/mydir --name /var/lib/mydir", 
            "title": "stdlib.directory"
        }, 
        {
            "location": "/resources/stdlib.directory/#stdlibdirectory", 
            "text": "", 
            "title": "stdlib.directory"
        }, 
        {
            "location": "/resources/stdlib.directory/#description", 
            "text": "Manages directories", 
            "title": "Description"
        }, 
        {
            "location": "/resources/stdlib.directory/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  owner: The owner of the directory. Default: root.  group: The group of the directory. Default: root.  mode: The perms/mode of the directory. Default: 750.  name: The destination directory. Required. namevar.  source: Optional source directory to copy.  recurse: Whether to apply all settings recursively. Optional.  parent: Whether to make the parent directories. Optional.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/stdlib.directory/#example", 
            "text": "stdlib.directory --source $WAFFLES_SITE_DIR/profiles/foo/files/mydir --name /var/lib/mydir", 
            "title": "Example"
        }, 
        {
            "location": "/resources/stdlib.file_line/", 
            "text": "stdlib.file_line\n\n\nDescription\n\n\nManages single lines in a file.\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nname: An arbitrary name for the resource. namevar.\n\n\nline: The line to manage. Required.\n\n\nfile: The file that the line belongs to. Required.\n\n\nmatch: A regex to match to. Optional.\n\n\n\n\nExample\n\n\nstdlib.file_line --name \n/etc/memcached.conf -l\n \\\n                 --file /etc/memcached.conf \\\n                 --line \n-l 0.0.0.0\n --match \n^-l", 
            "title": "stdlib.file_line"
        }, 
        {
            "location": "/resources/stdlib.file_line/#stdlibfile_line", 
            "text": "", 
            "title": "stdlib.file_line"
        }, 
        {
            "location": "/resources/stdlib.file_line/#description", 
            "text": "Manages single lines in a file.", 
            "title": "Description"
        }, 
        {
            "location": "/resources/stdlib.file_line/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  name: An arbitrary name for the resource. namevar.  line: The line to manage. Required.  file: The file that the line belongs to. Required.  match: A regex to match to. Optional.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/stdlib.file_line/#example", 
            "text": "stdlib.file_line --name  /etc/memcached.conf -l  \\\n                 --file /etc/memcached.conf \\\n                 --line  -l 0.0.0.0  --match  ^-l", 
            "title": "Example"
        }, 
        {
            "location": "/resources/stdlib.file/", 
            "text": "stdlib.file\n\n\nDescription\n\n\nManages files\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nowner: The owner of the directory. Default: root.\n\n\ngroup: The group of the directory. Default: root.\n\n\nmode: The perms/mode of the directory. Default: 750.\n\n\nname: The destination file. Required. namevar.\n\n\ncontent: STDIN content for the file. Optional.\n\n\nsource: Source directory to copy. Optional.\n\n\n\n\nExample\n\n\nstdlib.file --name /etc/foobar --content \nHello, World!", 
            "title": "stdlib.file"
        }, 
        {
            "location": "/resources/stdlib.file/#stdlibfile", 
            "text": "", 
            "title": "stdlib.file"
        }, 
        {
            "location": "/resources/stdlib.file/#description", 
            "text": "Manages files", 
            "title": "Description"
        }, 
        {
            "location": "/resources/stdlib.file/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  owner: The owner of the directory. Default: root.  group: The group of the directory. Default: root.  mode: The perms/mode of the directory. Default: 750.  name: The destination file. Required. namevar.  content: STDIN content for the file. Optional.  source: Source directory to copy. Optional.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/stdlib.file/#example", 
            "text": "stdlib.file --name /etc/foobar --content  Hello, World!", 
            "title": "Example"
        }, 
        {
            "location": "/resources/stdlib.git/", 
            "text": "stdlib.git\n\n\nDescription\n\n\nManage a git repository\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nname: The name (path) of the git repo destination. Required.\n\n\nsource: The URI of the source git repo. Required.\n\n\nbranch: The branch to checkout. Optional. Default: master.\n\n\ntag: The tag to checkout. Optional.\n\n\ncommit: the commit to checkout. Optional.\n\n\nowner: The owner of the repo. Default: root.\n\n\ngroup: The group owner of the repo. Default: root.\n\n\n\n\nExample\n\n\ngit --state latest --name /root/.dotfiles --source https://github.com/jtopjian/dotfiles\n\n\n\n\nNotes\n\n\nIf state is set to \"latest\", Waffles will do a \ngit pull\n, if it's able to.\n\n\nThe order of checkout preferences is:\n\n\n\n\ncommit\n\n\ntag\n\n\nbranch", 
            "title": "stdlib.git"
        }, 
        {
            "location": "/resources/stdlib.git/#stdlibgit", 
            "text": "", 
            "title": "stdlib.git"
        }, 
        {
            "location": "/resources/stdlib.git/#description", 
            "text": "Manage a git repository", 
            "title": "Description"
        }, 
        {
            "location": "/resources/stdlib.git/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  name: The name (path) of the git repo destination. Required.  source: The URI of the source git repo. Required.  branch: The branch to checkout. Optional. Default: master.  tag: The tag to checkout. Optional.  commit: the commit to checkout. Optional.  owner: The owner of the repo. Default: root.  group: The group owner of the repo. Default: root.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/stdlib.git/#example", 
            "text": "git --state latest --name /root/.dotfiles --source https://github.com/jtopjian/dotfiles", 
            "title": "Example"
        }, 
        {
            "location": "/resources/stdlib.git/#notes", 
            "text": "If state is set to \"latest\", Waffles will do a  git pull , if it's able to.  The order of checkout preferences is:   commit  tag  branch", 
            "title": "Notes"
        }, 
        {
            "location": "/resources/stdlib.groupadd/", 
            "text": "stdlib.groupadd\n\n\nDescription\n\n\nManages groups\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\ngroup: The group. Required. namevar.\n\n\ngid: The gid of the group. Optional.\n\n\n\n\nExample\n\n\nstdlib.groupadd --group jdoe --gid 999", 
            "title": "stdlib.groupadd"
        }, 
        {
            "location": "/resources/stdlib.groupadd/#stdlibgroupadd", 
            "text": "", 
            "title": "stdlib.groupadd"
        }, 
        {
            "location": "/resources/stdlib.groupadd/#description", 
            "text": "Manages groups", 
            "title": "Description"
        }, 
        {
            "location": "/resources/stdlib.groupadd/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  group: The group. Required. namevar.  gid: The gid of the group. Optional.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/stdlib.groupadd/#example", 
            "text": "stdlib.groupadd --group jdoe --gid 999", 
            "title": "Example"
        }, 
        {
            "location": "/resources/stdlib.ini/", 
            "text": "stdlib.ini\n\n\nDescription\n\n\nManages ini files/entries\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nfile: The ini file. Required.\n\n\nsection: The ini file section. Use \"\nnone\n\" to not use a section. Required.\n\n\noption: The ini file setting/option. Required.\n\n\nvalue: The value of the option. Use \"\nnone\n\" to not set a value. Required.\n\n\n\n\nExample\n\n\nstdlib.ini --file /etc/nova/nova.conf --section DEFAULT --option debug --value True", 
            "title": "stdlib.ini"
        }, 
        {
            "location": "/resources/stdlib.ini/#stdlibini", 
            "text": "", 
            "title": "stdlib.ini"
        }, 
        {
            "location": "/resources/stdlib.ini/#description", 
            "text": "Manages ini files/entries", 
            "title": "Description"
        }, 
        {
            "location": "/resources/stdlib.ini/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  file: The ini file. Required.  section: The ini file section. Use \" none \" to not use a section. Required.  option: The ini file setting/option. Required.  value: The value of the option. Use \" none \" to not set a value. Required.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/stdlib.ini/#example", 
            "text": "stdlib.ini --file /etc/nova/nova.conf --section DEFAULT --option debug --value True", 
            "title": "Example"
        }, 
        {
            "location": "/resources/stdlib.ip6tables_rule/", 
            "text": "stdlib.ip6tables_rule\n\n\nDescription\n\n\nManages ip6tables rules\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nname: An arbitrary name for the rule. Required. namevar.\n\n\npriority: An arbitrary number to give the rule priority. Required. Default 100.\n\n\ntable: The table to add the rule to.. Required. Default: filter.\n\n\nchain: The chain to add the rule to. Required. Default: INPUT.\n\n\nrule: The rule. Required.\n\n\naction: The action to take on the rule. Required. Default: ACCEPT.\n\n\n\n\nExample\n\n\nstdlib.ip6tables_rule --priority 100 --name \nallow all from 192.168.1.0/24\n --rule \n-m tcp -s 192.168.1.0/24\n --action ACCEPT", 
            "title": "stdlib.ip6tables_rule"
        }, 
        {
            "location": "/resources/stdlib.ip6tables_rule/#stdlibip6tables_rule", 
            "text": "", 
            "title": "stdlib.ip6tables_rule"
        }, 
        {
            "location": "/resources/stdlib.ip6tables_rule/#description", 
            "text": "Manages ip6tables rules", 
            "title": "Description"
        }, 
        {
            "location": "/resources/stdlib.ip6tables_rule/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  name: An arbitrary name for the rule. Required. namevar.  priority: An arbitrary number to give the rule priority. Required. Default 100.  table: The table to add the rule to.. Required. Default: filter.  chain: The chain to add the rule to. Required. Default: INPUT.  rule: The rule. Required.  action: The action to take on the rule. Required. Default: ACCEPT.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/stdlib.ip6tables_rule/#example", 
            "text": "stdlib.ip6tables_rule --priority 100 --name  allow all from 192.168.1.0/24  --rule  -m tcp -s 192.168.1.0/24  --action ACCEPT", 
            "title": "Example"
        }, 
        {
            "location": "/resources/stdlib.iptables_rule/", 
            "text": "stdlib.iptables_rule\n\n\nDescription\n\n\nManages iptables rules\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nname: An arbitrary name for the rule. Required. namevar.\n\n\npriority: An arbitrary number to give the rule priority. Required. Default 100.\n\n\ntable: The table to add the rule to.. Required. Default: filter.\n\n\nchain: The chain to add the rule to. Required. Default: INPUT.\n\n\nrule: The rule. Required.\n\n\naction: The action to take on the rule. Required. Default: ACCEPT.\n\n\n\n\nExample\n\n\nstdlib.iptables_rule --priority 100 --name \nallow all from 192.168.1.0/24\n --rule \n-m tcp -s 192.168.1.0/24\n --action ACCEPT", 
            "title": "stdlib.iptables_rule"
        }, 
        {
            "location": "/resources/stdlib.iptables_rule/#stdlibiptables_rule", 
            "text": "", 
            "title": "stdlib.iptables_rule"
        }, 
        {
            "location": "/resources/stdlib.iptables_rule/#description", 
            "text": "Manages iptables rules", 
            "title": "Description"
        }, 
        {
            "location": "/resources/stdlib.iptables_rule/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  name: An arbitrary name for the rule. Required. namevar.  priority: An arbitrary number to give the rule priority. Required. Default 100.  table: The table to add the rule to.. Required. Default: filter.  chain: The chain to add the rule to. Required. Default: INPUT.  rule: The rule. Required.  action: The action to take on the rule. Required. Default: ACCEPT.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/stdlib.iptables_rule/#example", 
            "text": "stdlib.iptables_rule --priority 100 --name  allow all from 192.168.1.0/24  --rule  -m tcp -s 192.168.1.0/24  --action ACCEPT", 
            "title": "Example"
        }, 
        {
            "location": "/resources/stdlib.sudo_cmd/", 
            "text": "stdlib.sudo_cmd\n\n\nDescription\n\n\nProvides an easy way to give a user sudo access to a single command.\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nuser: The user of the sudo privilege. Required. namevar.\n\n\ncommand: The command of the sudo privilege. Required. namevar.\n\n\npassword: Whether to prompt for a password. Required. Default: false.\n\n\n\n\nExample\n\n\nsudo_cmd --user consul --command /usr/local/bin/consul_build_hosts_file.sh", 
            "title": "stdlib.sudo_cmd"
        }, 
        {
            "location": "/resources/stdlib.sudo_cmd/#stdlibsudo_cmd", 
            "text": "", 
            "title": "stdlib.sudo_cmd"
        }, 
        {
            "location": "/resources/stdlib.sudo_cmd/#description", 
            "text": "Provides an easy way to give a user sudo access to a single command.", 
            "title": "Description"
        }, 
        {
            "location": "/resources/stdlib.sudo_cmd/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  user: The user of the sudo privilege. Required. namevar.  command: The command of the sudo privilege. Required. namevar.  password: Whether to prompt for a password. Required. Default: false.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/stdlib.sudo_cmd/#example", 
            "text": "sudo_cmd --user consul --command /usr/local/bin/consul_build_hosts_file.sh", 
            "title": "Example"
        }, 
        {
            "location": "/resources/stdlib.sysvinit/", 
            "text": "stdlib.sysvinit\n\n\nDescription\n\n\nManages sysv-init services\n\n\nParameters\n\n\n\n\nstate: The state of the service. Required. Default: running.\n\n\nname: The name of the service. Required. namevar.\n\n\n\n\nExample\n\n\nstdlib.sysvinit --name memcached", 
            "title": "stdlib.sysvinit"
        }, 
        {
            "location": "/resources/stdlib.sysvinit/#stdlibsysvinit", 
            "text": "", 
            "title": "stdlib.sysvinit"
        }, 
        {
            "location": "/resources/stdlib.sysvinit/#description", 
            "text": "Manages sysv-init services", 
            "title": "Description"
        }, 
        {
            "location": "/resources/stdlib.sysvinit/#parameters", 
            "text": "state: The state of the service. Required. Default: running.  name: The name of the service. Required. namevar.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/stdlib.sysvinit/#example", 
            "text": "stdlib.sysvinit --name memcached", 
            "title": "Example"
        }, 
        {
            "location": "/resources/stdlib.upstart/", 
            "text": "stdlib.upstart\n\n\nDescription\n\n\nManages upstart services\n\n\nParameters\n\n\n\n\nstate: The state of the service. Required. Default: running.\n\n\nname: The name of the service. Required. namevar.\n\n\n\n\nExample\n\n\nstdlib.upstart --name memcached", 
            "title": "stdlib.upstart"
        }, 
        {
            "location": "/resources/stdlib.upstart/#stdlibupstart", 
            "text": "", 
            "title": "stdlib.upstart"
        }, 
        {
            "location": "/resources/stdlib.upstart/#description", 
            "text": "Manages upstart services", 
            "title": "Description"
        }, 
        {
            "location": "/resources/stdlib.upstart/#parameters", 
            "text": "state: The state of the service. Required. Default: running.  name: The name of the service. Required. namevar.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/stdlib.upstart/#example", 
            "text": "stdlib.upstart --name memcached", 
            "title": "Example"
        }, 
        {
            "location": "/resources/stdlib.useradd/", 
            "text": "stdlib.useradd\n\n\nDescription\n\n\nManages users\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nuser: The user Required. namevar.\n\n\nuid: The uid of the user Optional.\n\n\ngid: The gid of the user Optional.\n\n\ncreatehome: Whether to create the homedir. Default: false.\n\n\nsudo: Whether to give sudo ability: Default: false.\n\n\nshell: The shell of the user. Default /usr/sbin/nologin.\n\n\ncomment: The comment field. Optional.\n\n\nhomedir: The homedir of the user. Optional.\n\n\npasswd: The password hash. Optional.\n\n\ngroups: Supplemental groups of the user. Optional.\n\n\nsystem: Whether the user is a system user or not. Default: false\n\n\n\n\nExample\n\n\nstdlib.useradd --user jdoe --uid 999 --createhome true --homedir /home/jdoe\n               --shell /bin/bash --comment \nJohn Doe\n\n\n\n\n\nNotes\n\n\nThe \n--system true\n flag is only useful during a create. If the user already\nexists and you choose to change it into a system using with the \n--system\n\nflag, it's best to delete the user and recreate it.", 
            "title": "stdlib.useradd"
        }, 
        {
            "location": "/resources/stdlib.useradd/#stdlibuseradd", 
            "text": "", 
            "title": "stdlib.useradd"
        }, 
        {
            "location": "/resources/stdlib.useradd/#description", 
            "text": "Manages users", 
            "title": "Description"
        }, 
        {
            "location": "/resources/stdlib.useradd/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  user: The user Required. namevar.  uid: The uid of the user Optional.  gid: The gid of the user Optional.  createhome: Whether to create the homedir. Default: false.  sudo: Whether to give sudo ability: Default: false.  shell: The shell of the user. Default /usr/sbin/nologin.  comment: The comment field. Optional.  homedir: The homedir of the user. Optional.  passwd: The password hash. Optional.  groups: Supplemental groups of the user. Optional.  system: Whether the user is a system user or not. Default: false", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/stdlib.useradd/#example", 
            "text": "stdlib.useradd --user jdoe --uid 999 --createhome true --homedir /home/jdoe\n               --shell /bin/bash --comment  John Doe", 
            "title": "Example"
        }, 
        {
            "location": "/resources/stdlib.useradd/#notes", 
            "text": "The  --system true  flag is only useful during a create. If the user already\nexists and you choose to change it into a system using with the  --system \nflag, it's best to delete the user and recreate it.", 
            "title": "Notes"
        }, 
        {
            "location": "/resources/apache.section/", 
            "text": "apache.section\n\n\nDescription\n\n\nManages an apache section.\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\ntype: The type of the section Required. namevar.\n\n\nname: The name of the section Required. namevar.\n\n\npath: The path leading up to the type. Optional. Multi. namevar.\n\n\nfile: The file to store the settings in. Optional. Defaults to /etc/apache2/apache2.conf. namevar.\n\n\n\n\nExample\n\n\napache.section --path \nVirtualHost=*:80\n --type Directory --name / \\\n               --file /etc/apache2/sites-enabled/000-default.conf", 
            "title": "apache.section"
        }, 
        {
            "location": "/resources/apache.section/#apachesection", 
            "text": "", 
            "title": "apache.section"
        }, 
        {
            "location": "/resources/apache.section/#description", 
            "text": "Manages an apache section.", 
            "title": "Description"
        }, 
        {
            "location": "/resources/apache.section/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  type: The type of the section Required. namevar.  name: The name of the section Required. namevar.  path: The path leading up to the type. Optional. Multi. namevar.  file: The file to store the settings in. Optional. Defaults to /etc/apache2/apache2.conf. namevar.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/apache.section/#example", 
            "text": "apache.section --path  VirtualHost=*:80  --type Directory --name / \\\n               --file /etc/apache2/sites-enabled/000-default.conf", 
            "title": "Example"
        }, 
        {
            "location": "/resources/apache.setting/", 
            "text": "apache.setting\n\n\nDescription\n\n\nManages key/value settings in an Apache config file.\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nkey: The name of the setting. Required. namevar.\n\n\nvalue: The value of the setting. Required. namevar.\n\n\npath: The path leading up to the key. Optional. Multi. namevar.\n\n\nfile: The file to store the settings in. Optional. Defaults to /etc/apache2/apache2.conf. namevar.\n\n\n\n\nExample\n\n\napache.setting --path \nVirtualHost=*:80\n \\\n               --path \nDirectory=/\n \\\n               --key Require --value valid-user \\\n               --file /etc/apache2/sites-enabled/000-default.conf", 
            "title": "apache.setting"
        }, 
        {
            "location": "/resources/apache.setting/#apachesetting", 
            "text": "", 
            "title": "apache.setting"
        }, 
        {
            "location": "/resources/apache.setting/#description", 
            "text": "Manages key/value settings in an Apache config file.", 
            "title": "Description"
        }, 
        {
            "location": "/resources/apache.setting/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  key: The name of the setting. Required. namevar.  value: The value of the setting. Required. namevar.  path: The path leading up to the key. Optional. Multi. namevar.  file: The file to store the settings in. Optional. Defaults to /etc/apache2/apache2.conf. namevar.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/apache.setting/#example", 
            "text": "apache.setting --path  VirtualHost=*:80  \\\n               --path  Directory=/  \\\n               --key Require --value valid-user \\\n               --file /etc/apache2/sites-enabled/000-default.conf", 
            "title": "Example"
        }, 
        {
            "location": "/resources/augeas.aptconf/", 
            "text": "augeas.aptconf\n\n\nDescription\n\n\nManages apt.conf settings\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nsetting: The setting Required. namevar.\n\n\nvalue: A value for the setting Required.\n\n\nfile: The file to add the variable to. Required. namevar.\n\n\n\n\nExample\n\n\naugeas.aptconf --setting APT::Periodic::Update-Package-Lists --value 1 --file /etc/apt/apt.conf.d/20auto-upgrades\naugeas.aptconf --setting APT::Periodic::Unattended-Upgrade --value 1 --file /etc/apt/apt.conf.d/20auto-upgrades", 
            "title": "augeas.aptconf"
        }, 
        {
            "location": "/resources/augeas.aptconf/#augeasaptconf", 
            "text": "", 
            "title": "augeas.aptconf"
        }, 
        {
            "location": "/resources/augeas.aptconf/#description", 
            "text": "Manages apt.conf settings", 
            "title": "Description"
        }, 
        {
            "location": "/resources/augeas.aptconf/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  setting: The setting Required. namevar.  value: A value for the setting Required.  file: The file to add the variable to. Required. namevar.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/augeas.aptconf/#example", 
            "text": "augeas.aptconf --setting APT::Periodic::Update-Package-Lists --value 1 --file /etc/apt/apt.conf.d/20auto-upgrades\naugeas.aptconf --setting APT::Periodic::Unattended-Upgrade --value 1 --file /etc/apt/apt.conf.d/20auto-upgrades", 
            "title": "Example"
        }, 
        {
            "location": "/resources/augeas.cron/", 
            "text": "augeas.cron\n\n\nDescription\n\n\nManages a cron entry in /etc/cron.d/\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nname: An arbitrary name for the cron Required. namevar.\n\n\nuser: The user to run the cron under. Default: root.\n\n\nminute: The minute to run the cron. Default: *.\n\n\nhour: The hour to run the cron. Default: *.\n\n\ndom: The day of month to run the cron. Default: *.\n\n\nmonth: The month to run the cron. Default *.\n\n\ndow: The day of the week to run the cron. Default *.\n\n\ncmd: The command to run. Required.\n\n\n\n\nExample\n\n\naugeas.cron --name metrics --minute \n*/5\n --cmd /usr/local/bin/collect_metrics.sh", 
            "title": "augeas.cron"
        }, 
        {
            "location": "/resources/augeas.cron/#augeascron", 
            "text": "", 
            "title": "augeas.cron"
        }, 
        {
            "location": "/resources/augeas.cron/#description", 
            "text": "Manages a cron entry in /etc/cron.d/", 
            "title": "Description"
        }, 
        {
            "location": "/resources/augeas.cron/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  name: An arbitrary name for the cron Required. namevar.  user: The user to run the cron under. Default: root.  minute: The minute to run the cron. Default: *.  hour: The hour to run the cron. Default: *.  dom: The day of month to run the cron. Default: *.  month: The month to run the cron. Default *.  dow: The day of the week to run the cron. Default *.  cmd: The command to run. Required.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/augeas.cron/#example", 
            "text": "augeas.cron --name metrics --minute  */5  --cmd /usr/local/bin/collect_metrics.sh", 
            "title": "Example"
        }, 
        {
            "location": "/resources/augeas.file_line/", 
            "text": "augeas.file_line\n\n\nDescription\n\n\nManages single lines in a file\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nname: An arbitrary name for the line. Required. namevar.\n\n\nline: The line to manage in the file. Required.\n\n\nfile: The file to add the line. Required. namevar.\n\n\n\n\nExample\n\n\naugeas.file_line --name foo --file /root/foo.txt --line \nHello, World!", 
            "title": "augeas.file_line"
        }, 
        {
            "location": "/resources/augeas.file_line/#augeasfile_line", 
            "text": "", 
            "title": "augeas.file_line"
        }, 
        {
            "location": "/resources/augeas.file_line/#description", 
            "text": "Manages single lines in a file", 
            "title": "Description"
        }, 
        {
            "location": "/resources/augeas.file_line/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  name: An arbitrary name for the line. Required. namevar.  line: The line to manage in the file. Required.  file: The file to add the line. Required. namevar.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/augeas.file_line/#example", 
            "text": "augeas.file_line --name foo --file /root/foo.txt --line  Hello, World!", 
            "title": "Example"
        }, 
        {
            "location": "/resources/augeas.generic/", 
            "text": "augeas.generic\n\n\nDescription\n\n\nChange a file using Augeas\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nname: An arbitrary name for the resource. Required. namevar.\n\n\nlens: The Augeas lens to use without the .lns extension. Required.\n\n\nlens_path: A custom directory that contain lenses. Optional. Multi-var.\n\n\ncommand: A single Augeas command to run. Optional. Multi-var.\n\n\nonlyif: A match conditional to check prior to running commands. If \ntrue\n, the command(s) are run. Optional.\n\n\nnotif: The same as \nonlyif\n but when the match should fail. Optional.\n\n\nfile: The file to modify. Required. namevar.\n\n\n\n\nonlyif / notif Conditional Tests\n\n\nonlyif\n and \nnotif\n tests have the following format:\n\n\n--onlyif \npath\n \nfunction\n \noperator\n \ncomparison\n\n\n\n\n\nSize\n\n\nSize compares the amount of matches.\n\n\n\n\nsize -lt 1\n\n\nsize -gt 1\n\n\nAny numerical comparisons\n\n\n\n\nPath\n\n\n\n\n\n\nWill compare the returned path(s) with a string:\n\n\n\n\n\n\npath not_include \nstring\n\n\n\n\npath include \nstring\n\n\npath is \nstring\n\n\npath is_not \nstring\n\n\n\n\nResult\n\n\nResult will compare the returned result(s) with a string:\n\n\n\n\nresult not_include \nstring\n\n\nresult include \nstring\n\n\nresult is \nstring\n\n\nresult is_not \nstring\n\n\n\n\nConditional Test Examples\n\n\nAssume \n/files/etc/hosts\n:\n\n\n\n\n*/ipaddr[. =~ regexp(\"127.*\")]\n\n\n*/ipaddr[. =~ regexp(\"127.*\")] size -lt 1\n\n\n*/ipaddr[. =~ regexp(\"127.*\")] size -gt 1\n\n\n*/ipaddr[. =~ regexp(\"127.*\")] path not_include 127.0.0.1\n\n\n*/ipaddr[. = \"127.0.0.1\"]/../canonical result include localhost\n\n\n\n\nExample\n\n\naugeas.generic --name test --lens Hosts --file /root/hosts \\\n  --command \nset *[canonical = 'localhost'][1]/ipaddr '10.3.3.27'\n \\\n  --onlyif \n*/ipaddr[. = '127.0.0.1']/../canonical result include 'localhost'\n\n\naugeas.generic --name test2 --lens Hosts --file /root/hosts \\\n  --command \nset 0/ipaddr '8.8.8.8'\n \\\n  --command \nset 0/canonical 'google.com'\n \\\n  --onlyif \n*/ipaddr[. = '8.8.8.8'] result not_include '8.8.8.8'\n\n\naugeas.generic --name test3 --lens Hosts --file /root/hosts \\\n  --command \nset 0/ipaddr '1.1.1.1'\n \\\n  --command \nset 0/canonical 'foobar.com'\n \\\n  --onlyif \n*/ipaddr[. = '1.1.1.1'] path not_include 'ipaddr'\n\n\naugeas.generic --name test4 --lens Hosts --file /root/hosts \\\n  --command \nset 0/ipaddr '2.2.2.2'\n \\\n  --command \nset 0/canonical 'barfoo.com'\n \\\n  --onlyif \n*/ipaddr[. = '2.2.2.2'] size -eq 0\n\n\naugeas.generic --name test5 --lens Hosts --file /root/hosts \\\n  --command \nset 0/ipaddr '3.3.3.3'\n \\\n  --command \nset 0/canonical 'bazbar.com'\n \\\n  --onlyif \n*/ipaddr[. = '3.3.3.3'] size -lt 1", 
            "title": "augeas.generic"
        }, 
        {
            "location": "/resources/augeas.generic/#augeasgeneric", 
            "text": "", 
            "title": "augeas.generic"
        }, 
        {
            "location": "/resources/augeas.generic/#description", 
            "text": "Change a file using Augeas", 
            "title": "Description"
        }, 
        {
            "location": "/resources/augeas.generic/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  name: An arbitrary name for the resource. Required. namevar.  lens: The Augeas lens to use without the .lns extension. Required.  lens_path: A custom directory that contain lenses. Optional. Multi-var.  command: A single Augeas command to run. Optional. Multi-var.  onlyif: A match conditional to check prior to running commands. If  true , the command(s) are run. Optional.  notif: The same as  onlyif  but when the match should fail. Optional.  file: The file to modify. Required. namevar.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/augeas.generic/#onlyif-notif-conditional-tests", 
            "text": "onlyif  and  notif  tests have the following format:  --onlyif  path   function   operator   comparison   Size  Size compares the amount of matches.   size -lt 1  size -gt 1  Any numerical comparisons   Path    Will compare the returned path(s) with a string:    path not_include  string   path include  string  path is  string  path is_not  string   Result  Result will compare the returned result(s) with a string:   result not_include  string  result include  string  result is  string  result is_not  string   Conditional Test Examples  Assume  /files/etc/hosts :   */ipaddr[. =~ regexp(\"127.*\")]  */ipaddr[. =~ regexp(\"127.*\")] size -lt 1  */ipaddr[. =~ regexp(\"127.*\")] size -gt 1  */ipaddr[. =~ regexp(\"127.*\")] path not_include 127.0.0.1  */ipaddr[. = \"127.0.0.1\"]/../canonical result include localhost", 
            "title": "onlyif / notif Conditional Tests"
        }, 
        {
            "location": "/resources/augeas.generic/#example", 
            "text": "augeas.generic --name test --lens Hosts --file /root/hosts \\\n  --command  set *[canonical = 'localhost'][1]/ipaddr '10.3.3.27'  \\\n  --onlyif  */ipaddr[. = '127.0.0.1']/../canonical result include 'localhost' \n\naugeas.generic --name test2 --lens Hosts --file /root/hosts \\\n  --command  set 0/ipaddr '8.8.8.8'  \\\n  --command  set 0/canonical 'google.com'  \\\n  --onlyif  */ipaddr[. = '8.8.8.8'] result not_include '8.8.8.8' \n\naugeas.generic --name test3 --lens Hosts --file /root/hosts \\\n  --command  set 0/ipaddr '1.1.1.1'  \\\n  --command  set 0/canonical 'foobar.com'  \\\n  --onlyif  */ipaddr[. = '1.1.1.1'] path not_include 'ipaddr' \n\naugeas.generic --name test4 --lens Hosts --file /root/hosts \\\n  --command  set 0/ipaddr '2.2.2.2'  \\\n  --command  set 0/canonical 'barfoo.com'  \\\n  --onlyif  */ipaddr[. = '2.2.2.2'] size -eq 0 \n\naugeas.generic --name test5 --lens Hosts --file /root/hosts \\\n  --command  set 0/ipaddr '3.3.3.3'  \\\n  --command  set 0/canonical 'bazbar.com'  \\\n  --onlyif  */ipaddr[. = '3.3.3.3'] size -lt 1", 
            "title": "Example"
        }, 
        {
            "location": "/resources/augeas.host/", 
            "text": "augeas.host\n\n\nDescription\n\n\nManages hosts in /etc/hosts\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nname: The host. Required. namevar.\n\n\nip: The IP address of the host. Required.\n\n\naliases: A CSV list of host aliases. Optional\n\n\nfile: The hosts file. Default: /etc/hosts.\n\n\n\n\nExample\n\n\naugeas.host --name example.com --ip 192.168.1.1 --aliases www,db", 
            "title": "augeas.host"
        }, 
        {
            "location": "/resources/augeas.host/#augeashost", 
            "text": "", 
            "title": "augeas.host"
        }, 
        {
            "location": "/resources/augeas.host/#description", 
            "text": "Manages hosts in /etc/hosts", 
            "title": "Description"
        }, 
        {
            "location": "/resources/augeas.host/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  name: The host. Required. namevar.  ip: The IP address of the host. Required.  aliases: A CSV list of host aliases. Optional  file: The hosts file. Default: /etc/hosts.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/augeas.host/#example", 
            "text": "augeas.host --name example.com --ip 192.168.1.1 --aliases www,db", 
            "title": "Example"
        }, 
        {
            "location": "/resources/augeas.ini/", 
            "text": "augeas.ini\n\n\nDescription\n\n\nManages ini file entries\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nsection: The section in the ini file. Required. namevar.\n\n\noption: The option in the ini file. Required. namevar.\n\n\nvalue: The value of the option. Required.\n\n\nfile: The file to add the variable to. Required. namevar.\n\n\n\n\nExample\n\n\naugeas.ini --section DEFAULT --option foo --value bar --file /root/vars", 
            "title": "augeas.ini"
        }, 
        {
            "location": "/resources/augeas.ini/#augeasini", 
            "text": "", 
            "title": "augeas.ini"
        }, 
        {
            "location": "/resources/augeas.ini/#description", 
            "text": "Manages ini file entries", 
            "title": "Description"
        }, 
        {
            "location": "/resources/augeas.ini/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  section: The section in the ini file. Required. namevar.  option: The option in the ini file. Required. namevar.  value: The value of the option. Required.  file: The file to add the variable to. Required. namevar.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/augeas.ini/#example", 
            "text": "augeas.ini --section DEFAULT --option foo --value bar --file /root/vars", 
            "title": "Example"
        }, 
        {
            "location": "/resources/augeas.json_array/", 
            "text": "augeas.json_array\n\n\nDescription\n\n\nManages a dictionary entry in a JSON file\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\npath: The path to the setting in the json tree for non-k/v settings.\n\n\nkey: The key of the dictionary that will hold the array.\n\n\nvalue: The value of the array. Multi-var.\n\n\nfile: The file to add the variable to. Required.\n\n\n\n\nExample\n\n\naugeas.json_array --file /root/web.json --path / --key foo --value 1 --value 2 --value 3\n\n{\nfoo\n:[1,2,3]}", 
            "title": "augeas.json_array"
        }, 
        {
            "location": "/resources/augeas.json_array/#augeasjson_array", 
            "text": "", 
            "title": "augeas.json_array"
        }, 
        {
            "location": "/resources/augeas.json_array/#description", 
            "text": "Manages a dictionary entry in a JSON file", 
            "title": "Description"
        }, 
        {
            "location": "/resources/augeas.json_array/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  path: The path to the setting in the json tree for non-k/v settings.  key: The key of the dictionary that will hold the array.  value: The value of the array. Multi-var.  file: The file to add the variable to. Required.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/augeas.json_array/#example", 
            "text": "augeas.json_array --file /root/web.json --path / --key foo --value 1 --value 2 --value 3\n\n{ foo :[1,2,3]}", 
            "title": "Example"
        }, 
        {
            "location": "/resources/augeas.json_dict/", 
            "text": "augeas.json_dict\n\n\nDescription\n\n\nManages a dictionary entry in a JSON file\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\npath: The path to the setting in the json tree for non-k/v settings.\n\n\nkey: The key portion of the dictionary. Required.\n\n\nvalue: The value portion of the dictionary. Required.\n\n\ntype: The type of the value. Optional.\n\n\nfile: The file to add the variable to. Required.\n\n\n\n\nExample\n\n\naugeas.json_dict --file /root/web.json --path / --key \nfoo\n --value _dict\naugeas.json_dict --file /root/web.json --path / --key \nfoo\n --value _array\naugeas.json_dict --file /root/web.json --path / --key \nfoo\n --value \nbar", 
            "title": "augeas.json_dict"
        }, 
        {
            "location": "/resources/augeas.json_dict/#augeasjson_dict", 
            "text": "", 
            "title": "augeas.json_dict"
        }, 
        {
            "location": "/resources/augeas.json_dict/#description", 
            "text": "Manages a dictionary entry in a JSON file", 
            "title": "Description"
        }, 
        {
            "location": "/resources/augeas.json_dict/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  path: The path to the setting in the json tree for non-k/v settings.  key: The key portion of the dictionary. Required.  value: The value portion of the dictionary. Required.  type: The type of the value. Optional.  file: The file to add the variable to. Required.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/augeas.json_dict/#example", 
            "text": "augeas.json_dict --file /root/web.json --path / --key  foo  --value _dict\naugeas.json_dict --file /root/web.json --path / --key  foo  --value _array\naugeas.json_dict --file /root/web.json --path / --key  foo  --value  bar", 
            "title": "Example"
        }, 
        {
            "location": "/resources/augeas.mail_alias/", 
            "text": "augeas.mail_alias\n\n\nDescription\n\n\nManages aliases in /etc/aliases\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\naccount: The mail account. Required. namevar.\n\n\ndestination: The destination for the account. Required.\n\n\nalias: Additional aliases for the account. Optional. Multi-value.\n\n\nfile: The aliases file. Default: /etc/aliases.\n\n\n\n\nExample\n\n\naugeas.mail_alias --account root --destination /dev/null", 
            "title": "augeas.mail_alias"
        }, 
        {
            "location": "/resources/augeas.mail_alias/#augeasmail_alias", 
            "text": "", 
            "title": "augeas.mail_alias"
        }, 
        {
            "location": "/resources/augeas.mail_alias/#description", 
            "text": "Manages aliases in /etc/aliases", 
            "title": "Description"
        }, 
        {
            "location": "/resources/augeas.mail_alias/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  account: The mail account. Required. namevar.  destination: The destination for the account. Required.  alias: Additional aliases for the account. Optional. Multi-value.  file: The aliases file. Default: /etc/aliases.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/augeas.mail_alias/#example", 
            "text": "augeas.mail_alias --account root --destination /dev/null", 
            "title": "Example"
        }, 
        {
            "location": "/resources/augeas.shellvar/", 
            "text": "augeas.shellvar\n\n\nDescription\n\n\nManages simple k=v settings in a file.\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nkey: The key. Required. namevar.\n\n\nvalue: A value for the key. Required.\n\n\nfile: The file to add the variable to. Required. namevar.\n\n\n\n\nExample\n\n\naugeas.shellvar --key foo --value bar --file /root/vars", 
            "title": "augeas.shellvar"
        }, 
        {
            "location": "/resources/augeas.shellvar/#augeasshellvar", 
            "text": "", 
            "title": "augeas.shellvar"
        }, 
        {
            "location": "/resources/augeas.shellvar/#description", 
            "text": "Manages simple k=v settings in a file.", 
            "title": "Description"
        }, 
        {
            "location": "/resources/augeas.shellvar/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  key: The key. Required. namevar.  value: A value for the key. Required.  file: The file to add the variable to. Required. namevar.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/augeas.shellvar/#example", 
            "text": "augeas.shellvar --key foo --value bar --file /root/vars", 
            "title": "Example"
        }, 
        {
            "location": "/resources/augeas.ssh_authorized_key/", 
            "text": "augeas.ssh_authorized_key\n\n\nDescription\n\n\nManages ssh_authorized_keys\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nname: The ssh_authorized_key. Required. namevar.\n\n\nkey: The ssh key. Required.\n\n\ntype: The key type. Required.\n\n\nkey_options: A CSV list of ssh_authorized_key options. Optional\n\n\nfile: The ssh_authorized_keys file. Required.\n\n\n\n\nExample\n\n\naugeas.ssh_authorized_key --name jdoe --key \nAAAAB3NzaC1...\n --type ssh-rsa --comment \njdoe@laptop\n --file \n/root/.ssh/authorized_keys\n\n\n\n\n\nNotes\n\n\nTODO: \noptions\n have not been tested.", 
            "title": "augeas.ssh_authorized_key"
        }, 
        {
            "location": "/resources/augeas.ssh_authorized_key/#augeasssh_authorized_key", 
            "text": "", 
            "title": "augeas.ssh_authorized_key"
        }, 
        {
            "location": "/resources/augeas.ssh_authorized_key/#description", 
            "text": "Manages ssh_authorized_keys", 
            "title": "Description"
        }, 
        {
            "location": "/resources/augeas.ssh_authorized_key/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  name: The ssh_authorized_key. Required. namevar.  key: The ssh key. Required.  type: The key type. Required.  key_options: A CSV list of ssh_authorized_key options. Optional  file: The ssh_authorized_keys file. Required.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/augeas.ssh_authorized_key/#example", 
            "text": "augeas.ssh_authorized_key --name jdoe --key  AAAAB3NzaC1...  --type ssh-rsa --comment  jdoe@laptop  --file  /root/.ssh/authorized_keys", 
            "title": "Example"
        }, 
        {
            "location": "/resources/augeas.ssh_authorized_key/#notes", 
            "text": "TODO:  options  have not been tested.", 
            "title": "Notes"
        }, 
        {
            "location": "/resources/consul.check/", 
            "text": "consul.check\n\n\nDescription\n\n\nManages a consul.check.\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nname: The name of the check Required. namevar.\n\n\nid: A unique ID for the check. Optional.\n\n\nservice_id: A service to tie the check to. Optional.\n\n\nnotes: Notes about the check. Optional.\n\n\ntoken: An ACL token. Optional.\n\n\ncheck: The script or http location for the check. Optional.\n\n\ntype: The type of check: script, http, or ttl. Required.\n\n\ninterval: The interval to run the script. Optional.\n\n\nttl: The TTL of the check. Optional.\n\n\nfile: The file to store the check in. Required. Defaults to /etc/consul/agent/conf.d/check-name.json\n\n\n\n\nExample\n\n\nconsul.check --name mysql \\\n             --check \n/usr/local/bin/check_mysql.sh\n \\\n             --type \nscript\n \\\n             --interval \n60s", 
            "title": "consul.check"
        }, 
        {
            "location": "/resources/consul.check/#consulcheck", 
            "text": "", 
            "title": "consul.check"
        }, 
        {
            "location": "/resources/consul.check/#description", 
            "text": "Manages a consul.check.", 
            "title": "Description"
        }, 
        {
            "location": "/resources/consul.check/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  name: The name of the check Required. namevar.  id: A unique ID for the check. Optional.  service_id: A service to tie the check to. Optional.  notes: Notes about the check. Optional.  token: An ACL token. Optional.  check: The script or http location for the check. Optional.  type: The type of check: script, http, or ttl. Required.  interval: The interval to run the script. Optional.  ttl: The TTL of the check. Optional.  file: The file to store the check in. Required. Defaults to /etc/consul/agent/conf.d/check-name.json", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/consul.check/#example", 
            "text": "consul.check --name mysql \\\n             --check  /usr/local/bin/check_mysql.sh  \\\n             --type  script  \\\n             --interval  60s", 
            "title": "Example"
        }, 
        {
            "location": "/resources/consul.service/", 
            "text": "consul.service\n\n\nDescription\n\n\nManages a consul service.\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nname: The name of the service. Required. namevar.\n\n\nid: A unique ID for the service. Optional.\n\n\ntag: Tags to describe the service. Optional. Multi-var.\n\n\naddress: The address of the service. Optional.\n\n\nport: The port that the service runs on. Optional.\n\n\ntoken: An ACL token. Optional.\n\n\ncheck: The script or location for the check. Optional. Multi-var.\n\n\ncheck_type: The type of check. Optional. Multi-var.\n\n\ncheck_interval: The interval to run the script. Optional. Multi-var.\n\n\ncheck_ttl: The TTL of the check. Optional. Multi-var.\n\n\nfile: The file to store the service in. Required. Defaults to /etc/consul/agent/conf.d/service-name.json\n\n\n\n\nExample\n\n\nconsul.service --name mysql \\\n               --port 3306 \\\n               --check_type \nscript\n \\\n               --check \n/usr/local/bin/check_mysql.sh\n \\\n               --check_interval \n60s", 
            "title": "consul.service"
        }, 
        {
            "location": "/resources/consul.service/#consulservice", 
            "text": "", 
            "title": "consul.service"
        }, 
        {
            "location": "/resources/consul.service/#description", 
            "text": "Manages a consul service.", 
            "title": "Description"
        }, 
        {
            "location": "/resources/consul.service/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  name: The name of the service. Required. namevar.  id: A unique ID for the service. Optional.  tag: Tags to describe the service. Optional. Multi-var.  address: The address of the service. Optional.  port: The port that the service runs on. Optional.  token: An ACL token. Optional.  check: The script or location for the check. Optional. Multi-var.  check_type: The type of check. Optional. Multi-var.  check_interval: The interval to run the script. Optional. Multi-var.  check_ttl: The TTL of the check. Optional. Multi-var.  file: The file to store the service in. Required. Defaults to /etc/consul/agent/conf.d/service-name.json", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/consul.service/#example", 
            "text": "consul.service --name mysql \\\n               --port 3306 \\\n               --check_type  script  \\\n               --check  /usr/local/bin/check_mysql.sh  \\\n               --check_interval  60s", 
            "title": "Example"
        }, 
        {
            "location": "/resources/consul.template/", 
            "text": "consul.template\n\n\nDescription\n\n\nManages a consul.template.\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nname: The name of the template. Required. namevar.\n\n\nsource: The source of the template. Optional. Defaults to /etc/consul/template/tpl/name.tpl\n\n\ndestination: The destination of the rendered template. Required.\n\n\ncommand: An optional command to run after the template is rendered. Optional.\n\n\nfile: The file to store the template in. Required. Defaults to /etc/consul/template/conf.d/name.json\n\n\n\n\nExample\n\n\nconsul.template --name hosts \\\n                --destination /etc/hosts", 
            "title": "consul.template"
        }, 
        {
            "location": "/resources/consul.template/#consultemplate", 
            "text": "", 
            "title": "consul.template"
        }, 
        {
            "location": "/resources/consul.template/#description", 
            "text": "Manages a consul.template.", 
            "title": "Description"
        }, 
        {
            "location": "/resources/consul.template/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  name: The name of the template. Required. namevar.  source: The source of the template. Optional. Defaults to /etc/consul/template/tpl/name.tpl  destination: The destination of the rendered template. Required.  command: An optional command to run after the template is rendered. Optional.  file: The file to store the template in. Required. Defaults to /etc/consul/template/conf.d/name.json", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/consul.template/#example", 
            "text": "consul.template --name hosts \\\n                --destination /etc/hosts", 
            "title": "Example"
        }, 
        {
            "location": "/resources/consul.watch/", 
            "text": "consul.watch\n\n\nDescription\n\n\nManages a consul.watch.\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nname: The name of the watch. Required. namevar.\n\n\ntype: The type of watch: key, keyprefix, services, nodes, service, checks, event. Required.\n\n\nkey: A key to monitor when using type \"key\". Optional.\n\n\nprefix: A prefix to monitor when using type \"keyprefix\". Optional.\n\n\nservice: A service to monitor when using type \"service\" or \"checks\". Optional.\n\n\ntag: A service tag to monitor when using type \"service\". Optional.\n\n\npassingonly: Only return instances passing all health checks when using type \"service\". Optional.\n\n\ncheck_state: A state to filter on when using type \"checks\". Optional.\n\n\nevent_name: An event to filter on when using type \"event. Optional.\n\n\ndatacenter: Can be provided to override the agent's default datacenter. Optional.\n\n\ntoken: Can be provided to override the agent's default ACL token. Optional.\n\n\nhandler: The handler to invoke when the data view updates. Required.\n\n\nfile: The file to store the watch in. Required. Defaults to /etc/consul/agent/conf.d/watch-name.json\n\n\n\n\nExample\n\n\nconsul.watch --name nodes \\\n             --type nodes \\\n             --handler \n/usr/local/bin/build_hosts_file.sh", 
            "title": "consul.watch"
        }, 
        {
            "location": "/resources/consul.watch/#consulwatch", 
            "text": "", 
            "title": "consul.watch"
        }, 
        {
            "location": "/resources/consul.watch/#description", 
            "text": "Manages a consul.watch.", 
            "title": "Description"
        }, 
        {
            "location": "/resources/consul.watch/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  name: The name of the watch. Required. namevar.  type: The type of watch: key, keyprefix, services, nodes, service, checks, event. Required.  key: A key to monitor when using type \"key\". Optional.  prefix: A prefix to monitor when using type \"keyprefix\". Optional.  service: A service to monitor when using type \"service\" or \"checks\". Optional.  tag: A service tag to monitor when using type \"service\". Optional.  passingonly: Only return instances passing all health checks when using type \"service\". Optional.  check_state: A state to filter on when using type \"checks\". Optional.  event_name: An event to filter on when using type \"event. Optional.  datacenter: Can be provided to override the agent's default datacenter. Optional.  token: Can be provided to override the agent's default ACL token. Optional.  handler: The handler to invoke when the data view updates. Required.  file: The file to store the watch in. Required. Defaults to /etc/consul/agent/conf.d/watch-name.json", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/consul.watch/#example", 
            "text": "consul.watch --name nodes \\\n             --type nodes \\\n             --handler  /usr/local/bin/build_hosts_file.sh", 
            "title": "Example"
        }, 
        {
            "location": "/resources/keepalived.global_defs/", 
            "text": "keepalived.global_defs\n\n\nDescription\n\n\nManages global_defs section in keepalived.conf\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nnotification_email: Email address to send notifications. Optional. Multi-var.\n\n\nnotification_email_from: The From address on email notifications. Optional.\n\n\nsmtp_server: The smtp server to send notifications. Optional.\n\n\nsmtp_connect_timeout: Connect timeout for sending notifications. Optional.\n\n\nrouter_id: The router ID. Optional.\n\n\nvrrp_mcast_group4: VRRP multicast group for IPv4. Optional.\n\n\nvrrp_mcast_group6: VRRP multicast group for IPv6. Optional.\n\n\nfile: The file to store the settings in. Optional. Defaults to /etc/keepalived/keepalived.conf.\n\n\n\n\nExample\n\n\nkeepalived.global_defs --notification_email root@localhost \\\n                       --notification_email jdoe@example.com \\\n                       --smtp_server smtp.example.com \\\n                       --router_id 42", 
            "title": "keepalived.global_defs"
        }, 
        {
            "location": "/resources/keepalived.global_defs/#keepalivedglobal_defs", 
            "text": "", 
            "title": "keepalived.global_defs"
        }, 
        {
            "location": "/resources/keepalived.global_defs/#description", 
            "text": "Manages global_defs section in keepalived.conf", 
            "title": "Description"
        }, 
        {
            "location": "/resources/keepalived.global_defs/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  notification_email: Email address to send notifications. Optional. Multi-var.  notification_email_from: The From address on email notifications. Optional.  smtp_server: The smtp server to send notifications. Optional.  smtp_connect_timeout: Connect timeout for sending notifications. Optional.  router_id: The router ID. Optional.  vrrp_mcast_group4: VRRP multicast group for IPv4. Optional.  vrrp_mcast_group6: VRRP multicast group for IPv6. Optional.  file: The file to store the settings in. Optional. Defaults to /etc/keepalived/keepalived.conf.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/keepalived.global_defs/#example", 
            "text": "keepalived.global_defs --notification_email root@localhost \\\n                       --notification_email jdoe@example.com \\\n                       --smtp_server smtp.example.com \\\n                       --router_id 42", 
            "title": "Example"
        }, 
        {
            "location": "/resources/keepalived.vrrp_instance/", 
            "text": "keepalived.vrrp_instance\n\n\nDescription\n\n\nManages vrrp_instance section in keepalived.conf\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nname: The name of the VRRP instance. Required. namevar.\n\n\nvrrp_state: The state of the VRRP instance. Required.\n\n\ninterface: The interface to monitor. Required.\n\n\nvirtual_router_id: The virtual router ID. Required.\n\n\npriority: The priority. Required.\n\n\nadvert_int: The advert interval. Optional.\n\n\nauth_type: The authentication type. Optional.\n\n\nauth_pass: The authentication password. Optional.\n\n\nvirtual_ipaddress: A virtual IP address. Optional. Multi-var.\n\n\nsmtp_alert: Send an email during transition. Optional. Defaults to false.\n\n\nunicast_src_ip: Source IP for unicast packets. Optional.\n\n\nunicast_peer: A peer in a unicast group. Optional. Multi-var.\n\n\nnative_ipv6: Force IPv6. Optional. Defaults to false.\n\n\nnotify_master: The notify_master script. Optional.\n\n\nnotify_backup: The notify_backup script. Optional.\n\n\nnotify_fault: The notify_fault script. Optional.\n\n\nnotify: The notify script. Optional.\n\n\ndebug: Enable debugging. Optional. Defaults to false.\n\n\nfile: The file to store the settings in. Required. Defaults to /etc/keepalived/keepalived.conf.\n\n\n\n\nExample\n\n\nkeepalived.vrrp_instance --name VI_1 \\\n                         --vrrp_state MASTER \\\n                         --interface eth0 \\\n                         --virtual_router_id 42 \\\n                         --priority 100 \\\n                         --virtual_ipaddress 192.168.1.10", 
            "title": "keepalived.vrrp_instance"
        }, 
        {
            "location": "/resources/keepalived.vrrp_instance/#keepalivedvrrp_instance", 
            "text": "", 
            "title": "keepalived.vrrp_instance"
        }, 
        {
            "location": "/resources/keepalived.vrrp_instance/#description", 
            "text": "Manages vrrp_instance section in keepalived.conf", 
            "title": "Description"
        }, 
        {
            "location": "/resources/keepalived.vrrp_instance/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  name: The name of the VRRP instance. Required. namevar.  vrrp_state: The state of the VRRP instance. Required.  interface: The interface to monitor. Required.  virtual_router_id: The virtual router ID. Required.  priority: The priority. Required.  advert_int: The advert interval. Optional.  auth_type: The authentication type. Optional.  auth_pass: The authentication password. Optional.  virtual_ipaddress: A virtual IP address. Optional. Multi-var.  smtp_alert: Send an email during transition. Optional. Defaults to false.  unicast_src_ip: Source IP for unicast packets. Optional.  unicast_peer: A peer in a unicast group. Optional. Multi-var.  native_ipv6: Force IPv6. Optional. Defaults to false.  notify_master: The notify_master script. Optional.  notify_backup: The notify_backup script. Optional.  notify_fault: The notify_fault script. Optional.  notify: The notify script. Optional.  debug: Enable debugging. Optional. Defaults to false.  file: The file to store the settings in. Required. Defaults to /etc/keepalived/keepalived.conf.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/keepalived.vrrp_instance/#example", 
            "text": "keepalived.vrrp_instance --name VI_1 \\\n                         --vrrp_state MASTER \\\n                         --interface eth0 \\\n                         --virtual_router_id 42 \\\n                         --priority 100 \\\n                         --virtual_ipaddress 192.168.1.10", 
            "title": "Example"
        }, 
        {
            "location": "/resources/keepalived.vrrp_script/", 
            "text": "keepalived.vrrp_script\n\n\nDescription\n\n\nManages vrrp_script section in keepalived.conf\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nname: The name of the VRRP instance. Required. namevar.\n\n\nscript: The script to define. Required.\n\n\ninterval: The interval to run the script. Optional.\n\n\nweight: The points for priority. Optional.\n\n\nfall: Number of failures for KO. Optional.\n\n\nraise: Number of successes for OK. Optional.\n\n\nfile: The file to store the settings in. Required. Defaults to /etc/keepalived/keepalived.conf.\n\n\n\n\nExample\n\n\nkeepalived.vrrp_script --name check_apache2 \\\n                       --script \nkillall -0 apache2", 
            "title": "keepalived.vrrp_script"
        }, 
        {
            "location": "/resources/keepalived.vrrp_script/#keepalivedvrrp_script", 
            "text": "", 
            "title": "keepalived.vrrp_script"
        }, 
        {
            "location": "/resources/keepalived.vrrp_script/#description", 
            "text": "Manages vrrp_script section in keepalived.conf", 
            "title": "Description"
        }, 
        {
            "location": "/resources/keepalived.vrrp_script/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  name: The name of the VRRP instance. Required. namevar.  script: The script to define. Required.  interval: The interval to run the script. Optional.  weight: The points for priority. Optional.  fall: Number of failures for KO. Optional.  raise: Number of successes for OK. Optional.  file: The file to store the settings in. Required. Defaults to /etc/keepalived/keepalived.conf.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/keepalived.vrrp_script/#example", 
            "text": "keepalived.vrrp_script --name check_apache2 \\\n                       --script  killall -0 apache2", 
            "title": "Example"
        }, 
        {
            "location": "/resources/keepalived.vrrp_sync_group/", 
            "text": "keepalived.vrrp_sync_group\n\n\nDescription\n\n\nManages vrrp_sync_group section in keepalived.conf\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nname: The name of the VRRP instance. Required. namevar.\n\n\ngroup: The name of a VRRP instance. Required. Multi-var.\n\n\nfile: The file to store the settings in. Required. Defaults to /etc/keepalived/keepalived.conf.\n\n\n\n\nExample\n\n\nkeepalived.vrrp_sync_group --name VSG_1 \\\n                           --group VI_1 \\\n                           --group VI_2 \\", 
            "title": "keepalived.vrrp_sync_group"
        }, 
        {
            "location": "/resources/keepalived.vrrp_sync_group/#keepalivedvrrp_sync_group", 
            "text": "", 
            "title": "keepalived.vrrp_sync_group"
        }, 
        {
            "location": "/resources/keepalived.vrrp_sync_group/#description", 
            "text": "Manages vrrp_sync_group section in keepalived.conf", 
            "title": "Description"
        }, 
        {
            "location": "/resources/keepalived.vrrp_sync_group/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  name: The name of the VRRP instance. Required. namevar.  group: The name of a VRRP instance. Required. Multi-var.  file: The file to store the settings in. Required. Defaults to /etc/keepalived/keepalived.conf.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/keepalived.vrrp_sync_group/#example", 
            "text": "keepalived.vrrp_sync_group --name VSG_1 \\\n                           --group VI_1 \\\n                           --group VI_2 \\", 
            "title": "Example"
        }, 
        {
            "location": "/resources/mysql.database/", 
            "text": "mysql.database\n\n\nDescription\n\n\nManages MySQL databases\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nname: The name of the database. Required. namevar.\n\n\ncharset: The character set of the database.\n\n\ncollate: The collation of the database.\n\n\n\n\nExample\n\n\nmysql.database --name root --password password", 
            "title": "mysql.database"
        }, 
        {
            "location": "/resources/mysql.database/#mysqldatabase", 
            "text": "", 
            "title": "mysql.database"
        }, 
        {
            "location": "/resources/mysql.database/#description", 
            "text": "Manages MySQL databases", 
            "title": "Description"
        }, 
        {
            "location": "/resources/mysql.database/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  name: The name of the database. Required. namevar.  charset: The character set of the database.  collate: The collation of the database.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/mysql.database/#example", 
            "text": "mysql.database --name root --password password", 
            "title": "Example"
        }, 
        {
            "location": "/resources/mysql.grant/", 
            "text": "mysql.grant\n\n\nDescription\n\n\nManages MySQL grants\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nuser: The user to receive the grant. Required. unique.\n\n\nhost: The host of the user. Required. unique.\n\n\ndatabase: The database to apply the grant on. Required.\n\n\nprivileges: The privileges to grant. Required.\n\n\n\n\nExample\n\n\nmysql.grant --user nova --host localhost --database nova --privileges \nSELECT, UPDATE, DELETE", 
            "title": "mysql.grant"
        }, 
        {
            "location": "/resources/mysql.grant/#mysqlgrant", 
            "text": "", 
            "title": "mysql.grant"
        }, 
        {
            "location": "/resources/mysql.grant/#description", 
            "text": "Manages MySQL grants", 
            "title": "Description"
        }, 
        {
            "location": "/resources/mysql.grant/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  user: The user to receive the grant. Required. unique.  host: The host of the user. Required. unique.  database: The database to apply the grant on. Required.  privileges: The privileges to grant. Required.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/mysql.grant/#example", 
            "text": "mysql.grant --user nova --host localhost --database nova --privileges  SELECT, UPDATE, DELETE", 
            "title": "Example"
        }, 
        {
            "location": "/resources/mysql.user/", 
            "text": "mysql.user\n\n\nDescription\n\n\nManages MySQL users\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nuser: The username of the mysql user. unique.\n\n\nhost: The host of the mysql user. Required. unique.\n\n\npassword: The password of the mysql user.\n\n\n\n\nUnintuitively, user and password are optional because MySQL allows blank usernames and blank passwords.\n\n\nExample\n\n\nmysql.user --user root --password password", 
            "title": "mysql.user"
        }, 
        {
            "location": "/resources/mysql.user/#mysqluser", 
            "text": "", 
            "title": "mysql.user"
        }, 
        {
            "location": "/resources/mysql.user/#description", 
            "text": "Manages MySQL users", 
            "title": "Description"
        }, 
        {
            "location": "/resources/mysql.user/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  user: The username of the mysql user. unique.  host: The host of the mysql user. Required. unique.  password: The password of the mysql user.   Unintuitively, user and password are optional because MySQL allows blank usernames and blank passwords.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/mysql.user/#example", 
            "text": "mysql.user --user root --password password", 
            "title": "Example"
        }, 
        {
            "location": "/resources/nginx.events/", 
            "text": "nginx.events\n\n\nDescription\n\n\nManages events key/value settings in nginx.conf\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nkey: The key. Required.\n\n\nvalue: A value for the key. Required.\n\n\nfile: The file to store the settings in. Optional. Defaults to /etc/nginx/nginx.conf.\n\n\n\n\nExample\n\n\nnginx.events --key worker_connections --value 768", 
            "title": "nginx.events"
        }, 
        {
            "location": "/resources/nginx.events/#nginxevents", 
            "text": "", 
            "title": "nginx.events"
        }, 
        {
            "location": "/resources/nginx.events/#description", 
            "text": "Manages events key/value settings in nginx.conf", 
            "title": "Description"
        }, 
        {
            "location": "/resources/nginx.events/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  key: The key. Required.  value: A value for the key. Required.  file: The file to store the settings in. Optional. Defaults to /etc/nginx/nginx.conf.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/nginx.events/#example", 
            "text": "nginx.events --key worker_connections --value 768", 
            "title": "Example"
        }, 
        {
            "location": "/resources/nginx.global/", 
            "text": "nginx.global\n\n\nDescription\n\n\nManages global key/value settings in nginx.conf\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nkey: The key. Required.\n\n\nvalue: A value for the key. Required.\n\n\nfile: The file to store the settings in. Optional. Defaults to /etc/nginx/nginx.conf.\n\n\n\n\nExample\n\n\nnginx.global --key user --value www-data\nnginx.global --key worker_processes --value 4", 
            "title": "nginx.global"
        }, 
        {
            "location": "/resources/nginx.global/#nginxglobal", 
            "text": "", 
            "title": "nginx.global"
        }, 
        {
            "location": "/resources/nginx.global/#description", 
            "text": "Manages global key/value settings in nginx.conf", 
            "title": "Description"
        }, 
        {
            "location": "/resources/nginx.global/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  key: The key. Required.  value: A value for the key. Required.  file: The file to store the settings in. Optional. Defaults to /etc/nginx/nginx.conf.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/nginx.global/#example", 
            "text": "nginx.global --key user --value www-data\nnginx.global --key worker_processes --value 4", 
            "title": "Example"
        }, 
        {
            "location": "/resources/nginx.http/", 
            "text": "nginx.http\n\n\nDescription\n\n\nManages http key/value settings in nginx.conf\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nkey: The key. Required.\n\n\nvalue: A value for the key. Required.\n\n\nfile: The file to store the settings in. Optional. Defaults to /etc/nginx/nginx.conf.\n\n\n\n\nExample\n\n\nnginx.http --key index --value \nindex.html index.htm index.php\n\nlog_format='main \n$remote_addr - $remote_user [$time_local] $status \\\n$request\\\n $body_bytes_sent \\\n$http_referer\\\n \\\n$http_user_agent\\\n \\\n$http_x_forwarded_for\\\n'\nnginx.http --key log_format --value \n$log_format\n\nnginx.http --key access_log --value \n/var/log/nginx/access.log main", 
            "title": "nginx.http"
        }, 
        {
            "location": "/resources/nginx.http/#nginxhttp", 
            "text": "", 
            "title": "nginx.http"
        }, 
        {
            "location": "/resources/nginx.http/#description", 
            "text": "Manages http key/value settings in nginx.conf", 
            "title": "Description"
        }, 
        {
            "location": "/resources/nginx.http/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  key: The key. Required.  value: A value for the key. Required.  file: The file to store the settings in. Optional. Defaults to /etc/nginx/nginx.conf.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/nginx.http/#example", 
            "text": "nginx.http --key index --value  index.html index.htm index.php \nlog_format='main  $remote_addr - $remote_user [$time_local] $status \\ $request\\  $body_bytes_sent \\ $http_referer\\  \\ $http_user_agent\\  \\ $http_x_forwarded_for\\ '\nnginx.http --key log_format --value  $log_format \nnginx.http --key access_log --value  /var/log/nginx/access.log main", 
            "title": "Example"
        }, 
        {
            "location": "/resources/nginx.if/", 
            "text": "nginx.if\n\n\nDescription\n\n\nManages key/value settings in an nginx server if block\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nname: The conditional of the if block. Required. namevar.\n\n\nserver_name: The name of the nginx_server resource. Required.\n\n\nkey: The key. Required.\n\n\nvalue: A value for the key. Required.\n\n\nfile: The file to add the variable to. Optional. Defaults to /etc/nginx/sites-enabled/server_name.\n\n\n\n\nExample\n\n\nnginx.if --name '$request_method !~ ^(GET|HEAD|POST)$' --server_name example.com --key return --value 444", 
            "title": "nginx.if"
        }, 
        {
            "location": "/resources/nginx.if/#nginxif", 
            "text": "", 
            "title": "nginx.if"
        }, 
        {
            "location": "/resources/nginx.if/#description", 
            "text": "Manages key/value settings in an nginx server if block", 
            "title": "Description"
        }, 
        {
            "location": "/resources/nginx.if/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  name: The conditional of the if block. Required. namevar.  server_name: The name of the nginx_server resource. Required.  key: The key. Required.  value: A value for the key. Required.  file: The file to add the variable to. Optional. Defaults to /etc/nginx/sites-enabled/server_name.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/nginx.if/#example", 
            "text": "nginx.if --name '$request_method !~ ^(GET|HEAD|POST)$' --server_name example.com --key return --value 444", 
            "title": "Example"
        }, 
        {
            "location": "/resources/nginx.location/", 
            "text": "nginx.location\n\n\nDescription\n\n\nManages key/value settings in an nginx server location block\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nname: The name of the location block. Required. namevar.\n\n\nserver_name: The name of the nginx_server resource. Required.\n\n\nkey: The key. Required.\n\n\nvalue: A value for the key. Required.\n\n\nfile: The file to add the variable to. Optional. Defaults to /etc/nginx/sites-enabled/server_name.\n\n\n\n\nExample\n\n\nnginx.location --name '~ \\.php$' --server_name example.com --key try_files --value '$uri $uri/ @dw'", 
            "title": "nginx.location"
        }, 
        {
            "location": "/resources/nginx.location/#nginxlocation", 
            "text": "", 
            "title": "nginx.location"
        }, 
        {
            "location": "/resources/nginx.location/#description", 
            "text": "Manages key/value settings in an nginx server location block", 
            "title": "Description"
        }, 
        {
            "location": "/resources/nginx.location/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  name: The name of the location block. Required. namevar.  server_name: The name of the nginx_server resource. Required.  key: The key. Required.  value: A value for the key. Required.  file: The file to add the variable to. Optional. Defaults to /etc/nginx/sites-enabled/server_name.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/nginx.location/#example", 
            "text": "nginx.location --name '~ \\.php$' --server_name example.com --key try_files --value '$uri $uri/ @dw'", 
            "title": "Example"
        }, 
        {
            "location": "/resources/nginx.map/", 
            "text": "nginx.map\n\n\nDescription\n\n\nManages entries in an nginx.map block\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nname: The name of the map definition. Required.\n\n\nsource: The source of the map definition. Required.\n\n\nvariable: The variable of the map definition. Required.\n\n\nkey: The key. Required.\n\n\nvalue: A value for the key. Required.\n\n\nfile: The file to store the settings in. Optional. Defaults to /etc/nginx/conf.d/map_name.\n\n\n\n\nExample\n\n\nnginx.map --name my_map --source '$http_host' --variable '$name' --key default --value 0\nnginx.map --name my_map --source '$http_host' --variable '$name' --key example.com --value 1", 
            "title": "nginx.map"
        }, 
        {
            "location": "/resources/nginx.map/#nginxmap", 
            "text": "", 
            "title": "nginx.map"
        }, 
        {
            "location": "/resources/nginx.map/#description", 
            "text": "Manages entries in an nginx.map block", 
            "title": "Description"
        }, 
        {
            "location": "/resources/nginx.map/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  name: The name of the map definition. Required.  source: The source of the map definition. Required.  variable: The variable of the map definition. Required.  key: The key. Required.  value: A value for the key. Required.  file: The file to store the settings in. Optional. Defaults to /etc/nginx/conf.d/map_name.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/nginx.map/#example", 
            "text": "nginx.map --name my_map --source '$http_host' --variable '$name' --key default --value 0\nnginx.map --name my_map --source '$http_host' --variable '$name' --key example.com --value 1", 
            "title": "Example"
        }, 
        {
            "location": "/resources/nginx.server/", 
            "text": "nginx.server\n\n\nDescription\n\n\nManages key/value settings in an nginx server block\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nname: The name of the server. Required. namevar.\n\n\nserver_name: The domain of the server. Optional. Defaults to name.\n\n\nkey: The key. Required.\n\n\nvalue: A value for the key. Required.\n\n\nfile: The file to store the settings in. Optional. Defaults to /etc/nginx/sites-enabled/name.\n\n\n\n\nExample\n\n\nnginx.server --name example.com --key root --value /var/www/html\nnginx.server --name example.com --key listen --value 80\nnginx.server --name example.com --key index --value index.php", 
            "title": "nginx.server"
        }, 
        {
            "location": "/resources/nginx.server/#nginxserver", 
            "text": "", 
            "title": "nginx.server"
        }, 
        {
            "location": "/resources/nginx.server/#description", 
            "text": "Manages key/value settings in an nginx server block", 
            "title": "Description"
        }, 
        {
            "location": "/resources/nginx.server/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  name: The name of the server. Required. namevar.  server_name: The domain of the server. Optional. Defaults to name.  key: The key. Required.  value: A value for the key. Required.  file: The file to store the settings in. Optional. Defaults to /etc/nginx/sites-enabled/name.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/nginx.server/#example", 
            "text": "nginx.server --name example.com --key root --value /var/www/html\nnginx.server --name example.com --key listen --value 80\nnginx.server --name example.com --key index --value index.php", 
            "title": "Example"
        }, 
        {
            "location": "/resources/nginx.upstream/", 
            "text": "nginx.upstream\n\n\nDescription\n\n\nManages entries in an nginx upstream block\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nname: The name of the upstream definition. Required. namevar.\n\n\nkey: The key. Required.\n\n\nvalue: A value for the key. Required.\n\n\noptions: Extra options for the value. Optional.\n\n\nfile: The file to store the settings in. Optional. Defaults to /etc/nginx/conf.d/upstream_name.\n\n\n\n\nExample\n\n\nnginx.upstream --name example_com --key server --value server1.example.com --options \nweight=5\n\nnginx.upstream --name example_com --key server --value server2.example.com\n\n\n\n\nNotes\n\n\nThis is broke at the moment due to an issue with the Nginx Augeas lens.\nThis comment will be removed when it's working.", 
            "title": "nginx.upstream"
        }, 
        {
            "location": "/resources/nginx.upstream/#nginxupstream", 
            "text": "", 
            "title": "nginx.upstream"
        }, 
        {
            "location": "/resources/nginx.upstream/#description", 
            "text": "Manages entries in an nginx upstream block", 
            "title": "Description"
        }, 
        {
            "location": "/resources/nginx.upstream/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  name: The name of the upstream definition. Required. namevar.  key: The key. Required.  value: A value for the key. Required.  options: Extra options for the value. Optional.  file: The file to store the settings in. Optional. Defaults to /etc/nginx/conf.d/upstream_name.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/nginx.upstream/#example", 
            "text": "nginx.upstream --name example_com --key server --value server1.example.com --options  weight=5 \nnginx.upstream --name example_com --key server --value server2.example.com", 
            "title": "Example"
        }, 
        {
            "location": "/resources/nginx.upstream/#notes", 
            "text": "This is broke at the moment due to an issue with the Nginx Augeas lens.\nThis comment will be removed when it's working.", 
            "title": "Notes"
        }, 
        {
            "location": "/resources/python.pip/", 
            "text": "python.pip\n\n\nDescription\n\n\nManage a pip python package\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nname: The name of the pip package. Required.\n\n\nversion: The version of the pip package. Optional.\n\n\nvirtualenv: The virtual environment to put the package in. Required. Default: system.\n\n\nurl: A URL to install the package from. Optional.\n\n\nowner: The owner of the virtualenv. Required. Default: root.\n\n\ngroup: The group of the virtualenv. Required. Default: root.\n\n\nindex: Base URL of the python package index. Optional.\n\n\neditable: If the package is installed as an editable resource. Required. Default: false.\n\n\nenvironment: Additional environment variables. Optional.\n\n\ninstall_args: Additional arguments to use when installing. Optional.\n\n\nuninstall-args: Additional arguments to use when uninstalling. Optional.\n\n\n\n\nExample\n\n\npython.pip --name minilanguage\npython.pip --name minilanguage --version 0.3.0\npython.pip --name minilanguage --version latest\n\n\n\n\nNotes\n\n\nThis resource is heavily based on puppet-python", 
            "title": "python.pip"
        }, 
        {
            "location": "/resources/python.pip/#pythonpip", 
            "text": "", 
            "title": "python.pip"
        }, 
        {
            "location": "/resources/python.pip/#description", 
            "text": "Manage a pip python package", 
            "title": "Description"
        }, 
        {
            "location": "/resources/python.pip/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  name: The name of the pip package. Required.  version: The version of the pip package. Optional.  virtualenv: The virtual environment to put the package in. Required. Default: system.  url: A URL to install the package from. Optional.  owner: The owner of the virtualenv. Required. Default: root.  group: The group of the virtualenv. Required. Default: root.  index: Base URL of the python package index. Optional.  editable: If the package is installed as an editable resource. Required. Default: false.  environment: Additional environment variables. Optional.  install_args: Additional arguments to use when installing. Optional.  uninstall-args: Additional arguments to use when uninstalling. Optional.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/python.pip/#example", 
            "text": "python.pip --name minilanguage\npython.pip --name minilanguage --version 0.3.0\npython.pip --name minilanguage --version latest", 
            "title": "Example"
        }, 
        {
            "location": "/resources/python.pip/#notes", 
            "text": "This resource is heavily based on puppet-python", 
            "title": "Notes"
        }, 
        {
            "location": "/resources/python.virtualenv/", 
            "text": "python.virtualenv\n\n\nDescription\n\n\nManage a python virtualenv\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nname: The name of the virtualenv package. Required.\n\n\nvenv_dir: The path / parent directory to the virtual environment. Required. Default: /usr/local\"\n\n\nrequirements: The path to a requirements.txt file. Optional.\n\n\nsystempkgs: Copy system site-packages into the virtualenv. Required. Default: false.\n\n\ndistribute: Distribute method. Required. Default: distribute\n\n\nindex: An alternative pypi index file. Optional.\n\n\nowner: The owner of the virtualenv. Required. Default: root.\n\n\ngroup: The group of the virtualenv. Required. Default: root.\n\n\nmode: The directory mode of the venv. Required. Default: 755.\n\n\nenvironment: Additional environment variables. Optional.\n\n\npip_args: Extra pip args. Optional.\n\n\n\n\nExample\n\n\npython.virtualenv --name foo\n\n\n\n\nNotes\n\n\nThis resource is heavily based on puppet-python", 
            "title": "python.virtualenv"
        }, 
        {
            "location": "/resources/python.virtualenv/#pythonvirtualenv", 
            "text": "", 
            "title": "python.virtualenv"
        }, 
        {
            "location": "/resources/python.virtualenv/#description", 
            "text": "Manage a python virtualenv", 
            "title": "Description"
        }, 
        {
            "location": "/resources/python.virtualenv/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  name: The name of the virtualenv package. Required.  venv_dir: The path / parent directory to the virtual environment. Required. Default: /usr/local\"  requirements: The path to a requirements.txt file. Optional.  systempkgs: Copy system site-packages into the virtualenv. Required. Default: false.  distribute: Distribute method. Required. Default: distribute  index: An alternative pypi index file. Optional.  owner: The owner of the virtualenv. Required. Default: root.  group: The group of the virtualenv. Required. Default: root.  mode: The directory mode of the venv. Required. Default: 755.  environment: Additional environment variables. Optional.  pip_args: Extra pip args. Optional.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/python.virtualenv/#example", 
            "text": "python.virtualenv --name foo", 
            "title": "Example"
        }, 
        {
            "location": "/resources/python.virtualenv/#notes", 
            "text": "This resource is heavily based on puppet-python", 
            "title": "Notes"
        }, 
        {
            "location": "/resources/rabbitmq.cluster_nodes/", 
            "text": "rabbitmq.cluster_nodes\n\n\nDescription\n\n\nManages cluster_nodes settings in a rabbitmq.config file.\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nnode: A node. Required. Multi-var.\n\n\ncluster_type: The cluster type. Optional. Defaults to disc.\n\n\nfile: The file to store the settings in. Optional. Defaults to /etc/rabbitmq/rabbitmq.config.\n\n\n\n\nExample\n\n\nrabbitmq.cluster_nodes --node rabbit@my.host.com --node rabbit@my2.host.com --cluster_type ram", 
            "title": "rabbitmq.cluster_nodes"
        }, 
        {
            "location": "/resources/rabbitmq.cluster_nodes/#rabbitmqcluster_nodes", 
            "text": "", 
            "title": "rabbitmq.cluster_nodes"
        }, 
        {
            "location": "/resources/rabbitmq.cluster_nodes/#description", 
            "text": "Manages cluster_nodes settings in a rabbitmq.config file.", 
            "title": "Description"
        }, 
        {
            "location": "/resources/rabbitmq.cluster_nodes/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  node: A node. Required. Multi-var.  cluster_type: The cluster type. Optional. Defaults to disc.  file: The file to store the settings in. Optional. Defaults to /etc/rabbitmq/rabbitmq.config.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/rabbitmq.cluster_nodes/#example", 
            "text": "rabbitmq.cluster_nodes --node rabbit@my.host.com --node rabbit@my2.host.com --cluster_type ram", 
            "title": "Example"
        }, 
        {
            "location": "/resources/rabbitmq.config_settings/", 
            "text": "rabbitmq.config_settings\n\n\nDescription\n\n\nManages settings in a rabbitmq.config file.\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nauth_backends: The auth backend. Optional.\n\n\nauth_mechanisms: The auth mechanism. Optional.\n\n\nbacking_queue_module: The backing queue module. Optional.\n\n\ncluster_partition_handling: The cluster_partition_handling setting. Optional.\n\n\ncollect_statistics: The statistics to collect: none, coarse, fine. Optional.\n\n\ncollect_statistics_interval: The interval to collect statistics. Optional.\n\n\ndefault_permissions: A CSV list of conf, read, and write default permissions. Optional.\n\n\ndefault_user: The default user. Optional.\n\n\ndefault_user_tags: The default user tags. Optional.\n\n\ndefault_vhost: The default vhost. Optional.\n\n\ndelegate_count: The delegate count. Optional.\n\n\ndisk_free_limit_type: The disk free limit type. Either mem_relative or absolute. Optional\n\n\ndisk_free_limit_value: The disk free liit value. Optional.\n\n\nframe_max: The frame max setting. Optional.\n\n\nheartbeat: The heartbeat delay in seconds. Optional.\n\n\nhipe_compile: Whether or not to enable HiPE. Optional.\n\n\nlog_levels: Logging settings. Value is in format \"connection=info,channel=debug\". Optional.\n\n\nmsg_store_file_size_limit: The message store file size limit. Optional.\n\n\nmsg_store_index_module: The message store index module. Optional.\n\n\nqueue_index_max_journal_entries: The queue index max journal entries. Optional.\n\n\ntcp_listener_address: The address to listen on for non-SSL connections. Optional.\n\n\ntcp_listener_port: The port to listen on for non-SSL connections. Optional.\n\n\nvm_memory_high_watermark: The vm_memory_high_watermark setting. Optional.\n\n\nssl_listener_address: The address to listen on for SSL connections. Optional.\n\n\nssl_listener_port: The port to listen on for SSL connections. Optional.\n\n\nssl_keyfile: The certificate key. Optional.\n\n\nssl_certfile: The certificate. Optional.\n\n\nssl_cacertfile: The CA certificate. Optional.\n\n\nssl_verify: Whether to verify the peer certificate. Optional.\n\n\nssl_fail_if_no_peer_cert: Fail if no peer cert. Optional.\n\n\nfile: The file to store the settings in. Optional. Defaults to /etc/rabbitmq/rabbitmq.config.\n\n\n\n\nExample\n\n\nrabbitmq.config_settings --auth_backends PLAIN --auth_mechanisms PLAIN", 
            "title": "rabbitmq.config_settings"
        }, 
        {
            "location": "/resources/rabbitmq.config_settings/#rabbitmqconfig_settings", 
            "text": "", 
            "title": "rabbitmq.config_settings"
        }, 
        {
            "location": "/resources/rabbitmq.config_settings/#description", 
            "text": "Manages settings in a rabbitmq.config file.", 
            "title": "Description"
        }, 
        {
            "location": "/resources/rabbitmq.config_settings/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  auth_backends: The auth backend. Optional.  auth_mechanisms: The auth mechanism. Optional.  backing_queue_module: The backing queue module. Optional.  cluster_partition_handling: The cluster_partition_handling setting. Optional.  collect_statistics: The statistics to collect: none, coarse, fine. Optional.  collect_statistics_interval: The interval to collect statistics. Optional.  default_permissions: A CSV list of conf, read, and write default permissions. Optional.  default_user: The default user. Optional.  default_user_tags: The default user tags. Optional.  default_vhost: The default vhost. Optional.  delegate_count: The delegate count. Optional.  disk_free_limit_type: The disk free limit type. Either mem_relative or absolute. Optional  disk_free_limit_value: The disk free liit value. Optional.  frame_max: The frame max setting. Optional.  heartbeat: The heartbeat delay in seconds. Optional.  hipe_compile: Whether or not to enable HiPE. Optional.  log_levels: Logging settings. Value is in format \"connection=info,channel=debug\". Optional.  msg_store_file_size_limit: The message store file size limit. Optional.  msg_store_index_module: The message store index module. Optional.  queue_index_max_journal_entries: The queue index max journal entries. Optional.  tcp_listener_address: The address to listen on for non-SSL connections. Optional.  tcp_listener_port: The port to listen on for non-SSL connections. Optional.  vm_memory_high_watermark: The vm_memory_high_watermark setting. Optional.  ssl_listener_address: The address to listen on for SSL connections. Optional.  ssl_listener_port: The port to listen on for SSL connections. Optional.  ssl_keyfile: The certificate key. Optional.  ssl_certfile: The certificate. Optional.  ssl_cacertfile: The CA certificate. Optional.  ssl_verify: Whether to verify the peer certificate. Optional.  ssl_fail_if_no_peer_cert: Fail if no peer cert. Optional.  file: The file to store the settings in. Optional. Defaults to /etc/rabbitmq/rabbitmq.config.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/rabbitmq.config_settings/#example", 
            "text": "rabbitmq.config_settings --auth_backends PLAIN --auth_mechanisms PLAIN", 
            "title": "Example"
        }, 
        {
            "location": "/resources/rabbitmq.policy/", 
            "text": "rabbitmq.policy\n\n\nDescription\n\n\nManages RabbitMQ policies\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nname: The name of the policy. Required. namevar.\n\n\nvhost: The vhost to apply the policy to. Default: /.\n\n\nqueues: The queues to apply the policy to. Default: all.\n\n\npolicy: The policy. Required.\n\n\n\n\nExample\n\n\nrabbitmq.policy --name openstack-ha --vhost openstack --policy '{\nha-mode\n:\nall\n}'", 
            "title": "rabbitmq.policy"
        }, 
        {
            "location": "/resources/rabbitmq.policy/#rabbitmqpolicy", 
            "text": "", 
            "title": "rabbitmq.policy"
        }, 
        {
            "location": "/resources/rabbitmq.policy/#description", 
            "text": "Manages RabbitMQ policies", 
            "title": "Description"
        }, 
        {
            "location": "/resources/rabbitmq.policy/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  name: The name of the policy. Required. namevar.  vhost: The vhost to apply the policy to. Default: /.  queues: The queues to apply the policy to. Default: all.  policy: The policy. Required.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/rabbitmq.policy/#example", 
            "text": "rabbitmq.policy --name openstack-ha --vhost openstack --policy '{ ha-mode : all }'", 
            "title": "Example"
        }, 
        {
            "location": "/resources/rabbitmq.user_permissions/", 
            "text": "rabbitmq.user_permissions\n\n\nDescription\n\n\nManages RabbitMQ user permissions\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nuser: The username@vhost of the rabbitmq user. Required. namevar.\n\n\nconf: The conf portion of the set_permissions command. Default: '.*'\n\n\nwrite: The write portion of the set_permissions command. Default: '.*'\n\n\nread: The read portion of the set_permissions command. Default: '.*'\n\n\n\n\nExample\n\n\nrabbitmq.user_permission --user_permission root --password password", 
            "title": "rabbitmq.user_permissions"
        }, 
        {
            "location": "/resources/rabbitmq.user_permissions/#rabbitmquser_permissions", 
            "text": "", 
            "title": "rabbitmq.user_permissions"
        }, 
        {
            "location": "/resources/rabbitmq.user_permissions/#description", 
            "text": "Manages RabbitMQ user permissions", 
            "title": "Description"
        }, 
        {
            "location": "/resources/rabbitmq.user_permissions/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  user: The username@vhost of the rabbitmq user. Required. namevar.  conf: The conf portion of the set_permissions command. Default: '.*'  write: The write portion of the set_permissions command. Default: '.*'  read: The read portion of the set_permissions command. Default: '.*'", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/rabbitmq.user_permissions/#example", 
            "text": "rabbitmq.user_permission --user_permission root --password password", 
            "title": "Example"
        }, 
        {
            "location": "/resources/rabbitmq.user/", 
            "text": "rabbitmq.user\n\n\nDescription\n\n\nManages RabbitMQ users\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nuser: The username of the rabbitmq user. Required. namevar.\n\n\npassword: The password of the rabbitmq user.\n\n\nadmin: Make the user an admin. Default: false.\n\n\n\n\nExample\n\n\nrabbitmq.user --user root --password password", 
            "title": "rabbitmq.user"
        }, 
        {
            "location": "/resources/rabbitmq.user/#rabbitmquser", 
            "text": "", 
            "title": "rabbitmq.user"
        }, 
        {
            "location": "/resources/rabbitmq.user/#description", 
            "text": "Manages RabbitMQ users", 
            "title": "Description"
        }, 
        {
            "location": "/resources/rabbitmq.user/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  user: The username of the rabbitmq user. Required. namevar.  password: The password of the rabbitmq user.  admin: Make the user an admin. Default: false.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/rabbitmq.user/#example", 
            "text": "rabbitmq.user --user root --password password", 
            "title": "Example"
        }, 
        {
            "location": "/resources/rabbitmq.vhost/", 
            "text": "rabbitmq.vhost\n\n\nDescription\n\n\nManages RabbitMQ vhosts\n\n\nParameters\n\n\n\n\nstate: The state of the resource. Required. Default: present.\n\n\nvhost: The vhostname of the rabbitmq vhost. Required. namevar.\n\n\n\n\nExample\n\n\nrabbitmq.vhost --vhost openstack", 
            "title": "rabbitmq.vhost"
        }, 
        {
            "location": "/resources/rabbitmq.vhost/#rabbitmqvhost", 
            "text": "", 
            "title": "rabbitmq.vhost"
        }, 
        {
            "location": "/resources/rabbitmq.vhost/#description", 
            "text": "Manages RabbitMQ vhosts", 
            "title": "Description"
        }, 
        {
            "location": "/resources/rabbitmq.vhost/#parameters", 
            "text": "state: The state of the resource. Required. Default: present.  vhost: The vhostname of the rabbitmq vhost. Required. namevar.", 
            "title": "Parameters"
        }, 
        {
            "location": "/resources/rabbitmq.vhost/#example", 
            "text": "rabbitmq.vhost --vhost openstack", 
            "title": "Example"
        }
    ]
}